{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 도구 (Tools)\n",
    "\n",
    "도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\n",
    "\n",
    "LangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\n",
    "\n",
    "**LangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.**\n",
    "\n",
    "- [LangChain 통합된 도구 리스트](https://python.langchain.com/v0.1/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH12-Tools\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH12-Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# 경고 메시지 무시\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빌트인 도구(built-in tools)\n",
    "\n",
    "랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit) 을 사용할 수 있습니다.\n",
    "\n",
    "tool 은 단일 도구를 의미하며, toolkit 은 여러 도구를 묶어서 하나의 도구로 사용할 수 있습니다.\n",
    "\n",
    "관련 도구는 아래의 링크에서 참고하실 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "- [LangChain Tools/Toolkits](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python REPL 도구\n",
    "\n",
    "이 도구는 Python 코드를 REPL(Read-Eval-Print Loop) 환경에서 실행하기 위한 클래스를 제공합니다\n",
    "- PythonREPLTool\n",
    "\n",
    "**설명**\n",
    "\n",
    "- Python 셸 환경을 제공합니다.\n",
    "- 유효한 Python 명령어를 입력으로 받아 실행합니다.\n",
    "- 결과를 보려면 print(...) 함수를 사용해야 합니다.\n",
    "\n",
    "**주요 특징**\n",
    "\n",
    "- sanitize_input: 입력을 정제하는 옵션 (기본값: True)\n",
    "- python_repl: PythonREPL 인스턴스 (기본값: 전역 범위에서 실행)\n",
    "\n",
    "**사용 방법**\n",
    "\n",
    "- PythonREPLTool 인스턴스 생성\n",
    "- run 또는 arun, invoke 메서드를 사용하여 Python 코드 실행\n",
    "\n",
    "**입력 정제**\n",
    "\n",
    "- 입력 문자열에서 불필요한 공백, 백틱, 'python' 키워드 등을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# 파이썬 코드를 실행하는 도구를 생성합니다.\n",
    "python_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 코드를 실행하고 결과를 반환합니다.\n",
    "print(python_tool.invoke(\"print(100 + 200)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 LLM 에게 파이썬 코드를 작성하도록 요청하고 결과를 반환하는 예제입니다.\n",
    "\n",
    "**흐름 정리**\n",
    "1. LLM 모델에게 특정 작업을 수행하는 Python 코드를 작성하도록 요청합니다.\n",
    "2. 작성된 코드를 실행하여 결과를 얻습니다.\n",
    "3. 결과를 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# 파이썬 코드를 실행하고 중간 과정을 출력하고 도구 실행 결과를 반환하는 함수\n",
    "def print_and_execute(code, debug=True):\n",
    "    if debug:\n",
    "        print(\"CODE:\")\n",
    "        print(code)\n",
    "    return python_tool.invoke(code)\n",
    "\n",
    "\n",
    "# 파이썬 코드를 작성하도록 요청하는 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\n",
    "            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# 프롬프트와 LLM 모델을 사용하여 체인 생성\n",
    "chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:\n",
      "import random\n",
      "\n",
      "def generate_lotto_numbers():\n",
      "    return sorted(random.sample(range(1, 46), 6))\n",
      "\n",
      "print(generate_lotto_numbers())\n",
      "[4, 5, 20, 23, 34, 44]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(chain.invoke(\"로또 번호 생성기를 출력하는 코드를 작성하세요.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색 API 도구\n",
    "\n",
    "Tavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: `TavilySearchResults`와 `TavilyAnswer`.\n",
    "\n",
    "**API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "발급한 API 키를 환경변수에 설정합니다.\n",
    "\n",
    "`.env` 파일에 아래와 같이 설정합니다.\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**설명**\n",
    "- Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\n",
    "- 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\n",
    "- 현재 이벤트에 대한 질문에 답변할 때 유용합니다.\n",
    "\n",
    "**주요 매개변수**\n",
    "- `max_results` (int): 반환할 최대 검색 결과 수 (기본값: 5)\n",
    "- `search_depth` (str): 검색 깊이 (\"basic\" 또는 \"advanced\")\n",
    "- `include_domains` (List[str]): 검색 결과에 포함할 도메인 목록\n",
    "- `exclude_domains` (List[str]): 검색 결과에서 제외할 도메인 목록\n",
    "- `include_answer` (bool): 원본 쿼리에 대한 짧은 답변 포함 여부\n",
    "- `include_raw_content` (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부\n",
    "- `include_images` (bool): 쿼리 관련 이미지 목록 포함 여부\n",
    "\n",
    "**반환 값**\n",
    "- 검색 결과를 포함하는 JSON 형식의 문자열(url, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혹은 아래의 주석을 해제하고 발급받은 API 키를 입력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# 도구 생성\n",
    "tool = TavilySearchResults(\n",
    "    max_results=6,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    # include_images=True,\n",
    "    # search_depth=\"advanced\", # or \"basic\"\n",
    "    include_domains=[\"github.io\", \"wikidocs.net\"],\n",
    "    # exclude_domains = []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '01. 도구(Tools) -  - LangChain 한국어 튜토리얼',\n",
       "  'url': 'https://wikidocs.net/262582',\n",
       "  'content': '```python\\nimport os\\nos.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\"\\n```\\n```python\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\n도구 생성\\ntool = TavilySearchResults(\\n    max_results=6,\\n    include_answer=True,\\n    include_raw_content=True,\\n    # include_images=True,\\n    # search_depth=\"advanced\", # or \"basic\"\\n    include_domains=[\"github.io\", \"wikidocs.net\"],\\n    # exclude_domains = []\\n)\\n```\\n```python\\n도구 실행\\ntool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})\\n```\\n[ [...] <랭체인LangChain 노트> - Lang…\\nCH16 에이전트(Agent)\\n\\n01. 도구(Tools)\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n01. 도구(Tools)\\n도구 (Tools)\\n도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\\nLangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\\nLangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.\\n\\nLangChain 통합된 도구 리스트 [...] 사용자 정의 도구(Custom Tool)\\nLangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\\n이를 위해서는 langchain.tools 모듈에서 제공하는 tool 데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool 데코레이터\\n이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\\n사용 방법\\n\\n함수 위에 @tool 데코레이터 적용\\n필요에 따라 데코레이터 매개변수 설정',\n",
       "  'score': 0.8467682,\n",
       "  'raw_content': '01. 도구(Tools) - <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\nCH16 에이전트(Agent)\\n\\n01. 도구(Tools)\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n01. 도구(Tools)\\n도구 (Tools)\\n도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\\nLangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\\nLangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.\\n\\nLangChain 통합된 도구 리스트\\n\\n```python\\nAPI 키를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\nAPI 키 정보 로드\\nload_dotenv()\\n```\\nTrue\\n```python\\nLangSmith 추적을 설정합니다. https://smith.langchain.com\\n!pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH15-Tools\")\\n```\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH15-Tools\\n```python\\nimport warnings\\n경고 메시지 무시\\nwarnings.filterwarnings(\"ignore\")\\n```\\n빌트인 도구(built-in tools)\\n랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit) 을 사용할 수 있습니다.\\ntool 은 단일 도구를 의미하며, toolkit 은 여러 도구를 묶어서 하나의 도구로 사용할 수 있습니다.\\n관련 도구는 아래의 링크에서 참고하실 수 있습니다.\\n참고\\n\\nLangChain Tools/Toolkits\\n\\nPython REPL 도구\\n이 도구는 Python 코드를 REPL(Read-Eval-Print Loop) 환경에서 실행하기 위한 두 가지 주요 클래스를 제공합니다 - PythonREPLTool\\n설명\\n\\nPython 셸 환경을 제공합니다.\\n유효한 Python 명령어를 입력으로 받아 실행합니다.\\n결과를 보려면 print(...) 함수를 사용해야 합니다.\\n\\n주요 특징\\n\\nsanitize_input: 입력을 정제하는 옵션 (기본값: True)\\npython_repl: PythonREPL 인스턴스 (기본값: 전역 범위에서 실행)\\n\\n사용 방법\\n\\nPythonREPLTool 인스턴스 생성\\nrun 또는 arun, invoke 메서드를 사용하여 Python 코드 실행\\n\\n입력 정제\\n\\n입력 문자열에서 불필요한 공백, 백틱, \\'python\\' 키워드 등을 제거합니다.\\n\\n```python\\nfrom langchain_experimental.tools import PythonREPLTool\\n파이썬 코드를 실행하는 도구를 생성합니다.\\npython_tool = PythonREPLTool()\\n```\\n```python\\n파이썬 코드를 실행하고 결과를 반환합니다.\\nprint(python_tool.invoke(\"print(100 + 200)\"))\\n```\\n300\\n아래는 LLM 에게 파이썬 코드를 작성하도록 요청하고 결과를 반환하는 예제입니다.\\n흐름 정리\\n\\nLLM 모델에게 특정 작업을 수행하는 Python 코드를 작성하도록 요청합니다.\\n작성된 코드를 실행하여 결과를 얻습니다.\\n결과를 출력합니다.\\n\\n```python\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableLambda\\n파이썬 코드를 실행하고 중간 과정을 출력하고 도구 실행 결과를 반환하는 함수\\ndef print_and_execute(code, debug=True):\\n    if debug:\\n        print(\"CODE:\")\\n        print(code)\\n    return python_tool.invoke(code)\\n파이썬 코드를 작성하도록 요청하는 프롬프트\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\\n            \"system\",\\n            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\\n            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\\n        ),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\nLLM 모델 생성\\nllm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\\n프롬프트와 LLM 모델을 사용하여 체인 생성\\nchain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)\\n```\\n```python\\n결과 출력\\nprint(chain.invoke(\"로또 번호 생성기를 출력하는 코드를 작성하세요.\"))\\n```\\nCODE:\\nimport random\\ndef generate_lotto_numbers():\\n    return sorted(random.sample(range(1, 46), 6))\\nprint(generate_lotto_numbers())\\n[14, 17, 18, 22, 23, 37]\\n검색 API 도구\\nTavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: TavilySearchResults와 TavilyAnswer.\\nAPI 키 발급 주소\\n\\nhttps://app.tavily.com/\\n\\n발급한 API 키를 환경변수에 설정합니다.\\n.env 파일에 아래와 같이 설정합니다.\\nTAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\\nTavilySearchResults\\n설명\\n\\nTavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\\n포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\\n현재 이벤트에 대한 질문에 답변할 때 유용합니다.\\n\\n주요 매개변수\\n\\nmax_results (int): 반환할 최대 검색 결과 수 (기본값: 5)\\nsearch_depth (str): 검색 깊이 (\"basic\" 또는 \"advanced\")\\ninclude_domains (List[str]): 검색 결과에 포함할 도메인 목록\\nexclude_domains (List[str]): 검색 결과에서 제외할 도메인 목록\\ninclude_answer (bool): 원본 쿼리에 대한 짧은 답변 포함 여부\\ninclude_raw_content (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부\\ninclude_images (bool): 쿼리 관련 이미지 목록 포함 여부\\n\\n반환 값\\n\\n검색 결과를 포함하는 JSON 형식의 문자열(url, content) 혹은 아래의 주석을 해제하고 발급받은 API 키를 입력합니다.\\n\\n```python\\nimport os\\nos.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\"\\n```\\n```python\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\n도구 생성\\ntool = TavilySearchResults(\\n    max_results=6,\\n    include_answer=True,\\n    include_raw_content=True,\\n    # include_images=True,\\n    # search_depth=\"advanced\", # or \"basic\"\\n    include_domains=[\"github.io\", \"wikidocs.net\"],\\n    # exclude_domains = []\\n)\\n```\\n```python\\n도구 실행\\ntool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})\\n```\\n[\\n{\\'url\\': \\'https://teddylee777.github.io/langchain/langchain-agent/\\',\\n\\'content\\': \\'태그:\\\\nAgent,\\\\nAPI KEY,\\\\nFAISS,\\\\nLangChain,\\\\nLangSmith,\\\\nmemory,\\\\nOpenAI,\\\\nPython,\\\\nRetriever,\\\\nTavily Search,\\\\ntools,\\\\n검색도구,\\\\n랭체인,\\\\n에이전트\\\\n카테고리:\\\\nlangchain\\\\n업데이트: 2024년 02월 09일\\\\n참고\\\\nLangChain RAG 파헤치기: 다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n④ 메모리 추가하기\\\\n앞서 언급했듯이, 이 에이전트는 상태가 없습니다. LangChain 한국어 튜토리얼\\\\n바로가기 👀\\\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\\\n2024년 02월 09일\\\\n41 분 소요\\\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 📍 전체 템플릿 코드\\\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n마무리입니다!\\\\n 문서 기반 QA 시스템 설계 방법 - 심화편\\\\n2024년 02월 06일\\\\n22 분 소요\\\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\\\n\\'}, \\n{\\'url\\': \\'https://13akstjq.github.io/TIL/post/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4\\',  \\'content\\': \\'Memory. 원래 코드는 그대로 작동합니다. Langchain의 다양한 메모리 유형 목록에 대한 링크가 깨져 있어 찾아보았습니다. ... tools=toolkit, verbose=True) agent_executor\\\\xa0...\\'}, \\n{\\'url\\': \\'https://wikidocs.net/233351\\',  \\'content\\': \\'또한 LangChain은 포맷하는 동안 렌더링할 메시지를 완전히 제어할 수 있는 MessagePlaceholder 를 제공합니다. 메시지 프롬프트 템플릿에 어떤 역할을 사용해야 할지 확실\\\\xa0...\\'}, \\n{\\'url\\': \\'https://ncsoft.github.io/ncresearch/f4a00ed849299e3c91fb3244e74ea7f9b974ebb7\\',  \\'content\\': \\'Jun 23, 2023 · LangChain은 이런 LLM을 좀 더 쉽게 사용할 수 있도록 개념들을 추상화하여, LLM을 사용하면서 편리할만한 패턴들을 규격화시킨 프레임워크입니다. 이 글\\\\xa0...\\'}, \\n{\\'url\\': \\'https://13akstjq.github.io/TIL/post/2024-07-12-GenAIwithPythonLLMvsAgents\\',  \\'content\\': \\'Jul 12, 2024 · 주요 라이브러리는 다음과 같습니다: LangChain — 거의 모든 LLM 기능을 포함하는 매쉬업 프레임워크입니다. Agent가 낮은 수준에서 코딩되어야 하는 경\\\\xa0...\\'}, \\n{\\'url\\': \\'https://wikidocs.net/234282\\',  \\'content\\': \\'Mar 19, 2024 · langchain 은 언어 모델과 관련된 다양한 기능을 제공하는 라이브러리로, 이 중 검색 도구 생성 기능은 데이터 검색 및 처리 작업을 용이하게 한다.\\'}]\\n추가된 TavilySearch 도구 (커스텀 구현)\\nTavily 검색 API에서 사용되는 주요 파라미터들에 대한 설명\\n기본 검색 설정\\n\\nquery (str): 검색하고자 하는 키워드나 문장\\nsearch_depth (str): 검색의 상세도. \"basic\"(기본) 또는 \"advanced\"(고급) 중 선택\\ntopic (str): 검색 주제 분야. \"general\"(일반) 또는 \"news\"(뉴스) 중 선택\\ndays (int): 검색 결과의 최신성. 지정된 일수 이내의 결과만 반환\\nmax_results (int): 반환받을 최대 검색 결과 수\\n\\n도메인 필터링\\n\\ninclude_domains (list): 검색 결과에 반드시 포함할 도메인 목록\\nexclude_domains (list): 검색 결과에서 제외할 도메인 목록\\n\\n결과 상세 설정\\n\\ninclude_answer (bool): API가 생성한 답변 포함 여부\\ninclude_raw_content (bool): 웹페이지의 원본 HTML 콘텐츠 포함 여부\\ninclude_images (bool): 관련 이미지 정보 포함 여부\\nformat_output (bool): 검색 결과의 포맷팅 적용 여부\\n\\n기타\\n\\n**kwargs: 추가적인 키워드 인자. API의 향후 업데이트나 특수 기능에 사용될 수 있음\\n\\n```bash\\n!pip install -qU langchain-teddynote\\n```\\n```python\\nfrom langchain_teddynote.tools.tavily import TavilySearch\\n기본 예제\\ntavily_tool = TavilySearch()\\ninclude_domains 사용 예제\\n특정 도메인만 포함하여 검색\\ntavily_tool_with_domains = TavilySearch(include_domains=[\"github.io\", \"naver.com\"])\\nexclude_domains 사용 예제\\n특정 도메인을 제외하고 검색\\ntavily_tool_exclude = TavilySearch(exclude_domains=[\"ads.com\", \"spam.com\"])\\n다양한 파라미터를 사용한 검색 예제\\nresult1 = tavily_tool.search(\\n    query=\"유튜버 테디노트에 대해서 알려줘\",  # 검색 쿼리\\n    search_depth=\"advanced\",  # 고급 검색 수준\\n    topic=\"general\",  # 일반 주제\\n    days=7,  # 최근 7일 내 결과\\n    max_results=10,  # 최대 10개 결과\\n    include_answer=True,  # 답변 포함\\n    include_raw_content=True,  # 원본 콘텐츠 포함\\n    include_images=True,  # 이미지 포함\\n    format_output=True,  # 결과 포맷팅\\n)\\n뉴스 검색 예제\\nresult2 = tavily_tool.search(\\n    query=\"최신 AI 기술 동향\",  # 검색 쿼리\\n    search_depth=\"basic\",  # 기본 검색 수준\\n    topic=\"news\",  # 뉴스 주제\\n    days=3,  # 최근 3일 내 결과\\n    max_results=5,  # 최대 5개 결과\\n    include_answer=False,  # 답변 미포함\\n    include_raw_content=False,  # 원본 콘텐츠 미포함\\n    include_images=False,  # 이미지 미포함\\n    format_output=True,  # 결과 포맷팅\\n)\\n특정 도메인 포함 검색 예제\\nresult3 = tavily_tool_with_domains.search(\\n    query=\"파이썬 프로그래밍 팁\",  # 검색 쿼리\\n    search_depth=\"advanced\",  # 고급 검색 수준\\n    max_results=3,  # 최대 3개 결과\\n)\\n특정 도메인 제외 검색 예제\\nresult4 = tavily_tool_exclude.search(\\n    query=\"건강한 식단\",  # 검색 쿼리\\n    search_depth=\"basic\",  # 기본 검색 수준\\n    days=30,  # 최근 30일 내 결과\\n    max_results=7,  # 최대 7개 결과\\n)\\n결과 출력\\nprint(\"기본 검색 결과:\", result1)\\nprint(\"뉴스 검색 결과:\", result2)\\nprint(\"특정 도메인 포함 검색 결과:\", result3)\\nprint(\"특정 도메인 제외 검색 결과:\", result4)\\n```\\nImage 생성 도구 (DALL-E)\\n\\nDallEAPIWrapper 클래스: OpenAI의 DALL-E 이미지 생성기를 위한 래퍼(wrapper)입니다.\\n\\n이 도구를 사용하면 DALL-E API를 쉽게 통합하여 텍스트 기반 이미지 생성 기능을 구현할 수 있습니다. 다양한 설정 옵션을 통해 유연하고 강력한 이미지 생성 도구로 활용할 수 있습니다.\\n주요 속성\\n\\n\\nmodel: 사용할 DALL-E 모델 이름 (기본값: \"dall-e-2\", \"dall-e-3\")\\n\\n\\nn: 생성할 이미지 수 (기본값: 1)\\n\\n\\nsize: 생성할 이미지 크기\\n\\n\\n\"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\\n\\n\\n\"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\\n\\n\\nstyle: 생성될 이미지의 스타일 (기본값: \"natural\", \"vivid\")\\n\\n\\nquality: 생성될 이미지의 품질 (기본값: \"standard\", \"hd\")\\n\\n\\nmax_retries: 생성 시 최대 재시도 횟수\\n\\n\\n주요 기능\\n\\nDALL-E API를 사용하여 텍스트 설명에 기반한 이미지 생성\\n\\n흐름 정리\\n다음은 DALL-E Image Generator 를 사용하여 이미지를 생성하는 예제입니다.\\n이번에는 DallEAPIWrapper 를 사용하여 이미지를 생성해 보겠습니다.\\n이때 입력 프롬프트는 LLM 모델에게 이미지를 생성하는 프롬프트를 작성하도록 요청합니다.\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_openai import ChatOpenAI\\nChatOpenAI 모델 초기화\\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\\nDALL-E 이미지 생성을 위한 프롬프트 템플릿 정의\\nprompt = PromptTemplate.from_template(\\n    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\\n    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\\n    \"Output should be less than 1000 characters. Write in English only.\"\\n    \"Image Description: \\\\n{image_desc}\",\\n)\\n프롬프트, LLM, 출력 파서를 연결하는 체인 생성\\nchain = prompt | llm | StrOutputParser()\\n체인 실행\\nimage_prompt = chain.invoke(\\n    {\"image_desc\": \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"}\\n)\\n이미지 프롬프트 출력\\nprint(image_prompt)\\n```\\nCreate a neo-classical painting that satirically depicts a group of people intently gazing at their smartphones. The scene should be set in a grand, classical architectural setting with marble columns and intricate details reminiscent of ancient Greece. The figures, dressed in elegant, flowing garments typical of neo-classical art, exhibit exaggerated expressions of fascination and distraction as they interact with their devices. Incorporate elements such as classical sculptures or frescoes in the background that contrast with the modernity of the smartphones. Use soft, natural lighting to enhance the scene, and include subtle hints of irony, perhaps by depicting traditional activities or conversations happening just out of focus, symbolizing the disconnect in modern life.\\n그럼, 이전에 생성한 이미지 프롬프트를 DallEAPIWrapper 에 입력하여 이미지를 생성해 보겠습니다.\\n```python\\nDALL-E API 래퍼 가져오기\\nfrom langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\\nfrom IPython.display import Image\\nDALL-E API 래퍼 초기화\\nmodel: 사용할 DALL-E 모델 버전\\nsize: 생성할 이미지 크기\\nquality: 이미지 품질\\nn: 생성할 이미지 수\\ndalle = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\\n질문\\nquery = \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"\\n이미지 생성 및 URL 받기\\nchain.invoke()를 사용하여 이미지 설명을 DALL-E 프롬프트로 변환\\ndalle.run()을 사용하여 실제 이미지 생성\\nimage_url = dalle.run(chain.invoke({\"image_desc\": query}))\\n생성된 이미지를 표시합니다.\\nImage(url=image_url, width=500)\\n```\\n\\n사용자 정의 도구(Custom Tool)\\nLangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\\n이를 위해서는 langchain.tools 모듈에서 제공하는 tool 데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool 데코레이터\\n이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\\n사용 방법\\n\\n함수 위에 @tool 데코레이터 적용\\n필요에 따라 데코레이터 매개변수 설정\\n\\n이 데코레이터를 사용하면 일반 Python 함수를 강력한 도구로 쉽게 변환할 수 있으며, 자동화된 문서화와 유연한 인터페이스 생성이 가능합니다.\\n```python\\nfrom langchain.tools import tool\\n데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool\\ndef add_numbers(a: int, b: int) -> int:\\n    \"\"\"Add two numbers\"\"\"\\n    return a + b\\n@tool\\ndef multiply_numbers(a: int, b: int) -> int:\\n    \"\"\"Multiply two numbers\"\"\"\\n    return a * b\\n```\\n```python\\n도구 실행\\nadd_numbers.invoke({\"a\": 3, \"b\": 4})\\n```\\n7\\n```python\\n도구 실행\\nmultiply_numbers.invoke({\"a\": 3, \"b\": 4})\\n```\\n12\\n구글 뉴스기사 검색 도구\\nlangchain-teddynote 패키지에서 제공하는 GoogleNews 도구를 사용하여 구글 뉴스기사를 검색하는 도구입니다.\\n참고\\n\\nAPI 키가 필요하지 않습니다. (RSS 피드를 사용하기 때문)\\n\\nnews.google.com 에서 제공하는 뉴스기사를 검색하는 도구입니다.\\n설명\\n\\n구글 뉴스 검색 API를 사용하여 최신 뉴스를 검색합니다.\\n키워드를 기반으로 뉴스를 검색할 수 있습니다.\\n최신 뉴스를 검색할 수 있습니다.\\n\\n주요 매개변수\\n\\nk (int): 반환할 최대 검색 결과 수 (기본값: 5)\\n\\n사용하기 전 패키지를 업데이트 해주세요.\\n```python\\n!pip install -qU langchain-teddynote\\n```\\n```python\\nfrom langchain_teddynote.tools import GoogleNews\\n도구 생성\\nnews_tool = GoogleNews()\\n```\\n```python\\n최신 뉴스 검색\\nnews_tool.search_latest(k=5)\\n```\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMid0FVX3lxTE82ZXF0N1g0Tmc0SjdGcTN4T0ZJWE9UTXRJdDJxb0VxVUhUb2t5elFjWjlvcnZJMDZFWVpDMVBsdnozUlRKbXJkSGJSTTJITkF5bTBLekJyN0dYV3E1UDhMN0FQSWo0WGsxMW1Hay1GeWZfaHhkTXVZ0gF3QVVfeXFMTkg4WXh0Xy15VEV2YzRKLUljZEwzZzFlajV1bmdmZ2MzcnRvaGJGbmxmM3gtZFp5a2c4a3Q2cmxPUjNNRTFDdmtzN2h4NnNSUHk3ME9zY3NldmRwWlZqd1UzdzVJOHBwbUxQVTJCdnVrMHhpLTYwdW8?oc=5\\',  \\'content\\': \"\\'조건부 휴학\\' 승인‥복귀 안 하면 제적·유급 - MBC 뉴스\"}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMid0FVX3lxTE5pWEhEY0Jxd08zQjZ0N3ZySEVDSThRN0NLd2YzV3BRdTZGdmpxbXdpMmZmeE12VWc4cmdQWlJYWGpHMnpua044Y3FmRVZMcEsyU0NsajgycjVlNWI4cU5IRkpGT1ZZbS02LWdpbFhLRVREUGdfQXBV0gFmQVVfeXFMTmU0aU5WV25HTldZSS1JZHVmQmdYZk9PcmtWbXFzNGtLYVRQUmVtMmVHcXN3RHlTem5maENOVFNsYXhlQTFHb0NJM3RsSzg1a1FqeWMyRVJ1Mmp4MUFLZTBRbllyY0FB?oc=5\\',  \\'content\\': \\'‘한동훈 공격 사주 의혹’ 김대남, SGI서울보증 감사직 사퇴 - 동아일보\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMikAFBVV95cUxQWFRFelJKZTdwSjVDRFloNUpNbF83dVVLOXpYSnZ3Y25BS25jQUFWdFhuYklic0lQT0VwbWw0WEU5MGs2Wm83Y1lQLTBJakRrQTFFTEp0T09tNzY3NVpyVGhyRjdpQ2FNV3pVOVZZaFpwNEl1Q2Rtb1laa2VDY1o0NFRxZXFPOWFyUmF3X0NLa1jSAaQBQVVfeXFMTWJJX040anAtYl9lbzRidURVSDNmMGFlc0t4eHZDa1ZJWk14Z0tzNDd4dzBRTFVyZm5HTFEtMHFSajhkci1PUmlYTTdoUC11RUdNMDhWaW9JakszTlhDWkdmNFc2Vk9BUXVoZEt4dG1qOWVicUs1dXd6cWdtSHh6T2ZpcU9CQXFvMHp3ZElpQ1dZYUloT1NpUDVNMTRGcFNmeDBPVlQ?oc=5\\',  \\'content\\': \\'尹 \"한·필리핀 FTA 발효되면 무역·투자 획기적 확대될 것\" - 조선일보\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMickFVX3lxTE1Pd3RtbzBFOEpERWlqYk5ISnIzaldRQ21XdHcyaW5zMWpQYmNWR2ZveHVLRExncDhNX2oweTBFZlhrUV90OVVodE9xaVhqVFc0S1BFWUs5VFFILUExTVdpWE10QUlKbnBrSEgtSkN6Skl3UQ?oc=5\\',  \\'content\\': \\'문다혜씨 혈중알코올농도 0.149%…걸어서 파출소 이동 - 한겨레\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMickFVX3lxTE9HTU1JajFMeVRPZkViX2EwZkc3R05ySDdWbEJhdjN0QzNnTmo2V0RMbjZQcFI1YTl6dnVHMlpKU0RsODNuRW5TeWYwczBhNjdkNkhiRzc3cWtzQ0wtaHkwU1MwYjNQc2tLX3RjZjdhbEZpQQ?oc=5\\',  \\'content\\': \\'[단독] 김건희 결혼 후에도 ‘도이치 주식매수’ 정황…흔들리는 윤 해명 - 한겨레\\'}]\\n```python\\n키워드로 뉴스 검색\\nnews_tool.search_by_keyword(\"AI 투자\", k=5)\\n```\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\\',  \\'content\\': \\'글로벌 CEO들 \"향후 3년 무조건 AI 투자···직원도 더 뽑을 것\" - 네이트 뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\\',  \\'content\\': \\'MIT 경제학자 \"10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것\" - AI타임스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\\',  \\'content\\': \\'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiYEFVX3lxTE5XdlFLT29uWXR5SmRpS054Z2J3VldjZlJETHJIeVRPakFUNEdiOHh0N0hOU21BRTlHN1haRTBUYnlKUEdVdXJWUWdTbG9vczFHeDNPRG1hSkc2NzVRaVBLQQ?oc=5\\',  \\'content\\': \\'글로벌 CEO 64% “AI에 최우선 투자” - 아시아경제\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiZEFVX3lxTE02VVREUUxSRExwUkxkY0NGZEw0Z0x0N3FHenZvTXN4TEVlRHEzWEF0SGo4N1Y2Zm8xTE5TaGZDZzNubzFrTmxoUVRiNG9WN01wY2hyUGVyZ1lCS05ua1FLWXYwRTk?oc=5\\',  \\'content\\': \\'“AI시대 투자 키워드는 ‘공급 부족’...초반 5년이 기회” [헤럴드 머니페스타 2024] - 헤럴드미디어\\'}]\\n```python\\nfrom langchain_teddynote.tools import GoogleNews\\nfrom langchain.tools import tool\\nfrom typing import List, Dict\\n키워드로 뉴스 검색하는 도구 생성\\n@tool\\ndef search_keyword(query: str) -> List[Dict[str, str]]:\\n    \"\"\"Look up news by keyword\"\"\"\\n    print(query)\\n    news_tool = GoogleNews()\\n    return news_tool.search_by_keyword(query, k=5)\\n```\\n```python\\n실행 결과\\nsearch_keyword.invoke({\"query\": \"AI 투자\"})\\n```\\nAI 투자\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\\',  \\'content\\': \\'글로벌 CEO들 \"향후 3년 무조건 AI 투자···직원도 더 뽑을 것\" - 네이트 뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\\',  \\'content\\': \\'MIT 경제학자 \"10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것\" - AI타임스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\\',  \\'content\\': \\'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiYEFVX3lxTE5XdlFLT29uWXR5SmRpS054Z2J3VldjZlJETHJIeVRPakFUNEdiOHh0N0hOU21BRTlHN1haRTBUYnlKUEdVdXJWUWdTbG9vczFHeDNPRG1hSkc2NzVRaVBLQQ?oc=5\\',  \\'content\\': \\'글로벌 CEO 64% “AI에 최우선 투자” - 아시아경제\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiZEFVX3lxTE02VVREUUxSRExwUkxkY0NGZEw0Z0x0N3FHenZvTXN4TEVlRHEzWEF0SGo4N1Y2Zm8xTE5TaGZDZzNubzFrTmxoUVRiNG9WN01wY2hyUGVyZ1lCS05ua1FLWXYwRTk?oc=5\\',  \\'content\\': \\'“AI시대 투자 키워드는 ‘공급 부족’...초반 5년이 기회” [헤럴드 머니페스타 2024] - 헤럴드미디어\\'}]\\nLast edited by : Oct. 22, 2024, 9:53 p.m.\\nComment 0 Feedback\\n※ Commenting requires login. (Or use the feedback.)\\n\\nPrev : CH16 에이전트(Agent)\\nNext : 02. 도구 바인딩(Binding Tools)\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send\\n×\\nReport a comment.\\nDo you want to report this comment? Report a comment is available for the following situations:\\n\\nContains spam or advertising\\nContains inappropriate content, such as profanity, libel, or personal information.\\nIf it contains copyrighted material\\n\\nPlease enter the reason for the report.\\n※ Your report will be forwarded to an administrator who will review it and take appropriate action. Reports are anonymous and your information will not be disclosed.\\nClose Send'},\n",
       " {'title': '01. 도구(Tools) -  - LangChain 한국어 튜토리얼',\n",
       "  'url': 'https://wikidocs.net/262582',\n",
       "  'content': '```python\\nimport os\\nos.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\"\\n```\\n```python\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\n도구 생성\\ntool = TavilySearchResults(\\n    max_results=6,\\n    include_answer=True,\\n    include_raw_content=True,\\n    # include_images=True,\\n    # search_depth=\"advanced\", # or \"basic\"\\n    include_domains=[\"github.io\", \"wikidocs.net\"],\\n    # exclude_domains = []\\n)\\n```\\n```python\\n도구 실행\\ntool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})\\n```\\n[ [...] <랭체인LangChain 노트> - Lang…\\nCH16 에이전트(Agent)\\n\\n01. 도구(Tools)\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n01. 도구(Tools)\\n도구 (Tools)\\n도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\\nLangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\\nLangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.\\n\\nLangChain 통합된 도구 리스트 [...] 사용자 정의 도구(Custom Tool)\\nLangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\\n이를 위해서는 langchain.tools 모듈에서 제공하는 tool 데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool 데코레이터\\n이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\\n사용 방법\\n\\n함수 위에 @tool 데코레이터 적용\\n필요에 따라 데코레이터 매개변수 설정',\n",
       "  'score': 0.8467682,\n",
       "  'raw_content': '01. 도구(Tools) - <랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n<랭체인LangChain 노트> - Lang…\\nCH16 에이전트(Agent)\\n\\n01. 도구(Tools)\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n01. 도구(Tools)\\n도구 (Tools)\\n도구(Tool)는 에이전트, 체인 또는 LLM이 외부 세계와 상호작용하기 위한 인터페이스입니다.\\nLangChain 에서 기본 제공하는 도구를 사용하여 쉽게 도구를 활용할 수 있으며, 사용자 정의 도구(Custom Tool) 를 쉽게 구축하는 것도 가능합니다.\\nLangChain 에 통합된 도구 리스트는 아래 링크에서 확인할 수 있습니다.\\n\\nLangChain 통합된 도구 리스트\\n\\n```python\\nAPI 키를 환경변수로 관리하기 위한 설정 파일\\nfrom dotenv import load_dotenv\\nAPI 키 정보 로드\\nload_dotenv()\\n```\\nTrue\\n```python\\nLangSmith 추적을 설정합니다. https://smith.langchain.com\\n!pip install -qU langchain-teddynote\\nfrom langchain_teddynote import logging\\n프로젝트 이름을 입력합니다.\\nlogging.langsmith(\"CH15-Tools\")\\n```\\nLangSmith 추적을 시작합니다.\\n[프로젝트명]\\nCH15-Tools\\n```python\\nimport warnings\\n경고 메시지 무시\\nwarnings.filterwarnings(\"ignore\")\\n```\\n빌트인 도구(built-in tools)\\n랭체인에서 제공하는 사전에 정의된 도구(tool) 와 툴킷(toolkit) 을 사용할 수 있습니다.\\ntool 은 단일 도구를 의미하며, toolkit 은 여러 도구를 묶어서 하나의 도구로 사용할 수 있습니다.\\n관련 도구는 아래의 링크에서 참고하실 수 있습니다.\\n참고\\n\\nLangChain Tools/Toolkits\\n\\nPython REPL 도구\\n이 도구는 Python 코드를 REPL(Read-Eval-Print Loop) 환경에서 실행하기 위한 두 가지 주요 클래스를 제공합니다 - PythonREPLTool\\n설명\\n\\nPython 셸 환경을 제공합니다.\\n유효한 Python 명령어를 입력으로 받아 실행합니다.\\n결과를 보려면 print(...) 함수를 사용해야 합니다.\\n\\n주요 특징\\n\\nsanitize_input: 입력을 정제하는 옵션 (기본값: True)\\npython_repl: PythonREPL 인스턴스 (기본값: 전역 범위에서 실행)\\n\\n사용 방법\\n\\nPythonREPLTool 인스턴스 생성\\nrun 또는 arun, invoke 메서드를 사용하여 Python 코드 실행\\n\\n입력 정제\\n\\n입력 문자열에서 불필요한 공백, 백틱, \\'python\\' 키워드 등을 제거합니다.\\n\\n```python\\nfrom langchain_experimental.tools import PythonREPLTool\\n파이썬 코드를 실행하는 도구를 생성합니다.\\npython_tool = PythonREPLTool()\\n```\\n```python\\n파이썬 코드를 실행하고 결과를 반환합니다.\\nprint(python_tool.invoke(\"print(100 + 200)\"))\\n```\\n300\\n아래는 LLM 에게 파이썬 코드를 작성하도록 요청하고 결과를 반환하는 예제입니다.\\n흐름 정리\\n\\nLLM 모델에게 특정 작업을 수행하는 Python 코드를 작성하도록 요청합니다.\\n작성된 코드를 실행하여 결과를 얻습니다.\\n결과를 출력합니다.\\n\\n```python\\nfrom langchain_openai import ChatOpenAI\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableLambda\\n파이썬 코드를 실행하고 중간 과정을 출력하고 도구 실행 결과를 반환하는 함수\\ndef print_and_execute(code, debug=True):\\n    if debug:\\n        print(\"CODE:\")\\n        print(code)\\n    return python_tool.invoke(code)\\n파이썬 코드를 작성하도록 요청하는 프롬프트\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\\n            \"system\",\\n            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\\n            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\\n        ),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\nLLM 모델 생성\\nllm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\\n프롬프트와 LLM 모델을 사용하여 체인 생성\\nchain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)\\n```\\n```python\\n결과 출력\\nprint(chain.invoke(\"로또 번호 생성기를 출력하는 코드를 작성하세요.\"))\\n```\\nCODE:\\nimport random\\ndef generate_lotto_numbers():\\n    return sorted(random.sample(range(1, 46), 6))\\nprint(generate_lotto_numbers())\\n[14, 17, 18, 22, 23, 37]\\n검색 API 도구\\nTavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: TavilySearchResults와 TavilyAnswer.\\nAPI 키 발급 주소\\n\\nhttps://app.tavily.com/\\n\\n발급한 API 키를 환경변수에 설정합니다.\\n.env 파일에 아래와 같이 설정합니다.\\nTAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\\nTavilySearchResults\\n설명\\n\\nTavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\\n포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\\n현재 이벤트에 대한 질문에 답변할 때 유용합니다.\\n\\n주요 매개변수\\n\\nmax_results (int): 반환할 최대 검색 결과 수 (기본값: 5)\\nsearch_depth (str): 검색 깊이 (\"basic\" 또는 \"advanced\")\\ninclude_domains (List[str]): 검색 결과에 포함할 도메인 목록\\nexclude_domains (List[str]): 검색 결과에서 제외할 도메인 목록\\ninclude_answer (bool): 원본 쿼리에 대한 짧은 답변 포함 여부\\ninclude_raw_content (bool): 각 사이트의 정제된 HTML 콘텐츠 포함 여부\\ninclude_images (bool): 쿼리 관련 이미지 목록 포함 여부\\n\\n반환 값\\n\\n검색 결과를 포함하는 JSON 형식의 문자열(url, content) 혹은 아래의 주석을 해제하고 발급받은 API 키를 입력합니다.\\n\\n```python\\nimport os\\nos.environ[\"TAVILY_API_KEY\"] = \"TAVILY API 키 입력\"\\n```\\n```python\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\n도구 생성\\ntool = TavilySearchResults(\\n    max_results=6,\\n    include_answer=True,\\n    include_raw_content=True,\\n    # include_images=True,\\n    # search_depth=\"advanced\", # or \"basic\"\\n    include_domains=[\"github.io\", \"wikidocs.net\"],\\n    # exclude_domains = []\\n)\\n```\\n```python\\n도구 실행\\ntool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})\\n```\\n[\\n{\\'url\\': \\'https://teddylee777.github.io/langchain/langchain-agent/\\',\\n\\'content\\': \\'태그:\\\\nAgent,\\\\nAPI KEY,\\\\nFAISS,\\\\nLangChain,\\\\nLangSmith,\\\\nmemory,\\\\nOpenAI,\\\\nPython,\\\\nRetriever,\\\\nTavily Search,\\\\ntools,\\\\n검색도구,\\\\n랭체인,\\\\n에이전트\\\\n카테고리:\\\\nlangchain\\\\n업데이트: 2024년 02월 09일\\\\n참고\\\\nLangChain RAG 파헤치기: 다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n④ 메모리 추가하기\\\\n앞서 언급했듯이, 이 에이전트는 상태가 없습니다. LangChain 한국어 튜토리얼\\\\n바로가기 👀\\\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\\\n2024년 02월 09일\\\\n41 분 소요\\\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 📍 전체 템플릿 코드\\\\n다음의 추적 링크에서 자세한 단계별 수행 결과를 확인할 수 있습니다\\\\nLangSmith 추적\\\\n마무리입니다!\\\\n 문서 기반 QA 시스템 설계 방법 - 심화편\\\\n2024년 02월 06일\\\\n22 분 소요\\\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\\\n\\'}, \\n{\\'url\\': \\'https://13akstjq.github.io/TIL/post/2024-07-09-LLMStudyDiaryComprehensiveReviewofLangChainPart4\\',  \\'content\\': \\'Memory. 원래 코드는 그대로 작동합니다. Langchain의 다양한 메모리 유형 목록에 대한 링크가 깨져 있어 찾아보았습니다. ... tools=toolkit, verbose=True) agent_executor\\\\xa0...\\'}, \\n{\\'url\\': \\'https://wikidocs.net/233351\\',  \\'content\\': \\'또한 LangChain은 포맷하는 동안 렌더링할 메시지를 완전히 제어할 수 있는 MessagePlaceholder 를 제공합니다. 메시지 프롬프트 템플릿에 어떤 역할을 사용해야 할지 확실\\\\xa0...\\'}, \\n{\\'url\\': \\'https://ncsoft.github.io/ncresearch/f4a00ed849299e3c91fb3244e74ea7f9b974ebb7\\',  \\'content\\': \\'Jun 23, 2023 · LangChain은 이런 LLM을 좀 더 쉽게 사용할 수 있도록 개념들을 추상화하여, LLM을 사용하면서 편리할만한 패턴들을 규격화시킨 프레임워크입니다. 이 글\\\\xa0...\\'}, \\n{\\'url\\': \\'https://13akstjq.github.io/TIL/post/2024-07-12-GenAIwithPythonLLMvsAgents\\',  \\'content\\': \\'Jul 12, 2024 · 주요 라이브러리는 다음과 같습니다: LangChain — 거의 모든 LLM 기능을 포함하는 매쉬업 프레임워크입니다. Agent가 낮은 수준에서 코딩되어야 하는 경\\\\xa0...\\'}, \\n{\\'url\\': \\'https://wikidocs.net/234282\\',  \\'content\\': \\'Mar 19, 2024 · langchain 은 언어 모델과 관련된 다양한 기능을 제공하는 라이브러리로, 이 중 검색 도구 생성 기능은 데이터 검색 및 처리 작업을 용이하게 한다.\\'}]\\n추가된 TavilySearch 도구 (커스텀 구현)\\nTavily 검색 API에서 사용되는 주요 파라미터들에 대한 설명\\n기본 검색 설정\\n\\nquery (str): 검색하고자 하는 키워드나 문장\\nsearch_depth (str): 검색의 상세도. \"basic\"(기본) 또는 \"advanced\"(고급) 중 선택\\ntopic (str): 검색 주제 분야. \"general\"(일반) 또는 \"news\"(뉴스) 중 선택\\ndays (int): 검색 결과의 최신성. 지정된 일수 이내의 결과만 반환\\nmax_results (int): 반환받을 최대 검색 결과 수\\n\\n도메인 필터링\\n\\ninclude_domains (list): 검색 결과에 반드시 포함할 도메인 목록\\nexclude_domains (list): 검색 결과에서 제외할 도메인 목록\\n\\n결과 상세 설정\\n\\ninclude_answer (bool): API가 생성한 답변 포함 여부\\ninclude_raw_content (bool): 웹페이지의 원본 HTML 콘텐츠 포함 여부\\ninclude_images (bool): 관련 이미지 정보 포함 여부\\nformat_output (bool): 검색 결과의 포맷팅 적용 여부\\n\\n기타\\n\\n**kwargs: 추가적인 키워드 인자. API의 향후 업데이트나 특수 기능에 사용될 수 있음\\n\\n```bash\\n!pip install -qU langchain-teddynote\\n```\\n```python\\nfrom langchain_teddynote.tools.tavily import TavilySearch\\n기본 예제\\ntavily_tool = TavilySearch()\\ninclude_domains 사용 예제\\n특정 도메인만 포함하여 검색\\ntavily_tool_with_domains = TavilySearch(include_domains=[\"github.io\", \"naver.com\"])\\nexclude_domains 사용 예제\\n특정 도메인을 제외하고 검색\\ntavily_tool_exclude = TavilySearch(exclude_domains=[\"ads.com\", \"spam.com\"])\\n다양한 파라미터를 사용한 검색 예제\\nresult1 = tavily_tool.search(\\n    query=\"유튜버 테디노트에 대해서 알려줘\",  # 검색 쿼리\\n    search_depth=\"advanced\",  # 고급 검색 수준\\n    topic=\"general\",  # 일반 주제\\n    days=7,  # 최근 7일 내 결과\\n    max_results=10,  # 최대 10개 결과\\n    include_answer=True,  # 답변 포함\\n    include_raw_content=True,  # 원본 콘텐츠 포함\\n    include_images=True,  # 이미지 포함\\n    format_output=True,  # 결과 포맷팅\\n)\\n뉴스 검색 예제\\nresult2 = tavily_tool.search(\\n    query=\"최신 AI 기술 동향\",  # 검색 쿼리\\n    search_depth=\"basic\",  # 기본 검색 수준\\n    topic=\"news\",  # 뉴스 주제\\n    days=3,  # 최근 3일 내 결과\\n    max_results=5,  # 최대 5개 결과\\n    include_answer=False,  # 답변 미포함\\n    include_raw_content=False,  # 원본 콘텐츠 미포함\\n    include_images=False,  # 이미지 미포함\\n    format_output=True,  # 결과 포맷팅\\n)\\n특정 도메인 포함 검색 예제\\nresult3 = tavily_tool_with_domains.search(\\n    query=\"파이썬 프로그래밍 팁\",  # 검색 쿼리\\n    search_depth=\"advanced\",  # 고급 검색 수준\\n    max_results=3,  # 최대 3개 결과\\n)\\n특정 도메인 제외 검색 예제\\nresult4 = tavily_tool_exclude.search(\\n    query=\"건강한 식단\",  # 검색 쿼리\\n    search_depth=\"basic\",  # 기본 검색 수준\\n    days=30,  # 최근 30일 내 결과\\n    max_results=7,  # 최대 7개 결과\\n)\\n결과 출력\\nprint(\"기본 검색 결과:\", result1)\\nprint(\"뉴스 검색 결과:\", result2)\\nprint(\"특정 도메인 포함 검색 결과:\", result3)\\nprint(\"특정 도메인 제외 검색 결과:\", result4)\\n```\\nImage 생성 도구 (DALL-E)\\n\\nDallEAPIWrapper 클래스: OpenAI의 DALL-E 이미지 생성기를 위한 래퍼(wrapper)입니다.\\n\\n이 도구를 사용하면 DALL-E API를 쉽게 통합하여 텍스트 기반 이미지 생성 기능을 구현할 수 있습니다. 다양한 설정 옵션을 통해 유연하고 강력한 이미지 생성 도구로 활용할 수 있습니다.\\n주요 속성\\n\\n\\nmodel: 사용할 DALL-E 모델 이름 (기본값: \"dall-e-2\", \"dall-e-3\")\\n\\n\\nn: 생성할 이미지 수 (기본값: 1)\\n\\n\\nsize: 생성할 이미지 크기\\n\\n\\n\"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\\n\\n\\n\"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\\n\\n\\nstyle: 생성될 이미지의 스타일 (기본값: \"natural\", \"vivid\")\\n\\n\\nquality: 생성될 이미지의 품질 (기본값: \"standard\", \"hd\")\\n\\n\\nmax_retries: 생성 시 최대 재시도 횟수\\n\\n\\n주요 기능\\n\\nDALL-E API를 사용하여 텍스트 설명에 기반한 이미지 생성\\n\\n흐름 정리\\n다음은 DALL-E Image Generator 를 사용하여 이미지를 생성하는 예제입니다.\\n이번에는 DallEAPIWrapper 를 사용하여 이미지를 생성해 보겠습니다.\\n이때 입력 프롬프트는 LLM 모델에게 이미지를 생성하는 프롬프트를 작성하도록 요청합니다.\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_openai import ChatOpenAI\\nChatOpenAI 모델 초기화\\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\\nDALL-E 이미지 생성을 위한 프롬프트 템플릿 정의\\nprompt = PromptTemplate.from_template(\\n    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\\n    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\\n    \"Output should be less than 1000 characters. Write in English only.\"\\n    \"Image Description: \\\\n{image_desc}\",\\n)\\n프롬프트, LLM, 출력 파서를 연결하는 체인 생성\\nchain = prompt | llm | StrOutputParser()\\n체인 실행\\nimage_prompt = chain.invoke(\\n    {\"image_desc\": \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"}\\n)\\n이미지 프롬프트 출력\\nprint(image_prompt)\\n```\\nCreate a neo-classical painting that satirically depicts a group of people intently gazing at their smartphones. The scene should be set in a grand, classical architectural setting with marble columns and intricate details reminiscent of ancient Greece. The figures, dressed in elegant, flowing garments typical of neo-classical art, exhibit exaggerated expressions of fascination and distraction as they interact with their devices. Incorporate elements such as classical sculptures or frescoes in the background that contrast with the modernity of the smartphones. Use soft, natural lighting to enhance the scene, and include subtle hints of irony, perhaps by depicting traditional activities or conversations happening just out of focus, symbolizing the disconnect in modern life.\\n그럼, 이전에 생성한 이미지 프롬프트를 DallEAPIWrapper 에 입력하여 이미지를 생성해 보겠습니다.\\n```python\\nDALL-E API 래퍼 가져오기\\nfrom langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\\nfrom IPython.display import Image\\nDALL-E API 래퍼 초기화\\nmodel: 사용할 DALL-E 모델 버전\\nsize: 생성할 이미지 크기\\nquality: 이미지 품질\\nn: 생성할 이미지 수\\ndalle = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\\n질문\\nquery = \"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"\\n이미지 생성 및 URL 받기\\nchain.invoke()를 사용하여 이미지 설명을 DALL-E 프롬프트로 변환\\ndalle.run()을 사용하여 실제 이미지 생성\\nimage_url = dalle.run(chain.invoke({\"image_desc\": query}))\\n생성된 이미지를 표시합니다.\\nImage(url=image_url, width=500)\\n```\\n\\n사용자 정의 도구(Custom Tool)\\nLangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\\n이를 위해서는 langchain.tools 모듈에서 제공하는 tool 데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool 데코레이터\\n이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\\n사용 방법\\n\\n함수 위에 @tool 데코레이터 적용\\n필요에 따라 데코레이터 매개변수 설정\\n\\n이 데코레이터를 사용하면 일반 Python 함수를 강력한 도구로 쉽게 변환할 수 있으며, 자동화된 문서화와 유연한 인터페이스 생성이 가능합니다.\\n```python\\nfrom langchain.tools import tool\\n데코레이터를 사용하여 함수를 도구로 변환합니다.\\n@tool\\ndef add_numbers(a: int, b: int) -> int:\\n    \"\"\"Add two numbers\"\"\"\\n    return a + b\\n@tool\\ndef multiply_numbers(a: int, b: int) -> int:\\n    \"\"\"Multiply two numbers\"\"\"\\n    return a * b\\n```\\n```python\\n도구 실행\\nadd_numbers.invoke({\"a\": 3, \"b\": 4})\\n```\\n7\\n```python\\n도구 실행\\nmultiply_numbers.invoke({\"a\": 3, \"b\": 4})\\n```\\n12\\n구글 뉴스기사 검색 도구\\nlangchain-teddynote 패키지에서 제공하는 GoogleNews 도구를 사용하여 구글 뉴스기사를 검색하는 도구입니다.\\n참고\\n\\nAPI 키가 필요하지 않습니다. (RSS 피드를 사용하기 때문)\\n\\nnews.google.com 에서 제공하는 뉴스기사를 검색하는 도구입니다.\\n설명\\n\\n구글 뉴스 검색 API를 사용하여 최신 뉴스를 검색합니다.\\n키워드를 기반으로 뉴스를 검색할 수 있습니다.\\n최신 뉴스를 검색할 수 있습니다.\\n\\n주요 매개변수\\n\\nk (int): 반환할 최대 검색 결과 수 (기본값: 5)\\n\\n사용하기 전 패키지를 업데이트 해주세요.\\n```python\\n!pip install -qU langchain-teddynote\\n```\\n```python\\nfrom langchain_teddynote.tools import GoogleNews\\n도구 생성\\nnews_tool = GoogleNews()\\n```\\n```python\\n최신 뉴스 검색\\nnews_tool.search_latest(k=5)\\n```\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMid0FVX3lxTE82ZXF0N1g0Tmc0SjdGcTN4T0ZJWE9UTXRJdDJxb0VxVUhUb2t5elFjWjlvcnZJMDZFWVpDMVBsdnozUlRKbXJkSGJSTTJITkF5bTBLekJyN0dYV3E1UDhMN0FQSWo0WGsxMW1Hay1GeWZfaHhkTXVZ0gF3QVVfeXFMTkg4WXh0Xy15VEV2YzRKLUljZEwzZzFlajV1bmdmZ2MzcnRvaGJGbmxmM3gtZFp5a2c4a3Q2cmxPUjNNRTFDdmtzN2h4NnNSUHk3ME9zY3NldmRwWlZqd1UzdzVJOHBwbUxQVTJCdnVrMHhpLTYwdW8?oc=5\\',  \\'content\\': \"\\'조건부 휴학\\' 승인‥복귀 안 하면 제적·유급 - MBC 뉴스\"}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMid0FVX3lxTE5pWEhEY0Jxd08zQjZ0N3ZySEVDSThRN0NLd2YzV3BRdTZGdmpxbXdpMmZmeE12VWc4cmdQWlJYWGpHMnpua044Y3FmRVZMcEsyU0NsajgycjVlNWI4cU5IRkpGT1ZZbS02LWdpbFhLRVREUGdfQXBV0gFmQVVfeXFMTmU0aU5WV25HTldZSS1JZHVmQmdYZk9PcmtWbXFzNGtLYVRQUmVtMmVHcXN3RHlTem5maENOVFNsYXhlQTFHb0NJM3RsSzg1a1FqeWMyRVJ1Mmp4MUFLZTBRbllyY0FB?oc=5\\',  \\'content\\': \\'‘한동훈 공격 사주 의혹’ 김대남, SGI서울보증 감사직 사퇴 - 동아일보\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMikAFBVV95cUxQWFRFelJKZTdwSjVDRFloNUpNbF83dVVLOXpYSnZ3Y25BS25jQUFWdFhuYklic0lQT0VwbWw0WEU5MGs2Wm83Y1lQLTBJakRrQTFFTEp0T09tNzY3NVpyVGhyRjdpQ2FNV3pVOVZZaFpwNEl1Q2Rtb1laa2VDY1o0NFRxZXFPOWFyUmF3X0NLa1jSAaQBQVVfeXFMTWJJX040anAtYl9lbzRidURVSDNmMGFlc0t4eHZDa1ZJWk14Z0tzNDd4dzBRTFVyZm5HTFEtMHFSajhkci1PUmlYTTdoUC11RUdNMDhWaW9JakszTlhDWkdmNFc2Vk9BUXVoZEt4dG1qOWVicUs1dXd6cWdtSHh6T2ZpcU9CQXFvMHp3ZElpQ1dZYUloT1NpUDVNMTRGcFNmeDBPVlQ?oc=5\\',  \\'content\\': \\'尹 \"한·필리핀 FTA 발효되면 무역·투자 획기적 확대될 것\" - 조선일보\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMickFVX3lxTE1Pd3RtbzBFOEpERWlqYk5ISnIzaldRQ21XdHcyaW5zMWpQYmNWR2ZveHVLRExncDhNX2oweTBFZlhrUV90OVVodE9xaVhqVFc0S1BFWUs5VFFILUExTVdpWE10QUlKbnBrSEgtSkN6Skl3UQ?oc=5\\',  \\'content\\': \\'문다혜씨 혈중알코올농도 0.149%…걸어서 파출소 이동 - 한겨레\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMickFVX3lxTE9HTU1JajFMeVRPZkViX2EwZkc3R05ySDdWbEJhdjN0QzNnTmo2V0RMbjZQcFI1YTl6dnVHMlpKU0RsODNuRW5TeWYwczBhNjdkNkhiRzc3cWtzQ0wtaHkwU1MwYjNQc2tLX3RjZjdhbEZpQQ?oc=5\\',  \\'content\\': \\'[단독] 김건희 결혼 후에도 ‘도이치 주식매수’ 정황…흔들리는 윤 해명 - 한겨레\\'}]\\n```python\\n키워드로 뉴스 검색\\nnews_tool.search_by_keyword(\"AI 투자\", k=5)\\n```\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\\',  \\'content\\': \\'글로벌 CEO들 \"향후 3년 무조건 AI 투자···직원도 더 뽑을 것\" - 네이트 뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\\',  \\'content\\': \\'MIT 경제학자 \"10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것\" - AI타임스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\\',  \\'content\\': \\'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiYEFVX3lxTE5XdlFLT29uWXR5SmRpS054Z2J3VldjZlJETHJIeVRPakFUNEdiOHh0N0hOU21BRTlHN1haRTBUYnlKUEdVdXJWUWdTbG9vczFHeDNPRG1hSkc2NzVRaVBLQQ?oc=5\\',  \\'content\\': \\'글로벌 CEO 64% “AI에 최우선 투자” - 아시아경제\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiZEFVX3lxTE02VVREUUxSRExwUkxkY0NGZEw0Z0x0N3FHenZvTXN4TEVlRHEzWEF0SGo4N1Y2Zm8xTE5TaGZDZzNubzFrTmxoUVRiNG9WN01wY2hyUGVyZ1lCS05ua1FLWXYwRTk?oc=5\\',  \\'content\\': \\'“AI시대 투자 키워드는 ‘공급 부족’...초반 5년이 기회” [헤럴드 머니페스타 2024] - 헤럴드미디어\\'}]\\n```python\\nfrom langchain_teddynote.tools import GoogleNews\\nfrom langchain.tools import tool\\nfrom typing import List, Dict\\n키워드로 뉴스 검색하는 도구 생성\\n@tool\\ndef search_keyword(query: str) -> List[Dict[str, str]]:\\n    \"\"\"Look up news by keyword\"\"\"\\n    print(query)\\n    news_tool = GoogleNews()\\n    return news_tool.search_by_keyword(query, k=5)\\n```\\n```python\\n실행 결과\\nsearch_keyword.invoke({\"query\": \"AI 투자\"})\\n```\\nAI 투자\\n[{\\'url\\': \\'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB1VDRjTlIxeHRjV3NKaERHMFJLOFNpUlNUVnZzQ0JvOUpISVE2cW9rbTZPVU9lQXZuUURJNHF0aDZyaDdQM0F5NFhsc0NrN1dHNEZz?oc=5\\',  \\'content\\': \\'글로벌 CEO들 \"향후 3년 무조건 AI 투자···직원도 더 뽑을 것\" - 네이트 뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiakFVX3lxTE9BQUtjd3pDS1dXRkZQTlo4Y2w2d2laZFFQRXdsbGlCMFRTcWJYLTNLaksxbFlnYzk3clVnYlFxZF93U2xubXY1VVhBTDQ2SDhLbm9hcDdXQ3prTlJtV0VCYTFINmNRbjR5N3c?oc=5\\',  \\'content\\': \\'MIT 경제학자 \"10년간 AI에 영향받을 직업은 5% 불과...기업은 투자비만 날리게 될 것\" - AI타임스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiW0FVX3lxTE9oenZObVAzOV9hbUliNGhkLTBXZXZrTGpvT0ljcXlpWE5leld2b3RLbUJFTFRtZnU4c0VFaC1oYkVvTTdESEZCYmZUTDJSMFFYdGVXeXN3OVdRTEE?oc=5\\',  \\'content\\': \\'MS, 이탈리아에 AI 인프라 6조4천억 투자 결정 - 연합뉴스\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiYEFVX3lxTE5XdlFLT29uWXR5SmRpS054Z2J3VldjZlJETHJIeVRPakFUNEdiOHh0N0hOU21BRTlHN1haRTBUYnlKUEdVdXJWUWdTbG9vczFHeDNPRG1hSkc2NzVRaVBLQQ?oc=5\\',  \\'content\\': \\'글로벌 CEO 64% “AI에 최우선 투자” - 아시아경제\\'}, {\\'url\\': \\'https://news.google.com/rss/articles/CBMiZEFVX3lxTE02VVREUUxSRExwUkxkY0NGZEw0Z0x0N3FHenZvTXN4TEVlRHEzWEF0SGo4N1Y2Zm8xTE5TaGZDZzNubzFrTmxoUVRiNG9WN01wY2hyUGVyZ1lCS05ua1FLWXYwRTk?oc=5\\',  \\'content\\': \\'“AI시대 투자 키워드는 ‘공급 부족’...초반 5년이 기회” [헤럴드 머니페스타 2024] - 헤럴드미디어\\'}]\\nLast edited by : Oct. 22, 2024, 9:53 p.m.\\nComment 0 Feedback\\n※ Commenting requires login. (Or use the feedback.)\\n\\nPrev : CH16 에이전트(Agent)\\nNext : 02. 도구 바인딩(Binding Tools)\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send\\n×\\nReport a comment.\\nDo you want to report this comment? Report a comment is available for the following situations:\\n\\nContains spam or advertising\\nContains inappropriate content, such as profanity, libel, or personal information.\\nIf it contains copyrighted material\\n\\nPlease enter the reason for the report.\\n※ Your report will be forwarded to an administrator who will review it and take appropriate action. Reports are anonymous and your information will not be disclosed.\\nClose Send'},\n",
       " {'title': 'LangChain - Machine Learning Studies - Jerome Boyer',\n",
       "  'url': 'https://jbcodeforce.github.io/ML-studies/coding/langchain/',\n",
       "  'content': 'LangChain is a open-source framework for developing applications powered by large language models, connecting them to external data sources, and manage',\n",
       "  'score': 0.7434107},\n",
       " {'title': 'LangChain Memory Types: A Comprehensive Guide for Engineers',\n",
       "  'url': 'https://thinhdanggroup.github.io/langchain-memories/',\n",
       "  'content': 'LangChain is a powerful platform for creating conversational AI applications using language models and chains. One of the key features of LangChain is its memory module, which provides various types of memory components for managing and manipulating chat histories and information. Memory Types in LangChain',\n",
       "  'score': 0.7050753},\n",
       " {'title': 'LangGraph Quickstart',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/',\n",
       "  'content': \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features:\",\n",
       "  'score': 0.6773251,\n",
       "  'raw_content': 'Learn the basics\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLearn the basics\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nDeployment\\n\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\n\\n[ ] \\nTutorials\\nTutorials\\n\\n\\n[ ] \\nQuick Start\\nQuick Start\\n\\nQuick Start\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nLocal Deploy\\n\\nCloud Deploy\\n\\n\\n\\nChatbots\\n\\nRAG\\nAgent Architectures\\nEvaluation & Analysis\\nExperimental\\nLangGraph Platform\\n\\n\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nLLMS-txt\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\nHome\\n\\nGuides\\nTutorials\\nQuick Start\\n\\n\\n🚀 LangGraph Quickstart¶\\nIn this tutorial, we will build a support chatbot in LangGraph that can:\\n✅ Answer common questions by searching the web\\n✅ Maintain conversation state across calls\\n✅ Route complex queries to a human for review\\n✅ Use custom state to control its behavior\\n✅ Rewind and explore alternative conversation paths\\nWe\\'ll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way. Let’s dive in! 🌟\\nSetup¶\\nFirst, install the required packages and configure your environment:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-2)%pip install -U langgraph langsmith langchain_anthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-1)importgetpass\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-2)importos\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-5)def_set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-10)_set_env(\"ANTHROPIC_API_KEY\")\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started here.\\nPart 1: Build a Basic Chatbot¶\\nWe\\'ll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We\\'ll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-6)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-9)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-10)    # Messages have the type \"list\". The `add_messages` function\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-11)    # in the annotation defines how this state key should be updated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-12)    # (in this case, it appends messages to the list, rather than overwriting them)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-13)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-16)graph_builder = StateGraph(State)\\nAPI Reference: StateGraph | START | END | add_messages\\nOur graph can now handle two key tasks:\\n\\nEach node can receive the current State as input and output an update to the state.\\nUpdates to messages will be appended to the existing list rather than overwriting it, thanks to the prebuilt add_messages function used with the Annotated syntax.\\n\\n\\nConcept\\nWhen defining a graph, the first step is to define its State. The State includes the graph\\'s schema and reducer functions that handle state updates. In our example, State is a TypedDict with one key: messages. The add_messages reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. Learn more about state, reducers, and related concepts in this guide.\\n\\nNext, add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-3)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-6)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-7)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-10)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-11)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-12)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-13)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic\\nNotice how the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\nThe add_messages function in our State will append the llm\\'s response messages to whatever messages are already in the state.\\nNext, add an entry point. This tells our graph where to start its work each time we run it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-4-1)graph_builder.add_edge(START, \"chatbot\")\\nSimilarly, set a finish point. This instructs the graph \"any time this node is run, you can exit.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-5-1)graph_builder.add_edge(\"chatbot\", END)\\nFinally, we\\'ll want to be able to run our graph. To do so, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-6-1)graph = graph_builder.compile()\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-7)    pass\\n\\nNow let\\'s run the chatbot!\\nTip: You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\".\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-1)defstream_graph_updates(user_input: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-2)    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-3)        for value in event.values():\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-4)            print(\"Assistant:\", value[\"messages\"][-1].content)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-7)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-8)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-9)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-10)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-11)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-12)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-14)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-15)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-16)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-17)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-18)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-19)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-20)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-2)Goodbye!\\nCongratulations! You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above at the provided link.\\nHowever, you may have noticed that the bot\\'s knowledge is limited to what\\'s in its training data. In the next part, we\\'ll add a web search tool to expand the bot\\'s knowledge and make it more capable.\\nBelow is the full code for this section for your reference:\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-6)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-20)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-21)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-24)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-25)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-26)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-27)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-28)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-29)graph_builder.set_finish_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-30)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | StateGraph | add_messages\\nPart 2: 🛠️ Enhancing the Chatbot with Tools¶\\nTo handle queries our chatbot can\\'t answer \"from memory\", we\\'ll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\\nRequirements¶\\nBefore we start, make sure you have the necessary packages installed and API keys set up:\\nFirst, install the requirements to use the Tavily Search Engine, and set your TAVILY_API_KEY.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-2)%pip install -U tavily-python langchain_community\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-12-1)_set_env(\"TAVILY_API_KEY\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-13-1)TAVILY_API_KEY:  ········\\nNext, define the tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-1)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-3)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-4)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-5)tool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\nAPI Reference: TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-1)[{\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-2)  \\'content\\': \\'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...\\'},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-3) {\\'url\\': \\'https://saksheepatil05.medium.com/demystifying-langgraph-a-beginner-friendly-dive-into-langgraph-concepts-5ffe890ddac0\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-4)  \\'content\\': \\'Nodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.\\'}]\\nThe results are page summaries our chat bot can use to answer questions.\\nNext, we\\'ll start defining our graph. The following is all the same as in Part 1, except we have added bind_tools on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-6)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-18)# Modification: tell the LLM which tools it can call\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-19)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-22)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-23)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-26)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic | StateGraph | START | END | add_messages\\nNext we need to create a function to actually run the tools if they are called. We\\'ll do this by adding the tools to a new node.\\nBelow, we implement a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nWe will later replace this with LangGraph\\'s prebuilt ToolNode to speed things up, but building it ourselves first is instructive.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-1)importjson\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-3)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-6)classBasicToolNode:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-7)\"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-9)    def__init__(self, tools: list) -> None:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-10)        self.tools_by_name = {tool.name: tool for tool in tools}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-12)    def__call__(self, inputs: dict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-13)        if messages := inputs.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-14)            message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-15)        else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-16)            raise ValueError(\"No message found in input\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-17)        outputs = []\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-18)        for tool_call in message.tool_calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-19)            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-20)                tool_call[\"args\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-21)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-22)            outputs.append(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-23)                ToolMessage(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-24)                    content=json.dumps(tool_result),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-25)                    name=tool_call[\"name\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-26)                    tool_call_id=tool_call[\"id\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-27)                )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-28)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-29)        return {\"messages\": outputs}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-32)tool_node = BasicToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-33)graph_builder.add_node(\"tools\", tool_node)\\nAPI Reference: ToolMessage\\nWith the tool node added, we can define the conditional_edges.\\nRecall that edges route the control flow from one node to the next. Conditional edges usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nBelow, call define a router function called route_tools, that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next.\\nThe condition will route to tools if tool calls are present and END if not.\\nLater, we will replace this with the prebuilt tools_condition to be more concise, but implementing it ourselves first makes things more clear.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-1)defroute_tools(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-2)    state: State,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-3)):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-4)\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-5)    Use in the conditional_edge to route to the ToolNode if the last message\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-6)    has tool calls. Otherwise, route to the end.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-7)    \"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-8)    if isinstance(state, list):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-9)        ai_message = state[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-10)    elif messages := state.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-11)        ai_message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-12)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-13)        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-14)    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-15)        return \"tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-16)    return END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-19)# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-20)# it is fine directly responding. This conditional routing defines the main agent loop.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-21)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-22)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-23)    route_tools,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-24)    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-25)    # It defaults to the identity function, but if you\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-26)    # want to use a node named something else apart from \"tools\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-27)    # You can update the value of the dictionary to something else\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-28)    # e.g., \"tools\": \"my_tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-29)    {\"tools\": \"tools\", END: END},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-31)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-32)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-33)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-34)graph = graph_builder.compile()\\nNotice that conditional edges start from a single node. This tells the graph \"any time the \\'chatbot\\' node runs, either go to \\'tools\\' if it calls a tool, or end the loop if it responds directly.\\nLike the prebuilt tools_condition, our function returns the END string if no tool calls are made. When the graph transitions to END, it has no more tasks to complete and ceases execution. Because the condition can return END, we don\\'t need to explicitly set a finish_point this time. Our graph already has a way to finish!\\nLet\\'s visualize the graph we\\'ve built. The following function has some additional dependencies to run that are unimportant for this tutorial.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-7)    pass\\n\\nNow we can ask the bot questions outside its training data.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-1)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-2)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-3)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-4)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-5)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-6)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-8)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-9)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-10)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-11)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-12)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-13)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-14)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-1)Assistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-2)Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-3)Assistant: Based on the search results, I can provide you with information about LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-5)1. Purpose:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-12)   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-13)   - Controllability: It offers enhanced control over the application flow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-14)   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-16)4. Use Cases:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-17)   LangGraph can be used for various applications, including:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-18)   - Conversational agents\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-19)   - Complex task automation\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-20)   - Custom LLM-backed experiences\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-22)5. Integration:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-23)   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-25)6. Significance:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-26)   LangGraph is described as setting the foundation for building and scaling AI workloads. It\\'s positioned as a key tool in the next chapter of LLM-based application development, particularly in the realm of agentic AI.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-28)7. Availability:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-29)   LangGraph is open-source and available on GitHub, which suggests that developers can access and contribute to its codebase.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-31)8. Comparison to Other Frameworks:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-32)   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-34)LangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-35)Goodbye!\\nCongrats! You\\'ve created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace.\\nOur chatbot still can\\'t remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we\\'ll add memory to address this.\\nThe full code for the graph we\\'ve created in this section is reproduced below, replacing our BasicToolNode for the prebuilt ToolNode, and our route_tools condition with the prebuilt tools_condition\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-8)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-42)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | add_messages | ToolNode | tools_condition\\nPart 3: Adding Memory to the Chatbot¶\\nOur chatbot can now use tools to answer user questions, but it doesn\\'t remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\\nLangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off.\\nWe will see later that checkpointing is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But before we get too ahead of ourselves, let\\'s add checkpointing to enable multi-turn conversations.\\nTo get started, create a MemorySaver checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-1)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-3)memory = MemorySaver()\\nAPI Reference: MemorySaver\\nNotice we\\'re using an in-memory checkpointer. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect to your own DB.\\nNext define the graph. Now that you\\'ve already built your own BasicToolNode, we\\'ll replace it with LangGraph\\'s prebuilt ToolNode and tools_condition, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-8)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-41)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nFinally, compile the graph with the provided checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-25-1)graph = graph_builder.compile(checkpointer=memory)\\nNotice the connectivity of the graph hasn\\'t changed since Part 2. All we are doing is checkpointing the State as the graph works through each node.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-7)    pass\\n\\nNow you can interact with your bot! First, pick a thread to use as the key for this conversation.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-27-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\nNext, call your chat bot.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-1)user_input = \"Hi there! My name is Will.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-3)Hi there! My name is Will.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-6)Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\\nNote: The config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({\\'messages\\': []}).\\nLet\\'s ask a followup: see if it remembers your name.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-1)user_input = \"Remember my name?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-6)Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\\nNotice that we aren\\'t using an external list for memory: it\\'s all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what\\'s going on.\\nDon\\'t believe me? Try this using a different config.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-1)# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-3)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-4)    {\"configurable\": {\"thread_id\": \"2\"}},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-5)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-7)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-8)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-6)I apologize, but I don\\'t have any previous context or memory of your name. As an AI assistant, I don\\'t retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\\nNotice that the only change we\\'ve made is to modify the thread_id in the config. See this call\\'s LangSmith trace for comparison.\\nBy now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph\\'s state for a given config at any time, call get_state(config).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-2)snapshot\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-35-1)StateSnapshot(values={\\'messages\\': [HumanMessage(content=\\'Hi there! My name is Will.\\', additional_kwargs={}, response_metadata={}, id=\\'8c1ca919-c553-4ebf-95d4-b59a2d61e078\\'), AIMessage(content=\"Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01WTQebPhNwmMrmmWojJ9KXJ\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 405, \\'output_tokens\\': 32}}, id=\\'run-58587b77-8c82-41e6-8a90-d62c444a261d-0\\', usage_metadata={\\'input_tokens\\': 405, \\'output_tokens\\': 32, \\'total_tokens\\': 437}), HumanMessage(content=\\'Remember my name?\\', additional_kwargs={}, response_metadata={}, id=\\'daba7df6-ad75-4d6b-8057-745881cea1ca\\'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}, next=(), config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-93e0-6acc-8004-f2ac846575d2\\'}}, metadata={\\'source\\': \\'loop\\', \\'writes\\': {\\'chatbot\\': {\\'messages\\': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}}, \\'step\\': 4, \\'parents\\': {}}, created_at=\\'2024-09-27T19:30:10.820758+00:00\\', parent_config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-859f-6206-8003-e1bd3c264b8f\\'}}, tasks=())\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-36-1)snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-37-1)()\\nThe snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an END state, so next is empty.\\nCongratulations! Your chatbot can now maintain conversation state across sessions thanks to LangGraph\\'s checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph\\'s checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory.\\nIn the next part, we\\'ll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\\nCheck out the code snippet below to review our graph from this section.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-9)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-11)fromlanggraph.prebuiltimport ToolNode\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-42)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-43)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | add_messages | ToolNode\\nPart 4: Human-in-the-loop¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. interrupt is ergonomically similar to Python\\'s built-in input(), with some caveats. We demonstrate an example below.\\nFirst, start with our existing code from Part 3. We will make one change, which is to add a simple human_assistance tool accessible to the chatbot. This tool uses interrupt to receive information from a human.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-16)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-17)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-20)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-24)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-25)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-26)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-27)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-30)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-31)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-32)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-33)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-36)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-37)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-38)    # Because we will be interrupting during tool execution,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-39)    # we disable parallel tool calling to avoid repeating any\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-40)    # tool invocations when we resume.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-41)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-42)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-45)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-47)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-48)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-49)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-50)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-51)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-52)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-53))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-54)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-55)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\n\\nTip\\nCheck out the Human-in-the-loop section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\n\\nWe compile the graph with a checkpointer, as before:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-1)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-3)graph = graph_builder.compile(checkpointer=memory)\\nVisualizing the graph, we recover the same layout as before. We have just added a tool!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-7)    pass\\n\\nLet\\'s now prompt the chatbot with a question that will engage the new human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-1)user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-2)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-3)I need some expert guidance for building an AI agent. Could you request assistance for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-6)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-8)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-9) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-11)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\nThe chatbot generated a tool call, but then execution has been interrupted! Note that if we inspect the graph state, we see that it stopped at the tools node:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-2)snapshot.next\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-45-1)(\\'tools\\',)\\nLet\\'s take a closer look at the human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-1)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-2)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-3)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-4)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-5)    return human_response[\"data\"]\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on our choice of checkpointer-- so if we are persisting with Postgres, we can resume at any time as long as the database is alive. Here we are persisting with the in-memory checkpointer, so we can resume any time as long as our Python kernel is running.\\nTo resume execution, we pass a Command object containing data expected by the tool. The format of this data can be customized based on our needs. Here, we just need a dict with a key \"data\":\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-1)human_response = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-2)    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-3)    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-6)human_command = Command(resume={\"data\": human_response})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-3)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-5)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-6) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-8)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-10)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-12)We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-15)Thank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-17)The experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-21)1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-23)2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-25)3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-27)To get started with LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-29)1. Search for the official LangGraph documentation or website to learn more about its features and how to use it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-30)2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-31)3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-33)If you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOur input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongrats! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nHuman-in-the-loop workflows enable a variety of new workflows and user experiences. Check out this section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-12)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-15)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-16)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-19)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-22)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-23)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-24)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-25)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-26)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-29)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-30)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-31)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-32)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-35)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-36)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-37)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-38)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-40)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-41)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-43)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-44)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-46)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-47)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-48)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-49))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-50)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-51)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-52)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-53)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-54)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 5: Customizing State¶\\nSo far, we\\'ve relied on a simple state with one entry-- a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. Here we will demonstrate a new scenario, in which the chatbot is using its search tool to find specific information, and forwarding them to a human for review. Let\\'s have the chatbot research the birthday of an entity. We will add name and birthday keys to the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-5)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-8)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-9)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-10)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-11)    birthday: str\\nAPI Reference: add_messages\\nAdding this information to the state makes it easily accessible by other graph nodes (e.g., a downstream node that stores or processes the information), as well as the graph\\'s persistence layer.\\nHere, we will populate the state keys inside of our human_assistance tool. This allows a human to review the information before it is stored in the state. We will again use Command, this time to issue a state update from inside our tool. Read more about use cases for Command here.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-1)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-2)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-4)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-7)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-8)# Note that because we are generating a ToolMessage for a state update, we\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-9)# generally require the ID of the corresponding tool call. We can use\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-10)# LangChain\\'s InjectedToolCallId to signal that this argument should not\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-11)# be revealed to the model in the tool\\'s schema.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-12)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-13)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-14)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-15)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-16)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-17)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-18)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-19)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-20)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-21)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-22)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-23)    # If the information is correct, update the state as-is.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-24)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-25)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-26)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-27)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-28)    # Otherwise, receive information from the human reviewer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-29)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-30)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-31)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-32)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-34)    # This time we explicitly update the state with a ToolMessage inside\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-35)    # the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-36)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-37)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-38)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-39)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-40)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-41)    # We return a Command object in the tool to update our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-42)    return Command(update=state_update)\\nAPI Reference: ToolMessage | InjectedToolCallId | tool | Command | interrupt\\nOtherwise, the rest of our graph is the same:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-2)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-4)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-6)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-9)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-10)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-11)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-12)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-15)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-16)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-17)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-18)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-21)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-22)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-24)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-25)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-27)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-28)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-29)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-31)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-32)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-34)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-35)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | MemorySaver | StateGraph | START | END | ToolNode | tools_condition\\nLet\\'s prompt our application to look up the \"birthday\" of the LangGraph library. We will direct the chatbot to reach out to the human_assistance tool once it has the required information. Note that setting name and birthday in the arguments for the tool, we force the chatbot to generate proposals for these fields.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-1)user_input = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-2)    \"Can you look up when LangGraph was released? \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-3)    \"When you have the answer, use the human_assistance tool for review.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-5)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-7)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-8)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-9)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-10)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-11))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-12)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-13)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-14)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-3)Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-6)[{\\'text\\': \"Certainly! I\\'ll start by searching for information about LangGraph\\'s release date using the Tavily search function. Then, I\\'ll use the human_assistance tool for review.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JoXQPgTVJXiuma8xMVwqAi\\', \\'input\\': {\\'query\\': \\'LangGraph release date\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-8)  tavily_search_results_json (toolu_01JoXQPgTVJXiuma8xMVwqAi)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-9) Call ID: toolu_01JoXQPgTVJXiuma8xMVwqAi\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-11)    query: LangGraph release date\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-15)[{\"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024 (Oct \\'24) Edit: Since the launch of LangGraph Cloud, we now have multiple deployment options alongside LangGraph Studio - which now fall under LangGraph Platform. LangGraph Cloud is synonymous with our Cloud SaaS deployment option.\"}, {\"url\": \"https://changelog.langchain.com/announcements/langgraph-cloud-deploy-at-scale-monitor-carefully-iterate-boldly\", \"content\": \"LangChain - Changelog | ☁ 🚀 LangGraph Cloud: Deploy at scale, monitor LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog Sign up for our newsletter to stay up to date DATE: The LangChain Team LangGraph LangGraph Cloud ☁ 🚀 LangGraph Cloud: Deploy at scale, monitor carefully, iterate boldly DATE: June 27, 2024 AUTHOR: The LangChain Team LangGraph Cloud is now in closed beta, offering scalable, fault-tolerant deployment for LangGraph agents. LangGraph Cloud also includes a new playground-like studio for debugging agent failure modes and quick iteration: Join the waitlist today for LangGraph Cloud. And to learn more, read our blog post announcement or check out our docs. Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-18)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-19)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-20)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-21) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-22)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-23)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-24)    birthday: 2023-01-01\\nWe\\'ve hit the interrupt in the human_assistance tool again. In this case, the chatbot failed to identify the correct date, so we can supply it:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-1)human_command = Command(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-2)    resume={\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-3)        \"name\": \"LangGraph\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-4)        \"birthday\": \"Jan 17, 2024\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-5)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-3)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-5)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-6) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-8)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-9)    birthday: 2023-01-01\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-11)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-13)Made a correction: {\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-16)Thank you for the human assistance. I can now provide you with the correct information about LangGraph\\'s release date.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph\\'s original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It\\'s worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-58-1){\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nThis makes them easily accessible to downstream nodes (e.g., a node that further processes or stores the information).\\nManually updating state¶\\nLangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), we can manually override a key using graph.update_state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-59-1)graph.update_state(config, {\"name\": \"LangGraph (library)\"})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-1){\\'configurable\\': {\\'thread_id\\': \\'1\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-2)  \\'checkpoint_ns\\': \\'\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-3)  \\'checkpoint_id\\': \\'1efd4ec5-cf69-6352-8006-9278f1730162\\'}}\\nIf we call graph.get_state, we can see the new value is reflected:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-62-1){\\'name\\': \\'LangGraph (library)\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nManual state updates will even generate a trace in LangSmith. If desired, they can also be used to control human-in-the-loop workflows, as described in this guide. Use of the interrupt function is generally recommended instead, as it allows data to be transmitted in a human-in-the-loop interaction independently of state updates.\\nCongratulations! You\\'ve added custom keys to the state to facilitate a more complex workflow, and learned how to generate state updates from inside tools.\\nWe\\'re almost done with the tutorial, but there is one more concept we\\'d like to review before finishing that connects checkpointing and state updates.\\nThis section\\'s code is reproduced below for your reference.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-5)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-6)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-7)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-9)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-10)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-11)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-12)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-17)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-18)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-19)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-20)    birthday: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-24)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-25)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-26)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-27)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-28)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-29)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-30)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-31)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-32)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-33)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-34)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-35)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-36)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-37)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-38)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-39)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-40)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-41)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-42)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-44)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-45)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-46)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-47)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-48)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-49)    return Command(update=state_update)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-50)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-51)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-52)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-53)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-54)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-55)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-56)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-57)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-58)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-59)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-60)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-61)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-62)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-63)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-64)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-65)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-66)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-67)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-68)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-69)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-70)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-71)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-72)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-73))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-74)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-75)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-76)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-77)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-78)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | ToolMessage | InjectedToolCallId | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 6: Time Travel¶\\nIn a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and control future responses.\\nBut what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant\\'s work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\\nYou can create both of these experiences and more using LangGraph\\'s built-in \"time travel\" functionality.\\nIn this section, you will \"rewind\" your graph by fetching a checkpoint using the graph\\'s get_state_history method. You can then resume execution at this previous point in time.\\nFor this, let\\'s use the simple chatbot with tools from Part 3:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-41)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-43)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-44)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nLet\\'s have our graph take a couple steps. Every step will be checkpointed in its state history:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-3)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-4)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-5)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-6)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-7)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-8)                    \"I\\'m learning LangGraph. \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-9)                    \"Could you do some research on it for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-10)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-11)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-12)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-13)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-14)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-15)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-16))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-17)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-18)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-19)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-3)I\\'m learning LangGraph. Could you do some research on it for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-6)[{\\'text\\': \"Certainly! I\\'d be happy to research LangGraph for you. To get the most up-to-date and accurate information, I\\'ll use the Tavily search engine to look this up. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BscbfJJB9EWJFqGrN6E54e\\', \\'input\\': {\\'query\\': \\'LangGraph latest information and features\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-8)  tavily_search_results_json (toolu_01BscbfJJB9EWJFqGrN6E54e)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-9) Call ID: toolu_01BscbfJJB9EWJFqGrN6E54e\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-11)    query: LangGraph latest information and features\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-15)[{\"url\": \"https://blockchain.news/news/langchain-new-features-upcoming-events-update\", \"content\": \"LangChain, a leading platform in the AI development space, has released its latest updates, showcasing new use cases and enhancements across its ecosystem. According to the LangChain Blog, the updates cover advancements in LangGraph Cloud, LangSmith\\'s self-improving evaluators, and revamped documentation for LangGraph.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-platform-announce/\", \"content\": \"With these learnings under our belt, we decided to couple some of our latest offerings under LangGraph Platform. LangGraph Platform today includes LangGraph Server, LangGraph Studio, plus the CLI and SDK. ... we added features in LangGraph Server to deliver on a few key value areas. Below, we\\'ll focus on these aspects of LangGraph Platform.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-18)Thank you for your patience. I\\'ve found some recent information about LangGraph for you. Let me summarize the key points:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-20)1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-22)2. Recent updates and features of LangGraph include:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-24)   a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren\\'t provided in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-26)   b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-27)      - LangGraph Server\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-28)      - LangGraph Studio\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-29)      - CLI (Command Line Interface)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-30)      - SDK (Software Development Kit)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-32)3. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren\\'t detailed in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-34)4. LangGraph Studio: This appears to be a new tool in the LangGraph ecosystem, likely providing a graphical interface for working with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-36)5. Documentation: The LangGraph documentation has been revamped, which should make it easier for learners like yourself to understand and use the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-38)6. Integration with LangSmith: While not directly part of LangGraph, LangSmith (another tool in the LangChain ecosystem) now features self-improving evaluators, which might be relevant if you\\'re using LangGraph as part of a larger LangChain project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-40)As you\\'re learning LangGraph, it would be beneficial to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-41)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-42)1. Check out the official LangChain documentation, especially the newly revamped LangGraph sections.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-43)2. Explore the different components of the LangGraph Platform (Server, Studio, CLI, and SDK) to see which best fits your learning needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-44)3. Keep an eye on LangGraph Cloud developments, as cloud-based solutions often provide an easier starting point for learners.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-45)4. Consider how LangGraph fits into the broader LangChain ecosystem, especially its interaction with tools like LangSmith.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-47)Is there any specific aspect of LangGraph you\\'d like to know more about? I\\'d be happy to do a more focused search on particular features or use cases.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-1)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-2)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-3)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-4)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-5)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-6)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-7)                    \"Ya that\\'s helpful. Maybe I\\'ll \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-8)                    \"build an autonomous agent with it!\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-9)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-10)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-11)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-12)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-13)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-14)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-15))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-16)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-17)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-18)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-3)Ya that\\'s helpful. Maybe I\\'ll build an autonomous agent with it!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-6)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-8)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-9) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-11)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-15)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-18)Great idea! Building an autonomous agent with LangGraph is definitely an exciting project. Based on the latest information I\\'ve found, here are some insights and tips for building autonomous agents with LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-20)1. Multi-Tool Agents: LangGraph is particularly well-suited for creating autonomous agents that can use multiple tools. This allows your agent to have a diverse set of capabilities and choose the right tool for each task.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-22)2. Integration with Large Language Models (LLMs): You can combine LangGraph with powerful LLMs like Gemini 2.0 to create more intelligent and capable agents. The LLM can serve as the \"brain\" of your agent, making decisions and generating responses.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-24)3. Workflow Management: LangGraph excels at managing complex, multi-step AI workflows. This is crucial for autonomous agents that need to break down tasks into smaller steps and execute them in the right order.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-26)4. Practical Tutorials Available: There are tutorials available that provide full code examples for building and running multi-tool agents. These can be incredibly helpful as you start your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-28)5. Langchain Integration: LangGraph is often used in conjunction with Langchain. This combination provides a powerful framework for building AI agents, offering features like memory management, tool integration, and prompt management.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-30)6. GitHub Resources: There are repositories available (like the one by anmolaman20) that provide comprehensive resources for building AI agents using Langchain and LangGraph. These can be valuable references as you develop your agent.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-32)7. Real-time Adaptation: LangGraph allows you to create agents that can think, reason, and adapt in real-time, which is crucial for truly autonomous behavior.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-34)8. Customization: You can equip your agent with specific tools tailored to your use case. For example, you might include tools for web searching, data analysis, or interacting with specific APIs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-36)To get started with your autonomous agent project:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-38)1. Familiarize yourself with LangGraph\\'s documentation and basic concepts.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-39)2. Look into tutorials that specifically deal with building autonomous agents, like the one mentioned from Towards Data Science.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-40)3. Decide on the specific capabilities you want your agent to have and identify the tools it will need.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-41)4. Start with a simple agent and gradually add complexity as you become more comfortable with the framework.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-42)5. Experiment with different LLMs to find the one that works best for your use case.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-43)6. Pay attention to how you structure the agent\\'s decision-making process and workflow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-44)7. Don\\'t forget to implement proper error handling and safety measures, especially if your agent will be interacting with external systems or making important decisions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-46)Building an autonomous agent is an iterative process, so be prepared to refine and improve your agent over time. Good luck with your project! If you need any more specific information as you progress, feel free to ask.\\nNow that we\\'ve had the agent take a couple steps, we can replay the full state history to see everything that occurred.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-1)to_replay = None\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-2)for state in graph.get_state_history(config):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-3)    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-4)    print(\"-\" * 80)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-5)    if len(state.values[\"messages\"]) == 6:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-6)        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-7)        to_replay = state\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-1)Num Messages:  8 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-2)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-3)Num Messages:  7 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-4)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-5)Num Messages:  6 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-6)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-7)Num Messages:  5 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-8)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-9)Num Messages:  4 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-10)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-11)Num Messages:  4 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-12)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-13)Num Messages:  3 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-14)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-15)Num Messages:  2 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-16)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-17)Num Messages:  1 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-18)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-19)Num Messages:  0 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-20)--------------------------------------------------------------------------------\\nNotice that checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread\\'s history. We\\'ve picked out to_replay as a state to resume from. This is the state after the chatbot node in the second graph invocation above.\\nResuming from this point should call the action node next.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-1)print(to_replay.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-2)print(to_replay.config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-1)(\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-2){\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1efd43e3-0c1f-6c4e-8006-891877d65740\\'}}\\nNotice that the checkpoint\\'s config (to_replay.config) contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph\\'s checkpointer to load the state from that moment in time. Let\\'s try it below:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-1)# The `checkpoint_id` in the `to_replay.config` corresponds to a state we\\'ve persisted to our checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-2)for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-3)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-4)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-3)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-5)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-6) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-8)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-10)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-12)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-15)Great idea! Building an autonomous agent with LangGraph is indeed an excellent way to apply and deepen your understanding of the technology. Based on the search results, I can provide you with some insights and resources to help you get started:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-17)1. Multi-Tool Agents:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-18)   LangGraph is well-suited for building autonomous agents that can use multiple tools. This allows your agent to have a variety of capabilities and choose the appropriate tool based on the task at hand.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-20)2. Integration with Large Language Models (LLMs):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-21)   There\\'s a tutorial that specifically mentions using Gemini 2.0 (Google\\'s LLM) with LangGraph to build autonomous agents. This suggests that LangGraph can be integrated with various LLMs, giving you flexibility in choosing the language model that best fits your needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-23)3. Practical Tutorials:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-24)   There are tutorials available that provide full code examples for building and running multi-tool agents. These can be invaluable as you start your project, giving you a concrete starting point and demonstrating best practices.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-26)4. GitHub Resources:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-27)   There\\'s a GitHub repository (github.com/anmolaman20/Tools_and_Agents) that provides resources for building AI agents using both Langchain and Langgraph. This could be a great resource for code examples, tutorials, and understanding how LangGraph fits into the broader LangChain ecosystem.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-29)5. Real-Time Adaptation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-30)   The resources mention creating intelligent systems that can think, reason, and adapt in real-time. This is a key feature of advanced autonomous agents and something you can aim for in your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-32)6. Diverse Applications:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-33)   The materials suggest that these techniques can be applied to various tasks, from answering questions to potentially more complex decision-making processes.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-35)To get started with your autonomous agent project using LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-36)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-37)1. Review the tutorials mentioned, especially those with full code examples.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-38)2. Explore the GitHub repository for hands-on examples and resources.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-39)3. Decide on the specific tasks or capabilities you want your agent to have.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-40)4. Choose an LLM to integrate with LangGraph (like GPT, Gemini, or others).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-41)5. Start with a simple agent that uses one or two tools, then gradually expand its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-42)6. Implement decision-making logic to help your agent choose between different tools or actions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-43)7. Test your agent thoroughly with various inputs and scenarios to ensure robust performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-45)Remember, building an autonomous agent is an iterative process. Start simple and gradually increase complexity as you become more comfortable with LangGraph and its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-47)Would you like more information on any specific aspect of building your autonomous agent with LangGraph?\\nNotice that the graph resumed execution from the **action** node. You can tell this is the case since the first value printed above is the response from our search engine tool.\\nCongratulations! You\\'ve now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications.\\nNext Steps¶\\nTake your journey further by exploring deployment and advanced features:\\nServer Quickstart¶\\n\\nLangGraph Server Quickstart: Launch a LangGraph server locally and interact with it using the REST API and LangGraph Studio Web UI.\\n\\nLangGraph Cloud¶\\n\\nLangGraph Cloud QuickStart: Deploy your LangGraph app using LangGraph Cloud.\\n\\nLangGraph Framework¶\\n\\nLangGraph Concepts: Learn the foundational concepts of LangGraph.\\nLangGraph How-to Guides: Guides for common tasks with LangGraph.\\n\\nLangGraph Platform¶\\nExpand your knowledge with these resources:\\n\\nLangGraph Platform Concepts: Understand the foundational concepts of the LangGraph Platform.\\nLangGraph Platform How-to Guides: Guides for common tasks with LangGraph Platform.\\n\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nComments\\nBack to top\\nPrevious TutorialsNext Workflows and Agents\\nCopyright © 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
       " {'title': 'LangGraph Quickstart',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/',\n",
       "  'content': \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features:\",\n",
       "  'score': 0.6773251,\n",
       "  'raw_content': 'Learn the basics\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLearn the basics\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nDeployment\\n\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\n\\n[ ] \\nTutorials\\nTutorials\\n\\n\\n[ ] \\nQuick Start\\nQuick Start\\n\\nQuick Start\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nLocal Deploy\\n\\nCloud Deploy\\n\\n\\n\\nChatbots\\n\\nRAG\\nAgent Architectures\\nEvaluation & Analysis\\nExperimental\\nLangGraph Platform\\n\\n\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nLLMS-txt\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: 🛠️ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\nHome\\n\\nGuides\\nTutorials\\nQuick Start\\n\\n\\n🚀 LangGraph Quickstart¶\\nIn this tutorial, we will build a support chatbot in LangGraph that can:\\n✅ Answer common questions by searching the web\\n✅ Maintain conversation state across calls\\n✅ Route complex queries to a human for review\\n✅ Use custom state to control its behavior\\n✅ Rewind and explore alternative conversation paths\\nWe\\'ll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way. Let’s dive in! 🌟\\nSetup¶\\nFirst, install the required packages and configure your environment:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-2)%pip install -U langgraph langsmith langchain_anthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-1)importgetpass\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-2)importos\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-5)def_set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-10)_set_env(\"ANTHROPIC_API_KEY\")\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started here.\\nPart 1: Build a Basic Chatbot¶\\nWe\\'ll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We\\'ll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-6)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-9)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-10)    # Messages have the type \"list\". The `add_messages` function\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-11)    # in the annotation defines how this state key should be updated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-12)    # (in this case, it appends messages to the list, rather than overwriting them)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-13)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-16)graph_builder = StateGraph(State)\\nAPI Reference: StateGraph | START | END | add_messages\\nOur graph can now handle two key tasks:\\n\\nEach node can receive the current State as input and output an update to the state.\\nUpdates to messages will be appended to the existing list rather than overwriting it, thanks to the prebuilt add_messages function used with the Annotated syntax.\\n\\n\\nConcept\\nWhen defining a graph, the first step is to define its State. The State includes the graph\\'s schema and reducer functions that handle state updates. In our example, State is a TypedDict with one key: messages. The add_messages reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. Learn more about state, reducers, and related concepts in this guide.\\n\\nNext, add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-3)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-6)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-7)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-10)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-11)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-12)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-13)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic\\nNotice how the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\nThe add_messages function in our State will append the llm\\'s response messages to whatever messages are already in the state.\\nNext, add an entry point. This tells our graph where to start its work each time we run it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-4-1)graph_builder.add_edge(START, \"chatbot\")\\nSimilarly, set a finish point. This instructs the graph \"any time this node is run, you can exit.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-5-1)graph_builder.add_edge(\"chatbot\", END)\\nFinally, we\\'ll want to be able to run our graph. To do so, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-6-1)graph = graph_builder.compile()\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-7)    pass\\n\\nNow let\\'s run the chatbot!\\nTip: You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\".\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-1)defstream_graph_updates(user_input: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-2)    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-3)        for value in event.values():\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-4)            print(\"Assistant:\", value[\"messages\"][-1].content)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-7)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-8)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-9)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-10)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-11)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-12)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-14)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-15)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-16)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-17)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-18)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-19)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-20)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-2)Goodbye!\\nCongratulations! You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above at the provided link.\\nHowever, you may have noticed that the bot\\'s knowledge is limited to what\\'s in its training data. In the next part, we\\'ll add a web search tool to expand the bot\\'s knowledge and make it more capable.\\nBelow is the full code for this section for your reference:\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-6)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-20)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-21)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-24)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-25)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-26)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-27)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-28)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-29)graph_builder.set_finish_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-30)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | StateGraph | add_messages\\nPart 2: 🛠️ Enhancing the Chatbot with Tools¶\\nTo handle queries our chatbot can\\'t answer \"from memory\", we\\'ll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\\nRequirements¶\\nBefore we start, make sure you have the necessary packages installed and API keys set up:\\nFirst, install the requirements to use the Tavily Search Engine, and set your TAVILY_API_KEY.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-2)%pip install -U tavily-python langchain_community\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-12-1)_set_env(\"TAVILY_API_KEY\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-13-1)TAVILY_API_KEY:  ········\\nNext, define the tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-1)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-3)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-4)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-5)tool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\nAPI Reference: TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-1)[{\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-2)  \\'content\\': \\'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...\\'},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-3) {\\'url\\': \\'https://saksheepatil05.medium.com/demystifying-langgraph-a-beginner-friendly-dive-into-langgraph-concepts-5ffe890ddac0\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-4)  \\'content\\': \\'Nodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.\\'}]\\nThe results are page summaries our chat bot can use to answer questions.\\nNext, we\\'ll start defining our graph. The following is all the same as in Part 1, except we have added bind_tools on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-6)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-18)# Modification: tell the LLM which tools it can call\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-19)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-22)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-23)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-26)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic | StateGraph | START | END | add_messages\\nNext we need to create a function to actually run the tools if they are called. We\\'ll do this by adding the tools to a new node.\\nBelow, we implement a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nWe will later replace this with LangGraph\\'s prebuilt ToolNode to speed things up, but building it ourselves first is instructive.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-1)importjson\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-3)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-6)classBasicToolNode:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-7)\"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-9)    def__init__(self, tools: list) -> None:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-10)        self.tools_by_name = {tool.name: tool for tool in tools}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-12)    def__call__(self, inputs: dict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-13)        if messages := inputs.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-14)            message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-15)        else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-16)            raise ValueError(\"No message found in input\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-17)        outputs = []\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-18)        for tool_call in message.tool_calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-19)            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-20)                tool_call[\"args\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-21)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-22)            outputs.append(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-23)                ToolMessage(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-24)                    content=json.dumps(tool_result),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-25)                    name=tool_call[\"name\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-26)                    tool_call_id=tool_call[\"id\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-27)                )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-28)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-29)        return {\"messages\": outputs}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-32)tool_node = BasicToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-33)graph_builder.add_node(\"tools\", tool_node)\\nAPI Reference: ToolMessage\\nWith the tool node added, we can define the conditional_edges.\\nRecall that edges route the control flow from one node to the next. Conditional edges usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nBelow, call define a router function called route_tools, that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next.\\nThe condition will route to tools if tool calls are present and END if not.\\nLater, we will replace this with the prebuilt tools_condition to be more concise, but implementing it ourselves first makes things more clear.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-1)defroute_tools(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-2)    state: State,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-3)):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-4)\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-5)    Use in the conditional_edge to route to the ToolNode if the last message\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-6)    has tool calls. Otherwise, route to the end.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-7)    \"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-8)    if isinstance(state, list):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-9)        ai_message = state[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-10)    elif messages := state.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-11)        ai_message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-12)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-13)        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-14)    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-15)        return \"tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-16)    return END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-19)# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-20)# it is fine directly responding. This conditional routing defines the main agent loop.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-21)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-22)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-23)    route_tools,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-24)    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-25)    # It defaults to the identity function, but if you\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-26)    # want to use a node named something else apart from \"tools\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-27)    # You can update the value of the dictionary to something else\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-28)    # e.g., \"tools\": \"my_tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-29)    {\"tools\": \"tools\", END: END},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-31)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-32)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-33)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-34)graph = graph_builder.compile()\\nNotice that conditional edges start from a single node. This tells the graph \"any time the \\'chatbot\\' node runs, either go to \\'tools\\' if it calls a tool, or end the loop if it responds directly.\\nLike the prebuilt tools_condition, our function returns the END string if no tool calls are made. When the graph transitions to END, it has no more tasks to complete and ceases execution. Because the condition can return END, we don\\'t need to explicitly set a finish_point this time. Our graph already has a way to finish!\\nLet\\'s visualize the graph we\\'ve built. The following function has some additional dependencies to run that are unimportant for this tutorial.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-7)    pass\\n\\nNow we can ask the bot questions outside its training data.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-1)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-2)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-3)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-4)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-5)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-6)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-8)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-9)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-10)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-11)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-12)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-13)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-14)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-1)Assistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-2)Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-3)Assistant: Based on the search results, I can provide you with information about LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-5)1. Purpose:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-12)   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-13)   - Controllability: It offers enhanced control over the application flow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-14)   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-16)4. Use Cases:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-17)   LangGraph can be used for various applications, including:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-18)   - Conversational agents\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-19)   - Complex task automation\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-20)   - Custom LLM-backed experiences\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-22)5. Integration:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-23)   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-25)6. Significance:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-26)   LangGraph is described as setting the foundation for building and scaling AI workloads. It\\'s positioned as a key tool in the next chapter of LLM-based application development, particularly in the realm of agentic AI.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-28)7. Availability:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-29)   LangGraph is open-source and available on GitHub, which suggests that developers can access and contribute to its codebase.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-31)8. Comparison to Other Frameworks:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-32)   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-34)LangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-35)Goodbye!\\nCongrats! You\\'ve created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace.\\nOur chatbot still can\\'t remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we\\'ll add memory to address this.\\nThe full code for the graph we\\'ve created in this section is reproduced below, replacing our BasicToolNode for the prebuilt ToolNode, and our route_tools condition with the prebuilt tools_condition\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-8)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-42)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | add_messages | ToolNode | tools_condition\\nPart 3: Adding Memory to the Chatbot¶\\nOur chatbot can now use tools to answer user questions, but it doesn\\'t remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\\nLangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off.\\nWe will see later that checkpointing is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But before we get too ahead of ourselves, let\\'s add checkpointing to enable multi-turn conversations.\\nTo get started, create a MemorySaver checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-1)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-3)memory = MemorySaver()\\nAPI Reference: MemorySaver\\nNotice we\\'re using an in-memory checkpointer. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect to your own DB.\\nNext define the graph. Now that you\\'ve already built your own BasicToolNode, we\\'ll replace it with LangGraph\\'s prebuilt ToolNode and tools_condition, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-8)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-41)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nFinally, compile the graph with the provided checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-25-1)graph = graph_builder.compile(checkpointer=memory)\\nNotice the connectivity of the graph hasn\\'t changed since Part 2. All we are doing is checkpointing the State as the graph works through each node.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-7)    pass\\n\\nNow you can interact with your bot! First, pick a thread to use as the key for this conversation.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-27-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\nNext, call your chat bot.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-1)user_input = \"Hi there! My name is Will.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-3)Hi there! My name is Will.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-6)Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\\nNote: The config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({\\'messages\\': []}).\\nLet\\'s ask a followup: see if it remembers your name.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-1)user_input = \"Remember my name?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-6)Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\\nNotice that we aren\\'t using an external list for memory: it\\'s all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what\\'s going on.\\nDon\\'t believe me? Try this using a different config.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-1)# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-3)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-4)    {\"configurable\": {\"thread_id\": \"2\"}},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-5)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-7)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-8)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-6)I apologize, but I don\\'t have any previous context or memory of your name. As an AI assistant, I don\\'t retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\\nNotice that the only change we\\'ve made is to modify the thread_id in the config. See this call\\'s LangSmith trace for comparison.\\nBy now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph\\'s state for a given config at any time, call get_state(config).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-2)snapshot\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-35-1)StateSnapshot(values={\\'messages\\': [HumanMessage(content=\\'Hi there! My name is Will.\\', additional_kwargs={}, response_metadata={}, id=\\'8c1ca919-c553-4ebf-95d4-b59a2d61e078\\'), AIMessage(content=\"Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01WTQebPhNwmMrmmWojJ9KXJ\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 405, \\'output_tokens\\': 32}}, id=\\'run-58587b77-8c82-41e6-8a90-d62c444a261d-0\\', usage_metadata={\\'input_tokens\\': 405, \\'output_tokens\\': 32, \\'total_tokens\\': 437}), HumanMessage(content=\\'Remember my name?\\', additional_kwargs={}, response_metadata={}, id=\\'daba7df6-ad75-4d6b-8057-745881cea1ca\\'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}, next=(), config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-93e0-6acc-8004-f2ac846575d2\\'}}, metadata={\\'source\\': \\'loop\\', \\'writes\\': {\\'chatbot\\': {\\'messages\\': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}}, \\'step\\': 4, \\'parents\\': {}}, created_at=\\'2024-09-27T19:30:10.820758+00:00\\', parent_config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-859f-6206-8003-e1bd3c264b8f\\'}}, tasks=())\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-36-1)snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-37-1)()\\nThe snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an END state, so next is empty.\\nCongratulations! Your chatbot can now maintain conversation state across sessions thanks to LangGraph\\'s checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph\\'s checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory.\\nIn the next part, we\\'ll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\\nCheck out the code snippet below to review our graph from this section.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-9)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-11)fromlanggraph.prebuiltimport ToolNode\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-42)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-43)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | add_messages | ToolNode\\nPart 4: Human-in-the-loop¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. interrupt is ergonomically similar to Python\\'s built-in input(), with some caveats. We demonstrate an example below.\\nFirst, start with our existing code from Part 3. We will make one change, which is to add a simple human_assistance tool accessible to the chatbot. This tool uses interrupt to receive information from a human.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-16)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-17)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-20)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-24)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-25)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-26)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-27)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-30)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-31)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-32)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-33)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-36)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-37)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-38)    # Because we will be interrupting during tool execution,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-39)    # we disable parallel tool calling to avoid repeating any\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-40)    # tool invocations when we resume.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-41)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-42)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-45)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-47)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-48)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-49)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-50)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-51)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-52)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-53))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-54)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-55)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\n\\nTip\\nCheck out the Human-in-the-loop section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\n\\nWe compile the graph with a checkpointer, as before:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-1)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-3)graph = graph_builder.compile(checkpointer=memory)\\nVisualizing the graph, we recover the same layout as before. We have just added a tool!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-7)    pass\\n\\nLet\\'s now prompt the chatbot with a question that will engage the new human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-1)user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-2)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-3)I need some expert guidance for building an AI agent. Could you request assistance for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-6)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-8)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-9) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-11)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\nThe chatbot generated a tool call, but then execution has been interrupted! Note that if we inspect the graph state, we see that it stopped at the tools node:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-2)snapshot.next\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-45-1)(\\'tools\\',)\\nLet\\'s take a closer look at the human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-1)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-2)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-3)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-4)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-5)    return human_response[\"data\"]\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on our choice of checkpointer-- so if we are persisting with Postgres, we can resume at any time as long as the database is alive. Here we are persisting with the in-memory checkpointer, so we can resume any time as long as our Python kernel is running.\\nTo resume execution, we pass a Command object containing data expected by the tool. The format of this data can be customized based on our needs. Here, we just need a dict with a key \"data\":\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-1)human_response = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-2)    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-3)    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-6)human_command = Command(resume={\"data\": human_response})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-3)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-5)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-6) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-8)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-10)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-12)We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-15)Thank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-17)The experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-21)1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-23)2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-25)3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-27)To get started with LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-29)1. Search for the official LangGraph documentation or website to learn more about its features and how to use it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-30)2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-31)3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-33)If you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOur input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongrats! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nHuman-in-the-loop workflows enable a variety of new workflows and user experiences. Check out this section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-12)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-15)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-16)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-19)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-22)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-23)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-24)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-25)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-26)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-29)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-30)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-31)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-32)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-35)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-36)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-37)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-38)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-40)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-41)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-43)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-44)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-46)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-47)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-48)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-49))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-50)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-51)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-52)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-53)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-54)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 5: Customizing State¶\\nSo far, we\\'ve relied on a simple state with one entry-- a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. Here we will demonstrate a new scenario, in which the chatbot is using its search tool to find specific information, and forwarding them to a human for review. Let\\'s have the chatbot research the birthday of an entity. We will add name and birthday keys to the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-5)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-8)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-9)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-10)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-11)    birthday: str\\nAPI Reference: add_messages\\nAdding this information to the state makes it easily accessible by other graph nodes (e.g., a downstream node that stores or processes the information), as well as the graph\\'s persistence layer.\\nHere, we will populate the state keys inside of our human_assistance tool. This allows a human to review the information before it is stored in the state. We will again use Command, this time to issue a state update from inside our tool. Read more about use cases for Command here.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-1)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-2)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-4)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-7)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-8)# Note that because we are generating a ToolMessage for a state update, we\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-9)# generally require the ID of the corresponding tool call. We can use\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-10)# LangChain\\'s InjectedToolCallId to signal that this argument should not\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-11)# be revealed to the model in the tool\\'s schema.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-12)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-13)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-14)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-15)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-16)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-17)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-18)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-19)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-20)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-21)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-22)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-23)    # If the information is correct, update the state as-is.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-24)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-25)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-26)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-27)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-28)    # Otherwise, receive information from the human reviewer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-29)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-30)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-31)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-32)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-34)    # This time we explicitly update the state with a ToolMessage inside\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-35)    # the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-36)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-37)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-38)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-39)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-40)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-41)    # We return a Command object in the tool to update our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-42)    return Command(update=state_update)\\nAPI Reference: ToolMessage | InjectedToolCallId | tool | Command | interrupt\\nOtherwise, the rest of our graph is the same:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-2)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-4)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-6)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-9)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-10)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-11)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-12)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-15)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-16)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-17)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-18)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-21)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-22)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-24)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-25)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-27)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-28)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-29)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-31)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-32)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-34)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-35)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | MemorySaver | StateGraph | START | END | ToolNode | tools_condition\\nLet\\'s prompt our application to look up the \"birthday\" of the LangGraph library. We will direct the chatbot to reach out to the human_assistance tool once it has the required information. Note that setting name and birthday in the arguments for the tool, we force the chatbot to generate proposals for these fields.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-1)user_input = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-2)    \"Can you look up when LangGraph was released? \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-3)    \"When you have the answer, use the human_assistance tool for review.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-5)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-7)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-8)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-9)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-10)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-11))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-12)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-13)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-14)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-3)Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-6)[{\\'text\\': \"Certainly! I\\'ll start by searching for information about LangGraph\\'s release date using the Tavily search function. Then, I\\'ll use the human_assistance tool for review.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JoXQPgTVJXiuma8xMVwqAi\\', \\'input\\': {\\'query\\': \\'LangGraph release date\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-8)  tavily_search_results_json (toolu_01JoXQPgTVJXiuma8xMVwqAi)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-9) Call ID: toolu_01JoXQPgTVJXiuma8xMVwqAi\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-11)    query: LangGraph release date\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-15)[{\"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024 (Oct \\'24) Edit: Since the launch of LangGraph Cloud, we now have multiple deployment options alongside LangGraph Studio - which now fall under LangGraph Platform. LangGraph Cloud is synonymous with our Cloud SaaS deployment option.\"}, {\"url\": \"https://changelog.langchain.com/announcements/langgraph-cloud-deploy-at-scale-monitor-carefully-iterate-boldly\", \"content\": \"LangChain - Changelog | ☁ 🚀 LangGraph Cloud: Deploy at scale, monitor LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog Sign up for our newsletter to stay up to date DATE: The LangChain Team LangGraph LangGraph Cloud ☁ 🚀 LangGraph Cloud: Deploy at scale, monitor carefully, iterate boldly DATE: June 27, 2024 AUTHOR: The LangChain Team LangGraph Cloud is now in closed beta, offering scalable, fault-tolerant deployment for LangGraph agents. LangGraph Cloud also includes a new playground-like studio for debugging agent failure modes and quick iteration: Join the waitlist today for LangGraph Cloud. And to learn more, read our blog post announcement or check out our docs. Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-18)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-19)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-20)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-21) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-22)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-23)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-24)    birthday: 2023-01-01\\nWe\\'ve hit the interrupt in the human_assistance tool again. In this case, the chatbot failed to identify the correct date, so we can supply it:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-1)human_command = Command(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-2)    resume={\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-3)        \"name\": \"LangGraph\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-4)        \"birthday\": \"Jan 17, 2024\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-5)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-3)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-5)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-6) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-8)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-9)    birthday: 2023-01-01\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-11)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-13)Made a correction: {\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-16)Thank you for the human assistance. I can now provide you with the correct information about LangGraph\\'s release date.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph\\'s original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It\\'s worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-58-1){\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nThis makes them easily accessible to downstream nodes (e.g., a node that further processes or stores the information).\\nManually updating state¶\\nLangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), we can manually override a key using graph.update_state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-59-1)graph.update_state(config, {\"name\": \"LangGraph (library)\"})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-1){\\'configurable\\': {\\'thread_id\\': \\'1\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-2)  \\'checkpoint_ns\\': \\'\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-3)  \\'checkpoint_id\\': \\'1efd4ec5-cf69-6352-8006-9278f1730162\\'}}\\nIf we call graph.get_state, we can see the new value is reflected:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-62-1){\\'name\\': \\'LangGraph (library)\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nManual state updates will even generate a trace in LangSmith. If desired, they can also be used to control human-in-the-loop workflows, as described in this guide. Use of the interrupt function is generally recommended instead, as it allows data to be transmitted in a human-in-the-loop interaction independently of state updates.\\nCongratulations! You\\'ve added custom keys to the state to facilitate a more complex workflow, and learned how to generate state updates from inside tools.\\nWe\\'re almost done with the tutorial, but there is one more concept we\\'d like to review before finishing that connects checkpointing and state updates.\\nThis section\\'s code is reproduced below for your reference.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-5)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-6)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-7)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-9)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-10)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-11)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-12)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-17)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-18)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-19)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-20)    birthday: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-24)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-25)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-26)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-27)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-28)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-29)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-30)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-31)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-32)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-33)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-34)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-35)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-36)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-37)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-38)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-39)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-40)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-41)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-42)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-44)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-45)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-46)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-47)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-48)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-49)    return Command(update=state_update)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-50)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-51)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-52)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-53)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-54)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-55)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-56)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-57)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-58)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-59)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-60)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-61)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-62)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-63)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-64)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-65)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-66)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-67)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-68)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-69)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-70)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-71)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-72)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-73))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-74)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-75)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-76)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-77)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-78)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | ToolMessage | InjectedToolCallId | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 6: Time Travel¶\\nIn a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and control future responses.\\nBut what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant\\'s work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\\nYou can create both of these experiences and more using LangGraph\\'s built-in \"time travel\" functionality.\\nIn this section, you will \"rewind\" your graph by fetching a checkpoint using the graph\\'s get_state_history method. You can then resume execution at this previous point in time.\\nFor this, let\\'s use the simple chatbot with tools from Part 3:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-41)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-43)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-44)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nLet\\'s have our graph take a couple steps. Every step will be checkpointed in its state history:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-3)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-4)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-5)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-6)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-7)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-8)                    \"I\\'m learning LangGraph. \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-9)                    \"Could you do some research on it for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-10)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-11)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-12)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-13)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-14)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-15)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-16))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-17)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-18)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-19)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-3)I\\'m learning LangGraph. Could you do some research on it for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-6)[{\\'text\\': \"Certainly! I\\'d be happy to research LangGraph for you. To get the most up-to-date and accurate information, I\\'ll use the Tavily search engine to look this up. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BscbfJJB9EWJFqGrN6E54e\\', \\'input\\': {\\'query\\': \\'LangGraph latest information and features\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-8)  tavily_search_results_json (toolu_01BscbfJJB9EWJFqGrN6E54e)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-9) Call ID: toolu_01BscbfJJB9EWJFqGrN6E54e\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-11)    query: LangGraph latest information and features\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-15)[{\"url\": \"https://blockchain.news/news/langchain-new-features-upcoming-events-update\", \"content\": \"LangChain, a leading platform in the AI development space, has released its latest updates, showcasing new use cases and enhancements across its ecosystem. According to the LangChain Blog, the updates cover advancements in LangGraph Cloud, LangSmith\\'s self-improving evaluators, and revamped documentation for LangGraph.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-platform-announce/\", \"content\": \"With these learnings under our belt, we decided to couple some of our latest offerings under LangGraph Platform. LangGraph Platform today includes LangGraph Server, LangGraph Studio, plus the CLI and SDK. ... we added features in LangGraph Server to deliver on a few key value areas. Below, we\\'ll focus on these aspects of LangGraph Platform.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-18)Thank you for your patience. I\\'ve found some recent information about LangGraph for you. Let me summarize the key points:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-20)1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-22)2. Recent updates and features of LangGraph include:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-24)   a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren\\'t provided in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-26)   b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-27)      - LangGraph Server\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-28)      - LangGraph Studio\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-29)      - CLI (Command Line Interface)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-30)      - SDK (Software Development Kit)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-32)3. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren\\'t detailed in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-34)4. LangGraph Studio: This appears to be a new tool in the LangGraph ecosystem, likely providing a graphical interface for working with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-36)5. Documentation: The LangGraph documentation has been revamped, which should make it easier for learners like yourself to understand and use the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-38)6. Integration with LangSmith: While not directly part of LangGraph, LangSmith (another tool in the LangChain ecosystem) now features self-improving evaluators, which might be relevant if you\\'re using LangGraph as part of a larger LangChain project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-40)As you\\'re learning LangGraph, it would be beneficial to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-41)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-42)1. Check out the official LangChain documentation, especially the newly revamped LangGraph sections.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-43)2. Explore the different components of the LangGraph Platform (Server, Studio, CLI, and SDK) to see which best fits your learning needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-44)3. Keep an eye on LangGraph Cloud developments, as cloud-based solutions often provide an easier starting point for learners.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-45)4. Consider how LangGraph fits into the broader LangChain ecosystem, especially its interaction with tools like LangSmith.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-47)Is there any specific aspect of LangGraph you\\'d like to know more about? I\\'d be happy to do a more focused search on particular features or use cases.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-1)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-2)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-3)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-4)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-5)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-6)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-7)                    \"Ya that\\'s helpful. Maybe I\\'ll \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-8)                    \"build an autonomous agent with it!\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-9)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-10)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-11)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-12)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-13)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-14)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-15))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-16)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-17)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-18)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-3)Ya that\\'s helpful. Maybe I\\'ll build an autonomous agent with it!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-6)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-8)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-9) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-11)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-15)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-18)Great idea! Building an autonomous agent with LangGraph is definitely an exciting project. Based on the latest information I\\'ve found, here are some insights and tips for building autonomous agents with LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-20)1. Multi-Tool Agents: LangGraph is particularly well-suited for creating autonomous agents that can use multiple tools. This allows your agent to have a diverse set of capabilities and choose the right tool for each task.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-22)2. Integration with Large Language Models (LLMs): You can combine LangGraph with powerful LLMs like Gemini 2.0 to create more intelligent and capable agents. The LLM can serve as the \"brain\" of your agent, making decisions and generating responses.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-24)3. Workflow Management: LangGraph excels at managing complex, multi-step AI workflows. This is crucial for autonomous agents that need to break down tasks into smaller steps and execute them in the right order.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-26)4. Practical Tutorials Available: There are tutorials available that provide full code examples for building and running multi-tool agents. These can be incredibly helpful as you start your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-28)5. Langchain Integration: LangGraph is often used in conjunction with Langchain. This combination provides a powerful framework for building AI agents, offering features like memory management, tool integration, and prompt management.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-30)6. GitHub Resources: There are repositories available (like the one by anmolaman20) that provide comprehensive resources for building AI agents using Langchain and LangGraph. These can be valuable references as you develop your agent.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-32)7. Real-time Adaptation: LangGraph allows you to create agents that can think, reason, and adapt in real-time, which is crucial for truly autonomous behavior.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-34)8. Customization: You can equip your agent with specific tools tailored to your use case. For example, you might include tools for web searching, data analysis, or interacting with specific APIs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-36)To get started with your autonomous agent project:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-38)1. Familiarize yourself with LangGraph\\'s documentation and basic concepts.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-39)2. Look into tutorials that specifically deal with building autonomous agents, like the one mentioned from Towards Data Science.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-40)3. Decide on the specific capabilities you want your agent to have and identify the tools it will need.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-41)4. Start with a simple agent and gradually add complexity as you become more comfortable with the framework.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-42)5. Experiment with different LLMs to find the one that works best for your use case.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-43)6. Pay attention to how you structure the agent\\'s decision-making process and workflow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-44)7. Don\\'t forget to implement proper error handling and safety measures, especially if your agent will be interacting with external systems or making important decisions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-46)Building an autonomous agent is an iterative process, so be prepared to refine and improve your agent over time. Good luck with your project! If you need any more specific information as you progress, feel free to ask.\\nNow that we\\'ve had the agent take a couple steps, we can replay the full state history to see everything that occurred.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-1)to_replay = None\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-2)for state in graph.get_state_history(config):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-3)    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-4)    print(\"-\" * 80)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-5)    if len(state.values[\"messages\"]) == 6:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-6)        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-7)        to_replay = state\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-1)Num Messages:  8 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-2)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-3)Num Messages:  7 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-4)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-5)Num Messages:  6 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-6)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-7)Num Messages:  5 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-8)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-9)Num Messages:  4 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-10)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-11)Num Messages:  4 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-12)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-13)Num Messages:  3 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-14)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-15)Num Messages:  2 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-16)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-17)Num Messages:  1 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-18)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-19)Num Messages:  0 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-20)--------------------------------------------------------------------------------\\nNotice that checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread\\'s history. We\\'ve picked out to_replay as a state to resume from. This is the state after the chatbot node in the second graph invocation above.\\nResuming from this point should call the action node next.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-1)print(to_replay.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-2)print(to_replay.config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-1)(\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-2){\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1efd43e3-0c1f-6c4e-8006-891877d65740\\'}}\\nNotice that the checkpoint\\'s config (to_replay.config) contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph\\'s checkpointer to load the state from that moment in time. Let\\'s try it below:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-1)# The `checkpoint_id` in the `to_replay.config` corresponds to a state we\\'ve persisted to our checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-2)for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-3)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-4)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-3)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-5)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-6) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-8)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-10)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-12)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable — they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a user’s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-15)Great idea! Building an autonomous agent with LangGraph is indeed an excellent way to apply and deepen your understanding of the technology. Based on the search results, I can provide you with some insights and resources to help you get started:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-17)1. Multi-Tool Agents:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-18)   LangGraph is well-suited for building autonomous agents that can use multiple tools. This allows your agent to have a variety of capabilities and choose the appropriate tool based on the task at hand.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-20)2. Integration with Large Language Models (LLMs):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-21)   There\\'s a tutorial that specifically mentions using Gemini 2.0 (Google\\'s LLM) with LangGraph to build autonomous agents. This suggests that LangGraph can be integrated with various LLMs, giving you flexibility in choosing the language model that best fits your needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-23)3. Practical Tutorials:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-24)   There are tutorials available that provide full code examples for building and running multi-tool agents. These can be invaluable as you start your project, giving you a concrete starting point and demonstrating best practices.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-26)4. GitHub Resources:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-27)   There\\'s a GitHub repository (github.com/anmolaman20/Tools_and_Agents) that provides resources for building AI agents using both Langchain and Langgraph. This could be a great resource for code examples, tutorials, and understanding how LangGraph fits into the broader LangChain ecosystem.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-29)5. Real-Time Adaptation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-30)   The resources mention creating intelligent systems that can think, reason, and adapt in real-time. This is a key feature of advanced autonomous agents and something you can aim for in your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-32)6. Diverse Applications:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-33)   The materials suggest that these techniques can be applied to various tasks, from answering questions to potentially more complex decision-making processes.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-35)To get started with your autonomous agent project using LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-36)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-37)1. Review the tutorials mentioned, especially those with full code examples.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-38)2. Explore the GitHub repository for hands-on examples and resources.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-39)3. Decide on the specific tasks or capabilities you want your agent to have.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-40)4. Choose an LLM to integrate with LangGraph (like GPT, Gemini, or others).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-41)5. Start with a simple agent that uses one or two tools, then gradually expand its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-42)6. Implement decision-making logic to help your agent choose between different tools or actions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-43)7. Test your agent thoroughly with various inputs and scenarios to ensure robust performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-45)Remember, building an autonomous agent is an iterative process. Start simple and gradually increase complexity as you become more comfortable with LangGraph and its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-47)Would you like more information on any specific aspect of building your autonomous agent with LangGraph?\\nNotice that the graph resumed execution from the **action** node. You can tell this is the case since the first value printed above is the response from our search engine tool.\\nCongratulations! You\\'ve now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications.\\nNext Steps¶\\nTake your journey further by exploring deployment and advanced features:\\nServer Quickstart¶\\n\\nLangGraph Server Quickstart: Launch a LangGraph server locally and interact with it using the REST API and LangGraph Studio Web UI.\\n\\nLangGraph Cloud¶\\n\\nLangGraph Cloud QuickStart: Deploy your LangGraph app using LangGraph Cloud.\\n\\nLangGraph Framework¶\\n\\nLangGraph Concepts: Learn the foundational concepts of LangGraph.\\nLangGraph How-to Guides: Guides for common tasks with LangGraph.\\n\\nLangGraph Platform¶\\nExpand your knowledge with these resources:\\n\\nLangGraph Platform Concepts: Understand the foundational concepts of the LangGraph Platform.\\nLangGraph Platform How-to Guides: Guides for common tasks with LangGraph Platform.\\n\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nComments\\nBack to top\\nPrevious TutorialsNext Workflows and Agents\\nCopyright © 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ❤️\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
       " {'title': 'How to Use Langchain with Huggingface- A Step-by-Step Guide',\n",
       "  'url': 'https://vikassri.github.io/posts/Introduction_to_LLM/',\n",
       "  'content': 'Langchain is a powerful language translation tool, and Huggingface is a popular open-source library for natural language processing (NLP).',\n",
       "  'score': 0.643173}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행\n",
    "tool.invoke({\"query\": \"LangChain Tools 에 대해서 알려주세요\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image 생성 도구 (DALL-E)\n",
    "\n",
    "- `DallEAPIWrapper 클래스`: OpenAI의 DALL-E 이미지 생성기를 위한 래퍼(wrapper)입니다.\n",
    "\n",
    "이 도구를 사용하면 DALL-E API를 쉽게 통합하여 텍스트 기반 이미지 생성 기능을 구현할 수 있습니다. 다양한 설정 옵션을 통해 유연하고 강력한 이미지 생성 도구로 활용할 수 있습니다.\n",
    "\n",
    "**주요 속성**\n",
    "\n",
    "- `model`: 사용할 DALL-E 모델 이름 (기본값: \"dall-e-2\", \"dall-e-3\")\n",
    "\n",
    "- `n`: 생성할 이미지 수 (기본값: 1)\n",
    "\n",
    "- `size`: 생성할 이미지 크기\n",
    "  - \"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\n",
    "  - \"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\n",
    "\n",
    "- `style`: 생성될 이미지의 스타일 (기본값: \"natural\", \"vivid\")\n",
    "\n",
    "- `quality`: 생성될 이미지의 품질 (기본값: \"standard\", \"hd\")\n",
    "\n",
    "- `max_retries`: 생성 시 최대 재시도 횟수\n",
    "\n",
    "**주요 기능**\n",
    "- DALL-E API를 사용하여 텍스트 설명에 기반한 이미지 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**흐름 정리**\n",
    "\n",
    "다음은 DALL-E Image Generator 를 사용하여 이미지를 생성하는 예제입니다.\n",
    "\n",
    "이번에는 `DallEAPIWrapper` 를 사용하여 이미지를 생성해 보겠습니다.\n",
    "\n",
    "이때 입력 프롬프트는 LLM 모델에게 이미지를 생성하는 프롬프트를 작성하도록 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vibrant concert scene featuring a large crowd of enthusiastic fans at an IU concert, all facing a brightly lit stage. Show a diverse group of people, including teenagers and adults, some holding light sticks, swaying to the music, and capturing moments on their smartphones. The background should be filled with colorful stage lights, with IU performing energetically at the center, surrounded by a dynamic band. Capture the excitement in the air, with confetti falling from above and expressions of joy and admiration on the faces of the audience. The setting is an outdoor arena at night, with a clear sky and stars visible, adding to the magical atmosphere of the concert.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\n",
    "\n",
    "# DALL-E 이미지 생성을 위한 프롬프트 템플릿 정의\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "# 프롬프트, LLM, 출력 파서를 연결하는 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "image_prompt = chain.invoke(\n",
    "    {\"image_desc\": \"아이유 콘서트를 바라보는 사람들을 모습을 그려\"}\n",
    ")\n",
    "\n",
    "# 이미지 프롬프트 출력\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼, 이전에 생성한 이미지 프롬프트를 `DallEAPIWrapper` 에 입력하여 이미지를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DallEAPIWrapper` 에 대한 임시 버그 안내사항** (작성일: 2024-10-13)\n",
    "\n",
    "- 현재 langchain 0.3.x 이상 버전에서 `DallEAPIWrapper` 에 대한 임시 버그가 있습니다. (`401 오류: invalid API key`)\n",
    "\n",
    "따라서, 아래의 코드를 오류 없이 실행하기 위해서는 LangChain 버전을 0.2.16 으로 변경해야 합니다.\n",
    "\n",
    "아래의 주석을 해제하고 실행하면 LangChain 버전을 0.2.16 으로 변경됩니다.\n",
    "\n",
    "하지만, 이후 내용에서는 LangChain 버전을 0.3.x 이상으로 변경하여 사용하기 때문에\n",
    "\n",
    "`poetry shell` 명령어를 통해 다시 최신 langchain 버전으로 변경해야 합니다.\n",
    "\n",
    "이 과정이 번거로운 분들은 일단 `DallEAPIWrapper` 를 사용하지 않고 진행하셔도 무방합니다.\n",
    "\n",
    "**업그레이드/다운그레이드** 후에는 반드시 상단 메뉴의 \"Restart\" 버튼을 클릭한 뒤 진행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 버전 다운그레이드 명령어 (실행 후 restart)\n",
    "# !pip install langchain==0.2.16 langchain-community==0.2.16 langchain-text-splitters==0.2.4 langchain-experimental==0.0.65 langchain-openai==0.1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-7c9J2OAcOUFTXC5xFVsaZjns/user-gUTWYjUBJ8idGcqbhboJaxVx/img-lXUggWTZMwbMiD6Wq3UFps61.png?st=2025-04-01T05%3A37%3A42Z&se=2025-04-01T07%3A37%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-03-31T14%3A07%3A44Z&ske=2025-04-01T14%3A07%3A44Z&sks=b&skv=2024-08-04&sig=aPVxqLaKYNaB82UpO6ubCtOf0698jTYOsk%2BD7nXtavI%3D\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DALL-E API 래퍼 가져오기\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "# DALL-E API 래퍼 초기화\n",
    "# model: 사용할 DALL-E 모델 버전\n",
    "# size: 생성할 이미지 크기\n",
    "# quality: 이미지 품질\n",
    "# n: 생성할 이미지 수\n",
    "dalle = DallEAPIWrapper(\n",
    "    model=\"dall-e-3\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# 질문\n",
    "query = \"아이유 콘서트를 바라보는 사람들을 모습을 지브리풍으로 그려춰\"\n",
    "\n",
    "# 이미지 생성 및 URL 받기\n",
    "# chain.invoke()를 사용하여 이미지 설명을 DALL-E 프롬프트로 변환\n",
    "# dalle.run()을 사용하여 실제 이미지 생성\n",
    "image_url = dalle.run(chain.invoke({\"image_desc\": query}))\n",
    "\n",
    "# 생성된 이미지를 표시합니다.\n",
    "Image(url=image_url, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 정의 도구(Custom Tool)\n",
    "\n",
    "LangChain 에서 제공하는 빌트인 도구 외에도 사용자가 직접 도구를 정의하여 사용할 수 있습니다.\n",
    "\n",
    "이를 위해서는 `langchain.tools` 모듈에서 제공하는 `tool` 데코레이터를 사용하여 함수를 도구로 변환합니다.\n",
    "\n",
    "### @tool 데코레이터\n",
    "\n",
    "이 데코레이터는 함수를 도구로 변환하는 기능을 제공합니다. 다양한 옵션을 통해 도구의 동작을 커스터마이즈할 수 있습니다.\n",
    "\n",
    "**사용 방법**\n",
    "1. 함수 위에 `@tool` 데코레이터 적용\n",
    "2. 필요에 따라 데코레이터 매개변수 설정\n",
    "\n",
    "이 데코레이터를 사용하면 일반 Python 함수를 강력한 도구로 쉽게 변환할 수 있으며, 자동화된 문서화와 유연한 인터페이스 생성이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# 데코레이터를 사용하여 함수를 도구로 변환합니다.\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행\n",
    "add_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 도구 실행\n",
    "multiply_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구글 뉴스기사 검색 도구\n",
    "\n",
    "`langchain-teddynote` 패키지에서 제공하는 `GoogleNews` 도구를 사용하여 구글 뉴스기사를 검색하는 도구입니다.\n",
    "\n",
    "**참고**\n",
    "- API 키가 필요하지 않습니다. (RSS 피드를 사용하기 때문)\n",
    "\n",
    "news.google.com 에서 제공하는 뉴스기사를 검색하는 도구입니다.\n",
    "\n",
    "**설명**\n",
    "- 구글 뉴스 검색 API를 사용하여 최신 뉴스를 검색합니다.\n",
    "- 키워드를 기반으로 뉴스를 검색할 수 있습니다.\n",
    "- 최신 뉴스를 검색할 수 있습니다.\n",
    "\n",
    "**주요 매개변수**\n",
    "- `k` (int): 반환할 최대 검색 결과 수 (기본값: 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용하기 전 패키지를 업데이트 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import GoogleNews\n",
    "\n",
    "# 도구 생성\n",
    "news_tool = GoogleNews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMidEFVX3lxTE1qU0pyR09odlpOeGZLM19NZ0ZjRVR5d21CWmhpOUhGMzRuT1JpQnpjUEZDcndCZkpEVlNkMWl4VlI2bmhFQXg2VTAzZlFjNnZJcXRSS0FFZ1VmNUtTQlVOeUxfS3NHNjg5cFlRbEo1RHhHRm82?oc=5',\n",
       "  'content': '“헌재 생방송 허용도 긍정신호”…만장일치 파면 점치는 야권 - 한겨레'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiWkFVX3lxTFBTa3hRSHA3b19tc1JyX1kzSWZ2VDZiemt6T3d4aWVoODVUQ2pmWDl6R2FDeHgwbVFpdTEwYWVTdnJnMVBKVmdfV1dfZ1kzajR3YkRneWhxdWFfZ9IBXEFVX3lxTE92QmdCelJxVHVnb1cxYVlYdi1DVGVDd001NFhsa3FWYmFzZUpSUG44b2Rzc1ljVmw5bWxqdC16X1lQeXM3MnBGLUQzb3dHdWQ1TW5ST2JEUzhnekFq?oc=5',\n",
       "  'content': '윤석열 탄핵 선고일 ‘갑호비상’…전국 경찰 서울 동원 - 경향신문'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiakFVX3lxTFBMM0p2bU5JSzF5YWJEN3VuYkE3S3IzYWItaUtfaFYza1BqLUFlQ0YwRkJqa0QxeWJLZXZSMFNhSzc5cGUwQ0k0aXAxbE1TQ0d0bFlZTEhjMHNYdEExTUlkUW9zTFF6bGVVNVE?oc=5',\n",
       "  'content': \"[단독] 한림대 의대생도 '전원 복귀'… 미등록 의대 한 곳만 남았다 - 한국일보\"},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiWkFVX3lxTE1VcE50UDB3aWdlSFRSNmpXZUZPdnBHem4zT1dlWGhvM3YzdDRxaFAwX3FjZ3VVLV85WmtCRDBVaDQ2MEpNZmM0a1ZOQ25kNUtTa29RZ3V1QWpfQdIBVEFVX3lxTE5ydTg4dUpXYzFCbTFyMFN5NE84czhYZGwzWmx1MFNudG1peG9nYThPcVpKQWN6UHExTERfajJ0LVBVWWZFN1FJYWVwZngzZ0JfU2xDYw?oc=5',\n",
       "  'content': '이수정 \"장제원 명복 빈다…피해자 안전 꼭 도모해야\" - hankyung.com'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMingFBVV95cUxOR2NHR3pGdHZxOFlhWGlJbXdrRThjZkhHRTBtS1IxdGc4cl9hUkltdXZrS0t5VGhsLVNSQncyWDdjcEtTRnhXQkdtMExONnR5MEIzcE9qMlpTR1dtTVZ5UGdOVHd2OHIwbGQyWHNFSWhsZGtkYmlVVm9HcXNuYl9ZSm51QlRBaDdycWEyZGxJZXV6RHQwSF9UNzkwT0xqd9IBsgFBVV95cUxNc1YxSU9YcVhkYVRMck5LYmNYbkNUMDRPLVdab1dMWmJSM3ZtTFVyWTJLX1dMUV9JaDlNVnc5MmlacnY0UzZqQU9kX0wxV1MzOFkyZWE2Q081UWFuZnBPTW5jb2hLYTdGYWtNVnlXcEJjWlp2elVpQW9zRVRqU1Zycm5yNFRvOVNhc1hXSG1QOXNDdnM1ZFdtQUtyY0cwbHpCdTk0RTlKR1R6eTMxZmFvYTJn?oc=5',\n",
       "  'content': '무너지는 52층 다리 뛰어넘은 한국인 …“아내와 딸 걱정뿐이었다” - 조선일보'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최신 뉴스 검색\n",
    "news_tool.search_latest(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMiakFVX3lxTE8xeTBoWWYwaFJCRFBNXzgyXzN0V3hyM1VjNlVVYzJZaDRGQndRUmpMeFR5bGJTdlZwWFRrYVkwMXpnMUxSQnRXM0k3cWp3UWY5YXlMZHoxdmNxXzhHNTlPQi1md0hXc3VqYXc?oc=5',\n",
       "  'content': '뤼튼테크놀로지스, 총 1080억원 규모 시리즈B 투자 유치 마무리 - AI타임스'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiVkFVX3lxTE9samZIMnBPLTR4OXdpRk9aN2xQcXgwcFI4VTZyYkZ0eW5WS19nQm5uOGoybDlXYnNvOUVIaU5WUFF0cEZTVWIyUVFKT2RRMGJSektzQ0tR?oc=5',\n",
       "  'content': '소프트뱅크, 美에 1470조원 투자 검토…\"AI 로봇 산업단지 조성\" - 지디넷코리아'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiWkFVX3lxTE15MzVLdVZWU1VGVzFBbFB4M2ZJX1V3WEtzTTFxRm9EelQzQ2Q0cWFnaWx6X0tVdFFGbmRhakV2VjdLNDZQRTZSV3JyNTJacThTTWNWTUJMLVUwQdIBVEFVX3lxTFAwWHI5WkM3bzNGUGp4dDMzSExJR3BDYkV5RExGSmdpcXdEZGxlWVBvMFJiY2EtNUFUU3VXYnVfSjZYMHh2em1ZS3ItWkpkbWU4Z0hkTA?oc=5',\n",
       "  'content': 'GPU마저 투자 외면…AI반도체 고점론 확산 - hankyung.com'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드로 뉴스 검색\n",
    "news_tool.search_by_keyword(\"AI 투자\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import GoogleNews\n",
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# 키워드로 뉴스 검색하는 도구 생성\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    print(query)\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMibkFVX3lxTE1qMC1EYjRZOEpMNVBEVVpSNm1BX3A4a3FrdmEyOTdDNWdjMGR1ZEgzWlpHZnRFZ1pSUXdKa3JnOXBQZU5qU3dKS3Q5VUNwLVZxRFZmbG1SZzJVSUoyM2lJbnZRbzhYYUJJcnFHWmp3?oc=5',\n",
       "  'content': '랭체인 LangChain 이란 무엇인가? | 인사이트리포트 | 삼성SDS - Samsung SDS'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiREFVX3lxTE9GcXU2aXlfUU42ZlZ0SXZreDJCeVd2VTlCUkQ1am45eE0tMThLQTJWYXJ3ZGFRN3RFUHdocUN0QzRfSk1L?oc=5',\n",
       "  'content': 'GUAVA AI 칼럼 : 뒤늦은 MCP 체험기 - 브런치스토리'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMilwFBVV95cUxNUklRWmZNZ3Y0ektzRm9scVR1UmI0Q0Z6NFh0MWxBYTlsOEFDdTBzYUY4UERva19HSnBLdElYVHBRbjV6NU52MDJtQ0xZOVlXb2VCak5VSVRrZ1FRMFZTaUNqUTBPMnN6cXVlWi1nUWNWNXZrOXRzWjVrZThQYXZBQjV6MG1EMmdxR2V3NHhUWW84ZDU3YWFB?oc=5',\n",
       "  'content': 'NVIDIA와 LangChain이 진행하는 생성형 AI 에이전트 개발자 컨테스트 - NVIDIA'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiXkFVX3lxTE43LUlDR2ZGZzJYQlRMNlJiZzRZV1NEQkJLZjBWZUpnU0FHT2VtcUJBaHY3N21WQ2h6OGpQaWhjbl9pTHBVR0pNZHNvQTgwNW1IQWpiVGc0OUd4aE1LUkHSAVZBVV95cUxQQXpCVkxiVnl6djBwdktSRWszYklXYVl6T3ZfNjNhcDI5SFNqRkctN09BWVliMVFwOTVwWXVHVVpySmhYU1FHM1hCdzd6OU9QNWh6V3RlZw?oc=5',\n",
       "  'content': '송파새일센터, 2025년 JAVA&Spring 백엔드 개발자 과정 교육생 모집 - 피앤피뉴스'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiakFVX3lxTE5SRG5pSjVLS0ZfZGZHQjN4Yk5jX0VqLWFCWFpDajdSRzhWTXNMZndzV09NWnkwMmlpaVRZWU14SjljR3BxOTVfRUxuMmwtbmhCTHhSMDJsZjU5MUVxcGg3NUN4ZlJoSHU0Q3fSAW5BVV95cUxNRG9weC15VUx4ZERDYmFZOF9DRExwWlRxLUFXRFJPNEhrSGpLNExkNFJDMng1YVoyY3hVcm82VW0wVW9tc1lWVDN0RjFEVUQ0RGlHWGQ5WWluMUNwRzQyQ3pCZTIwS0wtRlpGVGVFZw?oc=5',\n",
       "  'content': '주목해야 할 5대 기술 전망 “AI·랭체인·클라우드 전문가·SLM·데이터 전문가” - 지티티코리아'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_keyword.invoke({\"query\": \"LangChain AI\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-h6vp0ZFq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
