{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë„êµ¬ (Tools)\n",
    "\n",
    "ë„êµ¬(Tool)ëŠ” ì—ì´ì „íŠ¸, ì²´ì¸ ë˜ëŠ” LLMì´ ì™¸ë¶€ ì„¸ê³„ì™€ ìƒí˜¸ìž‘ìš©í•˜ê¸° ìœ„í•œ ì¸í„°íŽ˜ì´ìŠ¤ìž…ë‹ˆë‹¤.\n",
    "\n",
    "LangChain ì—ì„œ ê¸°ë³¸ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìžˆìœ¼ë©°, ì‚¬ìš©ìž ì •ì˜ ë„êµ¬(Custom Tool) ë¥¼ ì‰½ê²Œ êµ¬ì¶•í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "**LangChain ì— í†µí•©ëœ ë„êµ¬ ë¦¬ìŠ¤íŠ¸ëŠ” ì•„ëž˜ ë§í¬ì—ì„œ í™•ì¸í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.**\n",
    "\n",
    "- [LangChain í†µí•©ëœ ë„êµ¬ ë¦¬ìŠ¤íŠ¸](https://python.langchain.com/v0.1/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œìž‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CH12-Tools\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ìž…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"CH12-Tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë¹ŒíŠ¸ì¸ ë„êµ¬(built-in tools)\n",
    "\n",
    "ëž­ì²´ì¸ì—ì„œ ì œê³µí•˜ëŠ” ì‚¬ì „ì— ì •ì˜ëœ ë„êµ¬(tool) ì™€ íˆ´í‚·(toolkit) ì„ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "tool ì€ ë‹¨ì¼ ë„êµ¬ë¥¼ ì˜ë¯¸í•˜ë©°, toolkit ì€ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ë¬¶ì–´ì„œ í•˜ë‚˜ì˜ ë„êµ¬ë¡œ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê´€ë ¨ ë„êµ¬ëŠ” ì•„ëž˜ì˜ ë§í¬ì—ì„œ ì°¸ê³ í•˜ì‹¤ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "- [LangChain Tools/Toolkits](https://python.langchain.com/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python REPL ë„êµ¬\n",
    "\n",
    "ì´ ë„êµ¬ëŠ” Python ì½”ë“œë¥¼ REPL(Read-Eval-Print Loop) í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í´ëž˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤\n",
    "- PythonREPLTool\n",
    "\n",
    "**ì„¤ëª…**\n",
    "\n",
    "- Python ì…¸ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- ìœ íš¨í•œ Python ëª…ë ¹ì–´ë¥¼ ìž…ë ¥ìœ¼ë¡œ ë°›ì•„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "- ê²°ê³¼ë¥¼ ë³´ë ¤ë©´ print(...) í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” íŠ¹ì§•**\n",
    "\n",
    "- sanitize_input: ìž…ë ¥ì„ ì •ì œí•˜ëŠ” ì˜µì…˜ (ê¸°ë³¸ê°’: True)\n",
    "- python_repl: PythonREPL ì¸ìŠ¤í„´ìŠ¤ (ê¸°ë³¸ê°’: ì „ì—­ ë²”ìœ„ì—ì„œ ì‹¤í–‰)\n",
    "\n",
    "**ì‚¬ìš© ë°©ë²•**\n",
    "\n",
    "- PythonREPLTool ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "- run ë˜ëŠ” arun, invoke ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ Python ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "**ìž…ë ¥ ì •ì œ**\n",
    "\n",
    "- ìž…ë ¥ ë¬¸ìžì—´ì—ì„œ ë¶ˆí•„ìš”í•œ ê³µë°±, ë°±í‹±, 'python' í‚¤ì›Œë“œ ë“±ì„ ì œê±°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë„êµ¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "python_tool = PythonREPLTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "print(python_tool.invoke(\"print(100 + 200)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ëž˜ëŠ” LLM ì—ê²Œ íŒŒì´ì¬ ì½”ë“œë¥¼ ìž‘ì„±í•˜ë„ë¡ ìš”ì²­í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ˆì œìž…ë‹ˆë‹¤.\n",
    "\n",
    "**íë¦„ ì •ë¦¬**\n",
    "1. LLM ëª¨ë¸ì—ê²Œ íŠ¹ì • ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” Python ì½”ë“œë¥¼ ìž‘ì„±í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "2. ìž‘ì„±ëœ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "3. ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "# íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ì¤‘ê°„ ê³¼ì •ì„ ì¶œë ¥í•˜ê³  ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def print_and_execute(code, debug=True):\n",
    "    if debug:\n",
    "        print(\"CODE:\")\n",
    "        print(code)\n",
    "    return python_tool.invoke(code)\n",
    "\n",
    "\n",
    "# íŒŒì´ì¬ ì½”ë“œë¥¼ ìž‘ì„±í•˜ë„ë¡ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are Raymond Hetting, an expert python programmer, well versed in meta-programming and elegant, concise and short but well documented code. You follow the PEP8 style guide. \"\n",
    "            \"Return only the code, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the code.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "# LLM ëª¨ë¸ ìƒì„±\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ì™€ LLM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE:\n",
      "import random\n",
      "\n",
      "def generate_lotto_numbers():\n",
      "    return sorted(random.sample(range(1, 46), 6))\n",
      "\n",
      "print(generate_lotto_numbers())\n",
      "[2, 4, 16, 23, 30, 32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(chain.invoke(\"ë¡œë˜ ë²ˆí˜¸ ìƒì„±ê¸°ë¥¼ ì¶œë ¥í•˜ëŠ” ì½”ë“œë¥¼ ìž‘ì„±í•˜ì„¸ìš”.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê²€ìƒ‰ API ë„êµ¬\n",
    "\n",
    "Tavily ê²€ìƒ‰ APIë¥¼ í™œìš©í•˜ì—¬ ê²€ìƒ‰ ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤. ì´ ë„êµ¬ëŠ” ë‘ ê°€ì§€ ì£¼ìš” í´ëž˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤: `TavilySearchResults`ì™€ `TavilyAnswer`.\n",
    "\n",
    "**API í‚¤ ë°œê¸‰ ì£¼ì†Œ**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "ë°œê¸‰í•œ API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "`.env` íŒŒì¼ì— ì•„ëž˜ì™€ ê°™ì´ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**ì„¤ëª…**\n",
    "- Tavily ê²€ìƒ‰ APIë¥¼ ì¿¼ë¦¬í•˜ê³  JSON í˜•ì‹ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- í¬ê´„ì ì´ê³  ì •í™•í•˜ë©° ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ê²°ê³¼ì— ìµœì í™”ëœ ê²€ìƒ‰ ì—”ì§„ìž…ë‹ˆë‹¤.\n",
    "- í˜„ìž¬ ì´ë²¤íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë§¤ê°œë³€ìˆ˜**\n",
    "- `max_results` (int): ë°˜í™˜í•  ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n",
    "- `search_depth` (str): ê²€ìƒ‰ ê¹Šì´ (\"basic\" ë˜ëŠ” \"advanced\")\n",
    "- `include_domains` (List[str]): ê²€ìƒ‰ ê²°ê³¼ì— í¬í•¨í•  ë„ë©”ì¸ ëª©ë¡\n",
    "- `exclude_domains` (List[str]): ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œì™¸í•  ë„ë©”ì¸ ëª©ë¡\n",
    "- `include_answer` (bool): ì›ë³¸ ì¿¼ë¦¬ì— ëŒ€í•œ ì§§ì€ ë‹µë³€ í¬í•¨ ì—¬ë¶€\n",
    "- `include_raw_content` (bool): ê° ì‚¬ì´íŠ¸ì˜ ì •ì œëœ HTML ì½˜í…ì¸  í¬í•¨ ì—¬ë¶€\n",
    "- `include_images` (bool): ì¿¼ë¦¬ ê´€ë ¨ ì´ë¯¸ì§€ ëª©ë¡ í¬í•¨ ì—¬ë¶€\n",
    "\n",
    "**ë°˜í™˜ ê°’**\n",
    "- ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ì˜ ë¬¸ìžì—´(url, content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í˜¹ì€ ì•„ëž˜ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ë°œê¸‰ë°›ì€ API í‚¤ë¥¼ ìž…ë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"TAVILY API í‚¤ ìž…ë ¥\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# ë„êµ¬ ìƒì„±\n",
    "tool = TavilySearchResults(\n",
    "    max_results=6,\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    # include_images=True,\n",
    "    # search_depth=\"advanced\", # or \"basic\"\n",
    "    include_domains=[\"github.io\", \"wikidocs.net\"],\n",
    "    # exclude_domains = []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LangGraph Quickstart',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/tutorials/introduction/',\n",
       "  'content': \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-23)   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-25)6. Significance:\",\n",
       "  'score': 0.6259742717333333,\n",
       "  'raw_content': 'Learn the basics\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLearn the basics\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: ðŸ› ï¸ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nDeployment\\n\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\n\\n[ ] \\nTutorials\\nTutorials\\n\\n\\n[ ] \\nQuick Start\\nQuick Start\\n\\nQuick Start\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: ðŸ› ï¸ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\n\\n\\nLocal Deploy\\n\\nCloud Deploy\\n\\n\\n\\nChatbots\\n\\nRAG\\nAgent Architectures\\nEvaluation & Analysis\\nExperimental\\nLangGraph Platform\\n\\n\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\nPart 1: Build a Basic Chatbot\\n\\nPart 2: ðŸ› ï¸ Enhancing the Chatbot with Tools\\n\\nRequirements\\n\\n\\n\\nPart 3: Adding Memory to the Chatbot\\n\\nPart 4: Human-in-the-loop\\n\\nPart 5: Customizing State\\n\\nManually updating state\\n\\n\\n\\nPart 6: Time Travel\\n\\n\\nNext Steps\\n\\nServer Quickstart\\nLangGraph Cloud\\nLangGraph Framework\\nLangGraph Platform\\n\\n\\n\\nHome\\n\\nGuides\\nTutorials\\nQuick Start\\n\\n\\nðŸš€ LangGraph QuickstartÂ¶\\nIn this tutorial, we will build a support chatbot in LangGraph that can:\\nâœ… Answer common questions by searching the web\\nâœ… Maintain conversation state across calls\\nâœ… Route complex queries to a human for review\\nâœ… Use custom state to control its behavior\\nâœ… Rewind and explore alternative conversation paths\\nWe\\'ll start with a basic chatbot and progressively add more sophisticated capabilities, introducing key LangGraph concepts along the way. Letâ€™s dive in! ðŸŒŸ\\nSetupÂ¶\\nFirst, install the required packages and configure your environment:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-0-2)%pip install -U langgraph langsmith langchain_anthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-1)importgetpass\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-2)importos\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-5)def_set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-1-10)_set_env(\"ANTHROPIC_API_KEY\")\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started here.\\nPart 1: Build a Basic ChatbotÂ¶\\nWe\\'ll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Though simple, it will illustrate the core concepts of building with LangGraph. By the end of this section, you will have a built rudimentary chatbot.\\nStart by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We\\'ll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-6)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-9)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-10)    # Messages have the type \"list\". The `add_messages` function\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-11)    # in the annotation defines how this state key should be updated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-12)    # (in this case, it appends messages to the list, rather than overwriting them)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-13)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-2-16)graph_builder = StateGraph(State)\\nAPI Reference: StateGraph | START | END | add_messages\\nOur graph can now handle two key tasks:\\n\\nEach node can receive the current State as input and output an update to the state.\\nUpdates to messages will be appended to the existing list rather than overwriting it, thanks to the prebuilt add_messages function used with the Annotated syntax.\\n\\n\\nConcept\\nWhen defining a graph, the first step is to define its State. The State includes the graph\\'s schema and reducer functions that handle state updates. In our example, State is a TypedDict with one key: messages. The add_messages reducer function is used to append new messages to the list instead of overwriting it. Keys without a reducer annotation will overwrite previous values. Learn more about state, reducers, and related concepts in this guide.\\n\\nNext, add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-3)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-6)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-7)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-10)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-11)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-12)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-3-13)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic\\nNotice how the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\nThe add_messages function in our State will append the llm\\'s response messages to whatever messages are already in the state.\\nNext, add an entry point. This tells our graph where to start its work each time we run it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-4-1)graph_builder.add_edge(START, \"chatbot\")\\nSimilarly, set a finish point. This instructs the graph \"any time this node is run, you can exit.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-5-1)graph_builder.add_edge(\"chatbot\", END)\\nFinally, we\\'ll want to be able to run our graph. To do so, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-6-1)graph = graph_builder.compile()\\nYou can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-7-7)    pass\\n\\nNow let\\'s run the chatbot!\\nTip: You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\".\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-1)defstream_graph_updates(user_input: str):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-2)    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-3)        for value in event.values():\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-4)            print(\"Assistant:\", value[\"messages\"][-1].content)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-7)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-8)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-9)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-10)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-11)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-12)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-14)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-15)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-16)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-17)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-18)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-19)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-8-20)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It\\'s particularly useful for developing more complex, stateful AI applications that go beyond simple query-response interactions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-2)Goodbye!\\nCongratulations! You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a LangSmith Trace for the call above at the provided link.\\nHowever, you may have noticed that the bot\\'s knowledge is limited to what\\'s in its training data. In the next part, we\\'ll add a web search tool to expand the bot\\'s knowledge and make it more capable.\\nBelow is the full code for this section for your reference:\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-6)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-20)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-21)    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-24)# The first argument is the unique node name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-25)# The second argument is the function or object that will be called whenever\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-26)# the node is used.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-27)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-28)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-29)graph_builder.set_finish_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-10-30)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | StateGraph | add_messages\\nPart 2: ðŸ› ï¸ Enhancing the Chatbot with ToolsÂ¶\\nTo handle queries our chatbot can\\'t answer \"from memory\", we\\'ll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses.\\nRequirementsÂ¶\\nBefore we start, make sure you have the necessary packages installed and API keys set up:\\nFirst, install the requirements to use the Tavily Search Engine, and set your TAVILY_API_KEY.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-11-2)%pip install -U tavily-python langchain_community\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-12-1)_set_env(\"TAVILY_API_KEY\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-13-1)TAVILY_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\\nNext, define the tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-1)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-3)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-4)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-14-5)tool.invoke(\"What\\'s a \\'node\\' in LangGraph?\")\\nAPI Reference: TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-1)[{\\'url\\': \\'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-2)  \\'content\\': \\'Nodes: Nodes are the building blocks of your LangGraph. Each node represents a function or a computation step. You define nodes to perform specific tasks, such as processing input, making ...\\'},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-3) {\\'url\\': \\'https://saksheepatil05.medium.com/demystifying-langgraph-a-beginner-friendly-dive-into-langgraph-concepts-5ffe890ddac0\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-15-4)  \\'content\\': \\'Nodes (Tasks): Nodes are like the workstations on the assembly line. Each node performs a specific task on the product. In LangGraph, nodes are Python functions that take the current state, do some work, and return an updated state. Next, we define the nodes, each representing a task in our sandwich-making process.\\'}]\\nThe results are page summaries our chat bot can use to answer questions.\\nNext, we\\'ll start defining our graph. The following is all the same as in Part 1, except we have added bind_tools on our LLM. This lets the LLM know the correct JSON format to use if it wants to use our search engine.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-6)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-9)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-10)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-11)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-14)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-17)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-18)# Modification: tell the LLM which tools it can call\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-19)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-22)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-23)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-16-26)graph_builder.add_node(\"chatbot\", chatbot)\\nAPI Reference: ChatAnthropic | StateGraph | START | END | add_messages\\nNext we need to create a function to actually run the tools if they are called. We\\'ll do this by adding the tools to a new node.\\nBelow, we implement a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM\\'s tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers.\\nWe will later replace this with LangGraph\\'s prebuilt ToolNode to speed things up, but building it ourselves first is instructive.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-1)importjson\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-3)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-6)classBasicToolNode:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-7)\"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-9)    def__init__(self, tools: list) -> None:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-10)        self.tools_by_name = {tool.name: tool for tool in tools}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-12)    def__call__(self, inputs: dict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-13)        if messages := inputs.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-14)            message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-15)        else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-16)            raise ValueError(\"No message found in input\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-17)        outputs = []\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-18)        for tool_call in message.tool_calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-19)            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-20)                tool_call[\"args\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-21)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-22)            outputs.append(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-23)                ToolMessage(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-24)                    content=json.dumps(tool_result),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-25)                    name=tool_call[\"name\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-26)                    tool_call_id=tool_call[\"id\"],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-27)                )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-28)            )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-29)        return {\"messages\": outputs}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-32)tool_node = BasicToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-17-33)graph_builder.add_node(\"tools\", tool_node)\\nAPI Reference: ToolMessage\\nWith the tool node added, we can define the conditional_edges.\\nRecall that edges route the control flow from one node to the next. Conditional edges usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\\nBelow, call define a router function called route_tools, that checks for tool_calls in the chatbot\\'s output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next.\\nThe condition will route to tools if tool calls are present and END if not.\\nLater, we will replace this with the prebuilt tools_condition to be more concise, but implementing it ourselves first makes things more clear.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-1)defroute_tools(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-2)    state: State,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-3)):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-4)\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-5)    Use in the conditional_edge to route to the ToolNode if the last message\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-6)    has tool calls. Otherwise, route to the end.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-7)    \"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-8)    if isinstance(state, list):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-9)        ai_message = state[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-10)    elif messages := state.get(\"messages\", []):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-11)        ai_message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-12)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-13)        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-14)    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-15)        return \"tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-16)    return END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-19)# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-20)# it is fine directly responding. This conditional routing defines the main agent loop.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-21)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-22)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-23)    route_tools,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-24)    # The following dictionary lets you tell the graph to interpret the condition\\'s outputs as a specific node\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-25)    # It defaults to the identity function, but if you\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-26)    # want to use a node named something else apart from \"tools\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-27)    # You can update the value of the dictionary to something else\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-28)    # e.g., \"tools\": \"my_tools\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-29)    {\"tools\": \"tools\", END: END},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-31)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-32)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-33)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-18-34)graph = graph_builder.compile()\\nNotice that conditional edges start from a single node. This tells the graph \"any time the \\'chatbot\\' node runs, either go to \\'tools\\' if it calls a tool, or end the loop if it responds directly.\\nLike the prebuilt tools_condition, our function returns the END string if no tool calls are made. When the graph transitions to END, it has no more tasks to complete and ceases execution. Because the condition can return END, we don\\'t need to explicitly set a finish_point this time. Our graph already has a way to finish!\\nLet\\'s visualize the graph we\\'ve built. The following function has some additional dependencies to run that are unimportant for this tutorial.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-19-7)    pass\\n\\nNow we can ask the bot questions outside its training data.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-1)while True:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-2)    try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-3)        user_input = input(\"User: \")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-4)        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-5)            print(\"Goodbye!\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-6)            break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-8)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-9)    except:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-10)        # fallback if input() is not available\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-11)        user_input = \"What do you know about LangGraph?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-12)        print(\"User: \" + user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-13)        stream_graph_updates(user_input)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-20-14)        break\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-1)Assistant: [{\\'text\\': \"To provide you with accurate and up-to-date information about LangGraph, I\\'ll need to search for the latest details. Let me do that for you.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01Q588CszHaSvvP2MxRq9zRD\\', \\'input\\': {\\'query\\': \\'LangGraph AI tool information\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-2)Assistant: [{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph sets the foundation for how we can build and scale AI workloads \\\\u2014 from conversational agents, complex task automation, to custom LLM-backed experiences that \\'just work\\'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution ...\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-3)Assistant: Based on the search results, I can provide you with information about LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-5)1. Purpose:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It\\'s particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-9)   LangGraph is developed by LangChain, a company known for its tools and frameworks in the AI and LLM space.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-10)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-11)3. Key Features:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-12)   - Cycles: LangGraph allows the definition of flows that involve cycles, which is essential for most agentic architectures.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-13)   - Controllability: It offers enhanced control over the application flow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-14)   - Persistence: The library provides ways to maintain state and persistence in LLM-based applications.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-16)4. Use Cases:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-17)   LangGraph can be used for various applications, including:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-18)   - Conversational agents\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-19)   - Complex task automation\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-20)   - Custom LLM-backed experiences\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-22)5. Integration:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-23)   LangGraph works in conjunction with LangSmith, another tool by LangChain, to provide an out-of-the-box solution for building complex, production-ready features with LLMs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-25)6. Significance:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-26)   LangGraph is described as setting the foundation for building and scaling AI workloads. It\\'s positioned as a key tool in the next chapter of LLM-based application development, particularly in the realm of agentic AI.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-28)7. Availability:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-29)   LangGraph is open-source and available on GitHub, which suggests that developers can access and contribute to its codebase.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-31)8. Comparison to Other Frameworks:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-32)   LangGraph is noted to offer unique benefits compared to other LLM frameworks, particularly in its ability to handle cycles, provide controllability, and maintain persistence.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-34)LangGraph appears to be a significant tool in the evolving landscape of LLM-based application development, offering developers new ways to create more complex, stateful, and interactive AI systems.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-35)Goodbye!\\nCongrats! You\\'ve created a conversational agent in langgraph that can use a search engine to retrieve updated information when needed. Now it can handle a wider range of user queries. To inspect all the steps your agent just took, check out this LangSmith trace.\\nOur chatbot still can\\'t remember past interactions on its own, limiting its ability to have coherent, multi-turn conversations. In the next part, we\\'ll add memory to address this.\\nThe full code for the graph we\\'ve created in this section is reproduced below, replacing our BasicToolNode for the prebuilt ToolNode, and our route_tools condition with the prebuilt tools_condition\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-8)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-22-42)graph = graph_builder.compile()\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | add_messages | ToolNode | tools_condition\\nPart 3: Adding Memory to the ChatbotÂ¶\\nOur chatbot can now use tools to answer user questions, but it doesn\\'t remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\\nLangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off.\\nWe will see later that checkpointing is much more powerful than simple chat memory - it lets you save and resume complex state at any time for error recovery, human-in-the-loop workflows, time travel interactions, and more. But before we get too ahead of ourselves, let\\'s add checkpointing to enable multi-turn conversations.\\nTo get started, create a MemorySaver checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-1)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-23-3)memory = MemorySaver()\\nAPI Reference: MemorySaver\\nNotice we\\'re using an in-memory checkpointer. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect to your own DB.\\nNext define the graph. Now that you\\'ve already built your own BasicToolNode, we\\'ll replace it with LangGraph\\'s prebuilt ToolNode and tools_condition, since these do some nice things like parallel API execution. Apart from that, the following is all copied from Part 2.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-8)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-9)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-10)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-13)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-14)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-17)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-20)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-21)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-22)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-23)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-26)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-27)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-30)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-32)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-33)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-35)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-36)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-37)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-38))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-39)# Any time a tool is called, we return to the chatbot to decide the next step\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-24-41)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nFinally, compile the graph with the provided checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-25-1)graph = graph_builder.compile(checkpointer=memory)\\nNotice the connectivity of the graph hasn\\'t changed since Part 2. All we are doing is checkpointing the State as the graph works through each node.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-26-7)    pass\\n\\nNow you can interact with your bot! First, pick a thread to use as the key for this conversation.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-27-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\nNext, call your chat bot.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-1)user_input = \"Hi there! My name is Will.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-28-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-3)Hi there! My name is Will.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-29-6)Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\\nNote: The config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({\\'messages\\': []}).\\nLet\\'s ask a followup: see if it remembers your name.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-1)user_input = \"Remember my name?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-3)# The config is the **second positional argument** to stream() or invoke()!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-30-10)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-31-6)Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\\nNotice that we aren\\'t using an external list for memory: it\\'s all handled by the checkpointer! You can inspect the full execution in this LangSmith trace to see what\\'s going on.\\nDon\\'t believe me? Try this using a different config.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-1)# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-3)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-4)    {\"configurable\": {\"thread_id\": \"2\"}},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-5)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-7)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-32-8)    event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-3)Remember my name?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-33-6)I apologize, but I don\\'t have any previous context or memory of your name. As an AI assistant, I don\\'t retain information from past conversations. Each interaction starts fresh. Could you please tell me your name so I can address you properly in this conversation?\\nNotice that the only change we\\'ve made is to modify the thread_id in the config. See this call\\'s LangSmith trace for comparison.\\nBy now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph\\'s state for a given config at any time, call get_state(config).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-34-2)snapshot\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-35-1)StateSnapshot(values={\\'messages\\': [HumanMessage(content=\\'Hi there! My name is Will.\\', additional_kwargs={}, response_metadata={}, id=\\'8c1ca919-c553-4ebf-95d4-b59a2d61e078\\'), AIMessage(content=\"Hello Will! It\\'s nice to meet you. How can I assist you today? Is there anything specific you\\'d like to know or discuss?\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01WTQebPhNwmMrmmWojJ9KXJ\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 405, \\'output_tokens\\': 32}}, id=\\'run-58587b77-8c82-41e6-8a90-d62c444a261d-0\\', usage_metadata={\\'input_tokens\\': 405, \\'output_tokens\\': 32, \\'total_tokens\\': 437}), HumanMessage(content=\\'Remember my name?\\', additional_kwargs={}, response_metadata={}, id=\\'daba7df6-ad75-4d6b-8057-745881cea1ca\\'), AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}, next=(), config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-93e0-6acc-8004-f2ac846575d2\\'}}, metadata={\\'source\\': \\'loop\\', \\'writes\\': {\\'chatbot\\': {\\'messages\\': [AIMessage(content=\"Of course, I remember your name, Will. I always try to pay attention to important details that users share with me. Is there anything else you\\'d like to talk about or any questions you have? I\\'m here to help with a wide range of topics or tasks.\", additional_kwargs={}, response_metadata={\\'id\\': \\'msg_01E41KitY74HpENRgXx94vag\\', \\'model\\': \\'claude-3-5-sonnet-20240620\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 444, \\'output_tokens\\': 58}}, id=\\'run-ffeaae5c-4d2d-4ddb-bd59-5d5cbf2a5af8-0\\', usage_metadata={\\'input_tokens\\': 444, \\'output_tokens\\': 58, \\'total_tokens\\': 502})]}}, \\'step\\': 4, \\'parents\\': {}}, created_at=\\'2024-09-27T19:30:10.820758+00:00\\', parent_config={\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1ef7d06e-859f-6206-8003-e1bd3c264b8f\\'}}, tasks=())\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-36-1)snapshot.next  # (since the graph ended this turn, `next` is empty. If you fetch a state from within a graph invocation, next tells which node will execute next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-37-1)()\\nThe snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an END state, so next is empty.\\nCongratulations! Your chatbot can now maintain conversation state across sessions thanks to LangGraph\\'s checkpointing system. This opens up exciting possibilities for more natural, contextual interactions. LangGraph\\'s checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory.\\nIn the next part, we\\'ll introduce human oversight to our bot to handle situations where it may need guidance or verification before proceeding.\\nCheck out the code snippet below to review our graph from this section.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-9)fromlanggraph.graphimport StateGraph\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-11)fromlanggraph.prebuiltimport ToolNode\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-41)graph_builder.set_entry_point(\"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-42)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-38-43)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | add_messages | ToolNode\\nPart 4: Human-in-the-loopÂ¶\\nAgents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended.\\nLangGraph\\'s persistence layer supports human-in-the-loop workflows, allowing execution to pause and resume based on user feedback. The primary interface to this functionality is the interrupt function. Calling interrupt inside a node will pause execution. Execution can be resumed, together with new input from a human, by passing in a Command. interrupt is ergonomically similar to Python\\'s built-in input(), with some caveats. We demonstrate an example below.\\nFirst, start with our existing code from Part 3. We will make one change, which is to add a simple human_assistance tool accessible to the chatbot. This tool uses interrupt to receive information from a human.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-16)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-17)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-20)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-24)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-25)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-26)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-27)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-30)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-31)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-32)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-33)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-36)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-37)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-38)    # Because we will be interrupting during tool execution,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-39)    # we disable parallel tool calling to avoid repeating any\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-40)    # tool invocations when we resume.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-41)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-42)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-45)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-47)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-48)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-49)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-50)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-51)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-52)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-53))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-54)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-39-55)graph_builder.add_edge(START, \"chatbot\")\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\n\\nTip\\nCheck out the Human-in-the-loop section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\n\\nWe compile the graph with a checkpointer, as before:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-1)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-40-3)graph = graph_builder.compile(checkpointer=memory)\\nVisualizing the graph, we recover the same layout as before. We have just added a tool!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-3)try:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-41-7)    pass\\n\\nLet\\'s now prompt the chatbot with a question that will engage the new human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-1)user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-2)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-4)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-5)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-6)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-7)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-8))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-42-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-3)I need some expert guidance for building an AI agent. Could you request assistance for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-6)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-8)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-9) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-43-11)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\nThe chatbot generated a tool call, but then execution has been interrupted! Note that if we inspect the graph state, we see that it stopped at the tools node:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-44-2)snapshot.next\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-45-1)(\\'tools\\',)\\nLet\\'s take a closer look at the human_assistance tool:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-1)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-2)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-3)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-4)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-46-5)    return human_response[\"data\"]\\nSimilar to Python\\'s built-in input() function, calling interrupt inside the tool will pause execution. Progress is persisted based on our choice of checkpointer-- so if we are persisting with Postgres, we can resume at any time as long as the database is alive. Here we are persisting with the in-memory checkpointer, so we can resume any time as long as our Python kernel is running.\\nTo resume execution, we pass a Command object containing data expected by the tool. The format of this data can be customized based on our needs. Here, we just need a dict with a key \"data\":\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-1)human_response = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-2)    \"We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-3)    \" It\\'s much more reliable and extensible than simple autonomous agents.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-6)human_command = Command(resume={\"data\": human_response})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-47-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-3)[{\\'text\\': \"Certainly! I\\'d be happy to request expert assistance for you regarding building an AI agent. To do this, I\\'ll use the human_assistance function to relay your request. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01ABUqneqnuHNuo1vhfDFQCW\\', \\'input\\': {\\'query\\': \\'A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-5)  human_assistance (toolu_01ABUqneqnuHNuo1vhfDFQCW)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-6) Call ID: toolu_01ABUqneqnuHNuo1vhfDFQCW\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-8)    query: A user is requesting expert guidance for building an AI agent. Could you please provide some expert advice or resources on this topic?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-10)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-12)We, the experts are here to help! We\\'d recommend you check out LangGraph to build your agent. It\\'s much more reliable and extensible than simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-15)Thank you for your patience. I\\'ve received some expert advice regarding your request for guidance on building an AI agent. Here\\'s what the experts have suggested:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-17)The experts recommend that you look into LangGraph for building your AI agent. They mention that LangGraph is a more reliable and extensible option compared to simple autonomous agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-21)1. Reliability: The experts emphasize that LangGraph is more reliable than simpler autonomous agent approaches. This could mean it has better stability, error handling, or consistent performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-23)2. Extensibility: LangGraph is described as more extensible, which suggests that it probably offers a flexible architecture that allows you to easily add new features or modify existing ones as your agent\\'s requirements evolve.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-24)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-25)3. Advanced capabilities: Given that it\\'s recommended over \"simple autonomous agents,\" LangGraph likely provides more sophisticated tools and techniques for building complex AI agents.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-27)To get started with LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-29)1. Search for the official LangGraph documentation or website to learn more about its features and how to use it.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-30)2. Look for tutorials or guides specifically focused on building AI agents with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-31)3. Check if there are any community forums or discussion groups where you can ask questions and get support from other developers using LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-33)If you\\'d like more specific information about LangGraph or have any questions about this recommendation, please feel free to ask, and I can request further assistance from the experts.\\nOur input has been received and processed as a tool message. Review this call\\'s LangSmith trace to see the exact work that was done in the above call. Notice that the state is loaded in the first step so that our chatbot can continue where it left off.\\nCongrats! You\\'ve used an interrupt to add human-in-the-loop execution to your chatbot, allowing for human oversight and intervention when needed. This opens up the potential UIs you can create with your AI systems. Since we have already added a checkpointer, as long as the underlying persistence layer is running, the graph can be paused indefinitely and resumed at any time as if nothing had happened.\\nHuman-in-the-loop workflows enable a variety of new workflows and user experiences. Check out this section of the How-to Guides for more examples of Human-in-the-loop workflows, including how to review and edit tool calls before they are executed.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-12)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-15)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-16)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-18)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-19)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-22)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-23)defhuman_assistance(query: str) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-24)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-25)    human_response = interrupt({\"query\": query})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-26)    return human_response[\"data\"]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-29)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-30)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-31)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-32)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-35)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-36)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-37)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-38)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-40)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-41)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-43)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-44)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-46)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-47)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-48)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-49))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-50)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-51)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-52)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-53)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-49-54)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 5: Customizing StateÂ¶\\nSo far, we\\'ve relied on a simple state with one entry-- a list of messages. You can go far with this simple state, but if you want to define complex behavior without relying on the message list, you can add additional fields to the state. Here we will demonstrate a new scenario, in which the chatbot is using its search tool to find specific information, and forwarding them to a human for review. Let\\'s have the chatbot research the birthday of an entity. We will add name and birthday keys to the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-3)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-4)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-5)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-8)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-9)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-10)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-50-11)    birthday: str\\nAPI Reference: add_messages\\nAdding this information to the state makes it easily accessible by other graph nodes (e.g., a downstream node that stores or processes the information), as well as the graph\\'s persistence layer.\\nHere, we will populate the state keys inside of our human_assistance tool. This allows a human to review the information before it is stored in the state. We will again use Command, this time to issue a state update from inside our tool. Read more about use cases for Command here.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-1)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-2)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-4)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-7)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-8)# Note that because we are generating a ToolMessage for a state update, we\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-9)# generally require the ID of the corresponding tool call. We can use\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-10)# LangChain\\'s InjectedToolCallId to signal that this argument should not\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-11)# be revealed to the model in the tool\\'s schema.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-12)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-13)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-14)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-15)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-16)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-17)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-18)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-19)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-20)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-21)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-22)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-23)    # If the information is correct, update the state as-is.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-24)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-25)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-26)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-27)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-28)    # Otherwise, receive information from the human reviewer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-29)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-30)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-31)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-32)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-34)    # This time we explicitly update the state with a ToolMessage inside\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-35)    # the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-36)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-37)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-38)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-39)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-40)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-41)    # We return a Command object in the tool to update our state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-51-42)    return Command(update=state_update)\\nAPI Reference: ToolMessage | InjectedToolCallId | tool | Command | interrupt\\nOtherwise, the rest of our graph is the same:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-1)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-2)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-3)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-4)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-5)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-6)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-9)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-10)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-11)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-12)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-15)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-16)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-17)    assert len(message.tool_calls) <= 1\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-18)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-21)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-22)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-24)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-25)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-27)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-28)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-29)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-30))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-31)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-32)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-34)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-52-35)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | MemorySaver | StateGraph | START | END | ToolNode | tools_condition\\nLet\\'s prompt our application to look up the \"birthday\" of the LangGraph library. We will direct the chatbot to reach out to the human_assistance tool once it has the required information. Note that setting name and birthday in the arguments for the tool, we force the chatbot to generate proposals for these fields.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-1)user_input = (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-2)    \"Can you look up when LangGraph was released? \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-3)    \"When you have the answer, use the human_assistance tool for review.\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-4))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-5)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-6)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-7)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-8)    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-9)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-10)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-11))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-12)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-13)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-53-14)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-3)Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-6)[{\\'text\\': \"Certainly! I\\'ll start by searching for information about LangGraph\\'s release date using the Tavily search function. Then, I\\'ll use the human_assistance tool for review.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JoXQPgTVJXiuma8xMVwqAi\\', \\'input\\': {\\'query\\': \\'LangGraph release date\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-8)  tavily_search_results_json (toolu_01JoXQPgTVJXiuma8xMVwqAi)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-9) Call ID: toolu_01JoXQPgTVJXiuma8xMVwqAi\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-11)    query: LangGraph release date\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-15)[{\"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024 (Oct \\'24) Edit: Since the launch of LangGraph Cloud, we now have multiple deployment options alongside LangGraph Studio - which now fall under LangGraph Platform. LangGraph Cloud is synonymous with our Cloud SaaS deployment option.\"}, {\"url\": \"https://changelog.langchain.com/announcements/langgraph-cloud-deploy-at-scale-monitor-carefully-iterate-boldly\", \"content\": \"LangChain - Changelog | â˜ ðŸš€ LangGraph Cloud: Deploy at scale, monitor LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain LangSmith LangGraph LangChain Changelog Sign up for our newsletter to stay up to date DATE: The LangChain Team LangGraph LangGraph Cloud â˜ ðŸš€ LangGraph Cloud: Deploy at scale, monitor carefully, iterate boldly DATE: June 27, 2024 AUTHOR: The LangChain Team LangGraph Cloud is now in closed beta, offering scalable, fault-tolerant deployment for LangGraph agents. LangGraph Cloud also includes a new playground-like studio for debugging agent failure modes and quick iteration: Join the waitlist today for LangGraph Cloud. And to learn more, read our blog post announcement or check out our docs. Subscribe By clicking subscribe, you accept our privacy policy and terms and conditions.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-18)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-19)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-20)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-21) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-22)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-23)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-54-24)    birthday: 2023-01-01\\nWe\\'ve hit the interrupt in the human_assistance tool again. In this case, the chatbot failed to identify the correct date, so we can supply it:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-1)human_command = Command(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-2)    resume={\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-3)        \"name\": \"LangGraph\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-4)        \"birthday\": \"Jan 17, 2024\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-5)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-6))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-8)events = graph.stream(human_command, config, stream_mode=\"values\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-9)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-10)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-55-11)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-3)[{\\'text\\': \"Based on the search results, it appears that LangGraph was already in existence before June 27, 2024, when LangGraph Cloud was announced. However, the search results don\\'t provide a specific release date for the original LangGraph. \\\\n\\\\nGiven this information, I\\'ll use the human_assistance tool to review and potentially provide more accurate information about LangGraph\\'s initial release date.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01JDQAV7nPqMkHHhNs3j3XoN\\', \\'input\\': {\\'name\\': \\'Assistant\\', \\'birthday\\': \\'2023-01-01\\'}, \\'name\\': \\'human_assistance\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-5)  human_assistance (toolu_01JDQAV7nPqMkHHhNs3j3XoN)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-6) Call ID: toolu_01JDQAV7nPqMkHHhNs3j3XoN\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-8)    name: Assistant\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-9)    birthday: 2023-01-01\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-11)Name: human_assistance\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-13)Made a correction: {\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-16)Thank you for the human assistance. I can now provide you with the correct information about LangGraph\\'s release date.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-18)LangGraph was initially released on January 17, 2024. This information comes from the human assistance correction, which is more accurate than the search results I initially found.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-20)To summarize:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-21)1. LangGraph\\'s original release date: January 17, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-22)2. LangGraph Cloud announcement: June 27, 2024\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-56-24)It\\'s worth noting that LangGraph had been in development and use for some time before the LangGraph Cloud announcement, but the official initial release of LangGraph itself was on January 17, 2024.\\nNote that these fields are now reflected in the state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-57-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-58-1){\\'name\\': \\'LangGraph\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nThis makes them easily accessible to downstream nodes (e.g., a node that further processes or stores the information).\\nManually updating stateÂ¶\\nLangGraph gives a high degree of control over the application state. For instance, at any point (including when interrupted), we can manually override a key using graph.update_state:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-59-1)graph.update_state(config, {\"name\": \"LangGraph (library)\"})\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-1){\\'configurable\\': {\\'thread_id\\': \\'1\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-2)  \\'checkpoint_ns\\': \\'\\',\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-60-3)  \\'checkpoint_id\\': \\'1efd4ec5-cf69-6352-8006-9278f1730162\\'}}\\nIf we call graph.get_state, we can see the new value is reflected:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-1)snapshot = graph.get_state(config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-61-3){k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-62-1){\\'name\\': \\'LangGraph (library)\\', \\'birthday\\': \\'Jan 17, 2024\\'}\\nManual state updates will even generate a trace in LangSmith. If desired, they can also be used to control human-in-the-loop workflows, as described in this guide. Use of the interrupt function is generally recommended instead, as it allows data to be transmitted in a human-in-the-loop interaction independently of state updates.\\nCongratulations! You\\'ve added custom keys to the state to facilitate a more complex workflow, and learned how to generate state updates from inside tools.\\nWe\\'re almost done with the tutorial, but there is one more concept we\\'d like to review before finishing that connects checkpointing and state updates.\\nThis section\\'s code is reproduced below for your reference.\\nFull Code\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-5)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-6)fromlangchain_core.toolsimport InjectedToolCallId, tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-7)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-8)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-9)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-10)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-11)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-12)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-13)fromlanggraph.typesimport Command, interrupt\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-15)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-17)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-18)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-19)    name: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-20)    birthday: str\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-23)@tool\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-24)defhuman_assistance(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-25)    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-26)) -> str:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-27)\"\"\"Request assistance from a human.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-28)    human_response = interrupt(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-29)        {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-30)            \"question\": \"Is this correct?\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-31)            \"name\": name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-32)            \"birthday\": birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-33)        },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-34)    )\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-35)    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-36)        verified_name = name\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-37)        verified_birthday = birthday\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-38)        response = \"Correct\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-39)    else:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-40)        verified_name = human_response.get(\"name\", name)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-41)        verified_birthday = human_response.get(\"birthday\", birthday)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-42)        response = f\"Made a correction: {human_response}\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-43)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-44)    state_update = {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-45)        \"name\": verified_name,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-46)        \"birthday\": verified_birthday,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-47)        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-48)    }\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-49)    return Command(update=state_update)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-50)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-51)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-52)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-53)tools = [tool, human_assistance]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-54)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-55)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-56)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-57)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-58)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-59)    message = llm_with_tools.invoke(state[\"messages\"])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-60)    assert(len(message.tool_calls) <= 1)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-61)    return {\"messages\": [message]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-62)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-63)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-64)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-65)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-66)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-67)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-68)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-69)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-70)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-71)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-72)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-73))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-74)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-75)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-76)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-77)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-63-78)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | ToolMessage | InjectedToolCallId | tool | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition | Command | interrupt\\nPart 6: Time TravelÂ¶\\nIn a typical chat bot workflow, the user interacts with the bot 1 or more times to accomplish a task. In the previous sections, we saw how to add memory and a human-in-the-loop to be able to checkpoint our graph state and control future responses.\\nBut what if you want to let your user start from a previous response and \"branch off\" to explore a separate outcome? Or what if you want users to be able to \"rewind\" your assistant\\'s work to fix some mistakes or try a different strategy (common in applications like autonomous software engineers)?\\nYou can create both of these experiences and more using LangGraph\\'s built-in \"time travel\" functionality.\\nIn this section, you will \"rewind\" your graph by fetching a checkpoint using the graph\\'s get_state_history method. You can then resume execution at this previous point in time.\\nFor this, let\\'s use the simple chatbot with tools from Part 3:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-3)fromlangchain_anthropicimport ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-4)fromlangchain_community.tools.tavily_searchimport TavilySearchResults\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-5)fromlangchain_core.messagesimport BaseMessage\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-6)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-8)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-9)fromlanggraph.graphimport StateGraph, START, END\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-10)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-11)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-12)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-13)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-18)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-20)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-21)tool = TavilySearchResults(max_results=2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-22)tools = [tool]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-23)llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-24)llm_with_tools = llm.bind_tools(tools)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-26)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-27)defchatbot(state: State):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-28)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-30)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-31)graph_builder.add_node(\"chatbot\", chatbot)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-32)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-33)tool_node = ToolNode(tools=[tool])\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-34)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-36)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-37)    \"chatbot\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-38)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-39))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-40)graph_builder.add_edge(\"tools\", \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-41)graph_builder.add_edge(START, \"chatbot\")\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-42)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-43)memory = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-64-44)graph = graph_builder.compile(checkpointer=memory)\\nAPI Reference: ChatAnthropic | TavilySearchResults | BaseMessage | MemorySaver | StateGraph | START | END | add_messages | ToolNode | tools_condition\\nLet\\'s have our graph take a couple steps. Every step will be checkpointed in its state history:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-1)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-2)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-3)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-4)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-5)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-6)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-7)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-8)                    \"I\\'m learning LangGraph. \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-9)                    \"Could you do some research on it for me?\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-10)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-11)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-12)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-13)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-14)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-15)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-16))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-17)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-18)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-65-19)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-3)I\\'m learning LangGraph. Could you do some research on it for me?\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-6)[{\\'text\\': \"Certainly! I\\'d be happy to research LangGraph for you. To get the most up-to-date and accurate information, I\\'ll use the Tavily search engine to look this up. Let me do that for you now.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BscbfJJB9EWJFqGrN6E54e\\', \\'input\\': {\\'query\\': \\'LangGraph latest information and features\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-8)  tavily_search_results_json (toolu_01BscbfJJB9EWJFqGrN6E54e)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-9) Call ID: toolu_01BscbfJJB9EWJFqGrN6E54e\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-11)    query: LangGraph latest information and features\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-15)[{\"url\": \"https://blockchain.news/news/langchain-new-features-upcoming-events-update\", \"content\": \"LangChain, a leading platform in the AI development space, has released its latest updates, showcasing new use cases and enhancements across its ecosystem. According to the LangChain Blog, the updates cover advancements in LangGraph Cloud, LangSmith\\'s self-improving evaluators, and revamped documentation for LangGraph.\"}, {\"url\": \"https://blog.langchain.dev/langgraph-platform-announce/\", \"content\": \"With these learnings under our belt, we decided to couple some of our latest offerings under LangGraph Platform. LangGraph Platform today includes LangGraph Server, LangGraph Studio, plus the CLI and SDK. ... we added features in LangGraph Server to deliver on a few key value areas. Below, we\\'ll focus on these aspects of LangGraph Platform.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-18)Thank you for your patience. I\\'ve found some recent information about LangGraph for you. Let me summarize the key points:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-20)1. LangGraph is part of the LangChain ecosystem, which is a leading platform in AI development.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-22)2. Recent updates and features of LangGraph include:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-24)   a. LangGraph Cloud: This seems to be a cloud-based version of LangGraph, though specific details weren\\'t provided in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-26)   b. LangGraph Platform: This is a newly introduced concept that combines several offerings:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-27)      - LangGraph Server\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-28)      - LangGraph Studio\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-29)      - CLI (Command Line Interface)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-30)      - SDK (Software Development Kit)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-32)3. LangGraph Server: This component has received new features to enhance its value proposition, though the specific features weren\\'t detailed in the search results.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-34)4. LangGraph Studio: This appears to be a new tool in the LangGraph ecosystem, likely providing a graphical interface for working with LangGraph.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-36)5. Documentation: The LangGraph documentation has been revamped, which should make it easier for learners like yourself to understand and use the tool.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-38)6. Integration with LangSmith: While not directly part of LangGraph, LangSmith (another tool in the LangChain ecosystem) now features self-improving evaluators, which might be relevant if you\\'re using LangGraph as part of a larger LangChain project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-39)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-40)As you\\'re learning LangGraph, it would be beneficial to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-41)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-42)1. Check out the official LangChain documentation, especially the newly revamped LangGraph sections.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-43)2. Explore the different components of the LangGraph Platform (Server, Studio, CLI, and SDK) to see which best fits your learning needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-44)3. Keep an eye on LangGraph Cloud developments, as cloud-based solutions often provide an easier starting point for learners.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-45)4. Consider how LangGraph fits into the broader LangChain ecosystem, especially its interaction with tools like LangSmith.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-66-47)Is there any specific aspect of LangGraph you\\'d like to know more about? I\\'d be happy to do a more focused search on particular features or use cases.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-1)events = graph.stream(\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-2)    {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-3)        \"messages\": [\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-4)            {\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-5)                \"role\": \"user\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-6)                \"content\": (\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-7)                    \"Ya that\\'s helpful. Maybe I\\'ll \"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-8)                    \"build an autonomous agent with it!\"\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-9)                ),\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-10)            },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-11)        ],\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-12)    },\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-13)    config,\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-14)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-15))\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-16)for event in events:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-17)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-67-18)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-3)Ya that\\'s helpful. Maybe I\\'ll build an autonomous agent with it!\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-5)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-6)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-8)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-9) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-11)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-13)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-15)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable â€” they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a userâ€™s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-17)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-18)Great idea! Building an autonomous agent with LangGraph is definitely an exciting project. Based on the latest information I\\'ve found, here are some insights and tips for building autonomous agents with LangGraph:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-20)1. Multi-Tool Agents: LangGraph is particularly well-suited for creating autonomous agents that can use multiple tools. This allows your agent to have a diverse set of capabilities and choose the right tool for each task.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-21)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-22)2. Integration with Large Language Models (LLMs): You can combine LangGraph with powerful LLMs like Gemini 2.0 to create more intelligent and capable agents. The LLM can serve as the \"brain\" of your agent, making decisions and generating responses.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-23)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-24)3. Workflow Management: LangGraph excels at managing complex, multi-step AI workflows. This is crucial for autonomous agents that need to break down tasks into smaller steps and execute them in the right order.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-26)4. Practical Tutorials Available: There are tutorials available that provide full code examples for building and running multi-tool agents. These can be incredibly helpful as you start your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-27)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-28)5. Langchain Integration: LangGraph is often used in conjunction with Langchain. This combination provides a powerful framework for building AI agents, offering features like memory management, tool integration, and prompt management.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-29)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-30)6. GitHub Resources: There are repositories available (like the one by anmolaman20) that provide comprehensive resources for building AI agents using Langchain and LangGraph. These can be valuable references as you develop your agent.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-32)7. Real-time Adaptation: LangGraph allows you to create agents that can think, reason, and adapt in real-time, which is crucial for truly autonomous behavior.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-33)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-34)8. Customization: You can equip your agent with specific tools tailored to your use case. For example, you might include tools for web searching, data analysis, or interacting with specific APIs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-35)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-36)To get started with your autonomous agent project:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-37)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-38)1. Familiarize yourself with LangGraph\\'s documentation and basic concepts.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-39)2. Look into tutorials that specifically deal with building autonomous agents, like the one mentioned from Towards Data Science.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-40)3. Decide on the specific capabilities you want your agent to have and identify the tools it will need.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-41)4. Start with a simple agent and gradually add complexity as you become more comfortable with the framework.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-42)5. Experiment with different LLMs to find the one that works best for your use case.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-43)6. Pay attention to how you structure the agent\\'s decision-making process and workflow.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-44)7. Don\\'t forget to implement proper error handling and safety measures, especially if your agent will be interacting with external systems or making important decisions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-45)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-68-46)Building an autonomous agent is an iterative process, so be prepared to refine and improve your agent over time. Good luck with your project! If you need any more specific information as you progress, feel free to ask.\\nNow that we\\'ve had the agent take a couple steps, we can replay the full state history to see everything that occurred.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-1)to_replay = None\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-2)for state in graph.get_state_history(config):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-3)    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-4)    print(\"-\" * 80)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-5)    if len(state.values[\"messages\"]) == 6:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-6)        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-69-7)        to_replay = state\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-1)Num Messages:  8 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-2)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-3)Num Messages:  7 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-4)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-5)Num Messages:  6 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-6)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-7)Num Messages:  5 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-8)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-9)Num Messages:  4 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-10)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-11)Num Messages:  4 Next:  ()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-12)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-13)Num Messages:  3 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-14)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-15)Num Messages:  2 Next:  (\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-16)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-17)Num Messages:  1 Next:  (\\'chatbot\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-18)--------------------------------------------------------------------------------\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-19)Num Messages:  0 Next:  (\\'__start__\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-70-20)--------------------------------------------------------------------------------\\nNotice that checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread\\'s history. We\\'ve picked out to_replay as a state to resume from. This is the state after the chatbot node in the second graph invocation above.\\nResuming from this point should call the action node next.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-1)print(to_replay.next)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-71-2)print(to_replay.config)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-1)(\\'tools\\',)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-72-2){\\'configurable\\': {\\'thread_id\\': \\'1\\', \\'checkpoint_ns\\': \\'\\', \\'checkpoint_id\\': \\'1efd43e3-0c1f-6c4e-8006-891877d65740\\'}}\\nNotice that the checkpoint\\'s config (to_replay.config) contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph\\'s checkpointer to load the state from that moment in time. Let\\'s try it below:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-1)# The `checkpoint_id` in the `to_replay.config` corresponds to a state we\\'ve persisted to our checkpointer.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-2)for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-3)    if \"messages\" in event:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-73-4)        event[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-1)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-2)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-3)[{\\'text\\': \"That\\'s an exciting idea! Building an autonomous agent with LangGraph is indeed a great application of this technology. LangGraph is particularly well-suited for creating complex, multi-step AI workflows, which is perfect for autonomous agents. Let me gather some more specific information about using LangGraph for building autonomous agents.\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\', \\'input\\': {\\'query\\': \\'Building autonomous agents with LangGraph examples and tutorials\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-4)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-5)  tavily_search_results_json (toolu_01QWNHhUaeeWcGXvA4eHT7Zo)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-6) Call ID: toolu_01QWNHhUaeeWcGXvA4eHT7Zo\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-7)  Args:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-8)    query: Building autonomous agents with LangGraph examples and tutorials\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-9)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-10)Name: tavily_search_results_json\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-11)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-12)[{\"url\": \"https://towardsdatascience.com/building-autonomous-multi-tool-agents-with-gemini-2-0-and-langgraph-ad3d7bd5e79d\", \"content\": \"Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph | by Youness Mansar | Jan, 2025 | Towards Data Science Building Autonomous Multi-Tool Agents with Gemini 2.0 and LangGraph A practical tutorial with full code examples for building and running multi-tool agents Towards Data Science LLMs are remarkable â€” they can memorize vast amounts of information, answer general knowledge questions, write code, generate stories, and even fix your grammar. In this tutorial, we are going to build a simple LLM agent that is equipped with four tools that it can use to answer a userâ€™s question. This Agent will have the following specifications: Follow Published in Towards Data Science --------------------------------- Your home for data science and AI. Follow Follow Follow\"}, {\"url\": \"https://github.com/anmolaman20/Tools_and_Agents\", \"content\": \"GitHub - anmolaman20/Tools_and_Agents: This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository provides resources for building AI agents using Langchain and Langgraph. This repository serves as a comprehensive guide for building AI-powered agents using Langchain and Langgraph. It provides hands-on examples, practical tutorials, and resources for developers and AI enthusiasts to master building intelligent systems and workflows. AI Agent Development: Gain insights into creating intelligent systems that think, reason, and adapt in real time. This repository is ideal for AI practitioners, developers exploring language models, or anyone interested in building intelligent systems. This repository provides resources for building AI agents using Langchain and Langgraph.\"}]\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-13)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-14)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-15)Great idea! Building an autonomous agent with LangGraph is indeed an excellent way to apply and deepen your understanding of the technology. Based on the search results, I can provide you with some insights and resources to help you get started:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-16)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-17)1. Multi-Tool Agents:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-18)   LangGraph is well-suited for building autonomous agents that can use multiple tools. This allows your agent to have a variety of capabilities and choose the appropriate tool based on the task at hand.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-19)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-20)2. Integration with Large Language Models (LLMs):\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-21)   There\\'s a tutorial that specifically mentions using Gemini 2.0 (Google\\'s LLM) with LangGraph to build autonomous agents. This suggests that LangGraph can be integrated with various LLMs, giving you flexibility in choosing the language model that best fits your needs.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-22)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-23)3. Practical Tutorials:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-24)   There are tutorials available that provide full code examples for building and running multi-tool agents. These can be invaluable as you start your project, giving you a concrete starting point and demonstrating best practices.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-25)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-26)4. GitHub Resources:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-27)   There\\'s a GitHub repository (github.com/anmolaman20/Tools_and_Agents) that provides resources for building AI agents using both Langchain and Langgraph. This could be a great resource for code examples, tutorials, and understanding how LangGraph fits into the broader LangChain ecosystem.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-28)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-29)5. Real-Time Adaptation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-30)   The resources mention creating intelligent systems that can think, reason, and adapt in real-time. This is a key feature of advanced autonomous agents and something you can aim for in your project.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-31)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-32)6. Diverse Applications:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-33)   The materials suggest that these techniques can be applied to various tasks, from answering questions to potentially more complex decision-making processes.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-34)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-35)To get started with your autonomous agent project using LangGraph, you might want to:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-36)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-37)1. Review the tutorials mentioned, especially those with full code examples.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-38)2. Explore the GitHub repository for hands-on examples and resources.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-39)3. Decide on the specific tasks or capabilities you want your agent to have.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-40)4. Choose an LLM to integrate with LangGraph (like GPT, Gemini, or others).\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-41)5. Start with a simple agent that uses one or two tools, then gradually expand its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-42)6. Implement decision-making logic to help your agent choose between different tools or actions.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-43)7. Test your agent thoroughly with various inputs and scenarios to ensure robust performance.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-44)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-45)Remember, building an autonomous agent is an iterative process. Start simple and gradually increase complexity as you become more comfortable with LangGraph and its capabilities.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-46)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-74-47)Would you like more information on any specific aspect of building your autonomous agent with LangGraph?\\nNotice that the graph resumed execution from the **action** node. You can tell this is the case since the first value printed above is the response from our search engine tool.\\nCongratulations! You\\'ve now used time-travel checkpoint traversal in LangGraph. Being able to rewind and explore alternative paths opens up a world of possibilities for debugging, experimentation, and interactive applications.\\nNext StepsÂ¶\\nTake your journey further by exploring deployment and advanced features:\\nServer QuickstartÂ¶\\n\\nLangGraph Server Quickstart: Launch a LangGraph server locally and interact with it using the REST API and LangGraph Studio Web UI.\\n\\nLangGraph CloudÂ¶\\n\\nLangGraph Cloud QuickStart: Deploy your LangGraph app using LangGraph Cloud.\\n\\nLangGraph FrameworkÂ¶\\n\\nLangGraph Concepts: Learn the foundational concepts of LangGraph.\\nLangGraph How-to Guides: Guides for common tasks with LangGraph.\\n\\nLangGraph PlatformÂ¶\\nExpand your knowledge with these resources:\\n\\nLangGraph Platform Concepts: Understand the foundational concepts of the LangGraph Platform.\\nLangGraph Platform How-to Guides: Guides for common tasks with LangGraph Platform.\\n\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nComments\\nBack to top\\nPrevious TutorialsNext Workflows and Agents\\nCopyright Â© 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! â¤ï¸\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
       " {'title': 'Introduction - langchain-ai.github.io',\n",
       "  'url': 'https://langchain-ai.github.io/langmem/',\n",
       "  'content': 'The memory tools (create_manage_memory_tool and create_search_memory_tool) let you control what gets stored. The agent extracts key information from conversations, maintains memory consistency, and knows when to search past interactions. See Memory Tools for configuration options.',\n",
       "  'score': 0.58830167872,\n",
       "  'raw_content': 'Introduction\\nSkip to content\\n \\nLangMem\\nIntroduction\\n\\nInitializing search\\nGitHub\\n LangMem\\nGitHub\\n\\n\\n[ ]  Introduction Introduction\\nTable of contents\\n\\nKey features\\nInstallation\\nCreating an Agent\\nNext Steps\\n\\n\\n\\n[ ]  Quickstart ðŸŽï¸\\nQuickstart ðŸŽï¸\\n\\nðŸš€ Hot Path Quickstart\\nðŸ§  Background Quickstart\\n\\n\\n\\n[ ]  Concepts ðŸ’¡\\nConcepts ðŸ’¡\\n\\nCore Concepts\\n\\n\\n\\n[ ]  How-to Guides ðŸ”¨\\nHow-to Guides ðŸ”¨\\n\\nDefer Background Memory Processing\\nManage a Semantic Memory Collection\\nManage User Profiles\\nManage Episodic Memories\\nUse Memory Tools\\nOptimize Single Prompts\\nOptimize Multiple Prompts\\nConfigure Dynamic Namespaces\\nUse Tools in Custom Agents\\nUse Tools in CrewAI\\n\\n\\n\\n[ ] \\nAPI Reference ðŸ““\\nAPI Reference ðŸ““\\n\\nExtractive Memory\\nTools\\nPrompt Optimization\\nUtils\\n\\n\\n\\nTable of contents\\n\\nKey features\\nInstallation\\nCreating an Agent\\nNext Steps\\n\\n\\nLangMemÂ¶\\nLangMem helps agents learn and adapt from their interactions over time.\\nIt provides tooling to extract important information from conversations, optimize agent behavior through prompt refinement, and maintain long-term memory.\\nIt offers both functional primitives you can use with any storage system and native integration with LangGraph\\'s storage layer.\\nThis lets your agents continuously improve, personalize their responses, and maintain consistent behavior across sessions.\\nKey featuresÂ¶\\n\\nðŸ§© Core memory API that works with any storage system\\nðŸ§  Memory management tools that agents can use to record and search information during active conversations \"in the hot path\"\\nâš™ï¸ Background memory manager that automatically extracts, consolidates, and updates agent knowledge\\nâš¡ Native integration with LangGraph\\'s Long-term Memory Store, available by default in all LangGraph Platform deployments\\n\\nInstallationÂ¶\\n[](https://langchain-ai.github.io/langmem/#__codelineno-0-1)pipinstall-Ulangmem\\nConfigure your environment with an API key for your favorite LLM provider:\\n[](https://langchain-ai.github.io/langmem/#__codelineno-1-1)exportANTHROPIC_API_KEY=\"sk-...\"# Or another supported LLM provider\\nCreating an AgentÂ¶\\nHere\\'s how to create an agent that actively manages its own long-term memory in just a few lines:\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-1)# Import core components (1)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-2)fromlanggraph.prebuiltimport create_react_agent\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-3)fromlanggraph.store.memoryimport InMemoryStore\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-4)fromlangmemimport create_manage_memory_tool, create_search_memory_tool\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-5)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-6)# Set up storage (2)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-7)store = InMemoryStore(\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-8)    index={\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-9)        \"dims\": 1536,\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-10)        \"embed\": \"openai:text-embedding-3-small\",\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-11)    }\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-12)) \\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-13)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-14)# Create an agent with memory capabilities (3)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-15)agent = create_react_agent(\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-16)    \"anthropic:claude-3-5-sonnet-latest\",\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-17)    tools=[\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-18)        # Memory tools use LangGraph\\'s BaseStore for persistence (4)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-19)        create_manage_memory_tool(namespace=(\"memories\",)),\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-20)        create_search_memory_tool(namespace=(\"memories\",)),\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-21)    ],\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-22)    store=store,\\n[](https://langchain-ai.github.io/langmem/#__codelineno-2-23))\\n\\n\\nThe memory tools work in any LangGraph app. Here we use create_react_agent to run an LLM with tools, but you can add these tools to your existing agents or build custom memory systems without agents.\\n\\n\\nInMemoryStore keeps memories in process memoryâ€”they\\'ll be lost on restart. For production, use the AsyncPostgresStore or a similar DB-backed store to persist memories across server restarts.\\n\\n\\nThe memory tools (create_manage_memory_tool and create_search_memory_tool) let you control what gets stored. The agent extracts key information from conversations, maintains memory consistency, and knows when to search past interactions. See Memory Tools for configuration options.\\n\\n\\nThen use the agent:\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-1)# Store a new memory (1)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-2)agent.invoke(\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-3)    {\"messages\": [{\"role\": \"user\", \"content\": \"Remember that I prefer dark mode.\"}]}\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-4))\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-5)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-6)# Retrieve the stored memory (2)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-7)response = agent.invoke(\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-8)    {\"messages\": [{\"role\": \"user\", \"content\": \"What are my lighting preferences?\"}]}\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-9))\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-10)print(response[\"messages\"][-1].content)\\n[](https://langchain-ai.github.io/langmem/#__codelineno-3-11)# Output: \"You\\'ve told me that you prefer dark mode.\"\\n\\n\\nThe agent gets to decide what and when to store the memory. No special commands neededâ€”just chat normally and the agent uses create_manage_memory_tool to store relevant details.\\n\\n\\nThe agent maintains context between chats. When you ask about previous interactions, the LLM can invoke create_search_memory_tool to search for memories with similar content. See Memory Tools to customize memory storage and retrieval, and see the hot path quickstart for a more complete example on how to include memories without the agent having to expliictly search.\\n\\n\\nThe agent can now store important information from conversations, search its memory when relevant, and persist knowledge across conversations.\\nNext StepsÂ¶\\nFor more examples and detailed documentation:\\n\\nHot Path Quickstart - Learn how to let your LangGraph agent manage its own memory \"in the hot path\"\\nBackground Quickstart - Learn how to use a memory manager \"in the background\"\\nCore Concepts - Learn key ideas\\nAPI Reference - Full function documentation\\nBuild RSI ðŸ™‚\\n\\nBack to top\\nNext ðŸš€ Hot Path Quickstart\\nMade with Material for MkDocs\\n'},\n",
       " {'title': 'Learn the basics - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/',\n",
       "  'content': '[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-12)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-13)// Define the tools for the agent to use\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-14)consttools=[newTavilySearchResults({maxResults:3})];\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-15)consttoolNode=newToolNode(tools); [...] [](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-27)// If the LLM makes a tool call, then we route to the \"tools\" node\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-28)if(lastMessage.tool_calls?.length){\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-29)return\"tools\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-30)} [...] [](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-20)llm:agentModel,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-21)tools:agentTools,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-22)checkpointSaver:agentCheckpointer,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-23)});',\n",
       "  'score': 0.5283378394799999,\n",
       "  'raw_content': 'Learn the basics\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLearn the basics\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\nVersions\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nIntroduction\\nPrerequisites\\nLangSmith\\nMaking your first agent using LangGraph\\nHow does it work?\\nCustomizing agent behavior\\nNext Steps\\n\\n\\n\\nDeployment\\n\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\n\\n[ ] \\nTutorials\\nTutorials\\n\\n\\n[ ] \\nQuick Start\\nQuick Start\\n\\nQuick Start\\n\\n[ ]  Learn the basics Learn the basics\\nTable of contents\\n\\nIntroduction\\nPrerequisites\\nLangSmith\\nMaking your first agent using LangGraph\\nHow does it work?\\nCustomizing agent behavior\\nNext Steps\\n\\n\\n\\nCloud Deploy\\n\\n\\n\\n\\nChatbots\\n\\nRAG\\nAgent Architectures\\nEvaluation & Analysis\\n\\n\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\nVersions\\n\\nTable of contents\\n\\nIntroduction\\nPrerequisites\\nLangSmith\\nMaking your first agent using LangGraph\\nHow does it work?\\nCustomizing agent behavior\\n\\nNext Steps\\n\\n\\nHome\\n\\nGuides\\nTutorials\\nQuick Start\\n\\nLangGraph.js - QuickstartÂ¶\\nIntroductionÂ¶\\nIn this quickstart guide, you\\'ll get up and running with a simple Reason + Act Agent (often called a ReAct Agent) that can search the web using Tavily Search API. The code is fully configurable. You can:\\n\\nswap out components\\ncustomize the execution flow\\nextend it with custom code or tooling\\nchange the Large Language Model (LLM) and provider being used\\n\\nPrerequisitesÂ¶\\nTo follow along, you\\'ll need to have the following:\\n\\nNodeJS version 18 or newer\\nA Tavily account and API key\\nAn OpenAI developer platform account and API key\\n\\nStart by creating a new folder for the project. Open your terminal and run the following code:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-0-1)mkdirlanggraph-agent\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-0-2)cdlanggraph-agent\\nYou\\'ll also need to install a few dependencies to create an agent:\\n\\nlangchain/langgraph contains the building blocks used to assemble an agent\\nlangchain/openai enable your agent to use OpenAI\\'s LLMs\\nlangchain/community includes the Tavily integration give your agent search capabilities\\n\\nYou can install these dependencies using by running following npm command in your terminal:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-1-1)npminstall@langchain/core@langchain/langgraph@langchain/openai@langchain/community\\nLangSmithÂ¶\\nOptionally, set up LangSmith for best-in-class observability. Setup is simple - add the following variables to your environment and update the LANGCHAIN_API_KEY value with your API key.\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-2-1)// Optional, add tracing in LangSmith\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-2-2)// process.env.LANGCHAIN_API_KEY = \"ls__...\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-2-3)// process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-2-4)// process.env.LANGCHAIN_TRACING_V2 = \"true\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-2-5)// process.env.LANGCHAIN_PROJECT = \"Quickstart: LangGraphJS\";\\nMaking your first agent using LangGraphÂ¶\\nCreate a file named agent.ts (short for Reason + Act Agent) and add the below TypeScript code to it.\\nMake sure you update the environment variables at the top of the file to contain your API keys. If you don\\'t, the OpenAI and Tavily API calls will produce errors and your agent will not work correctly.\\nOnce you\\'ve added your API keys, save the file and run the code with the following command:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-3-1)npxtsxagent.ts\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-1)// agent.ts\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-2)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-3)// IMPORTANT - Add your API keys here. Be careful not to publish them.\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-4)process.env.OPENAI_API_KEY=\"sk-...\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-5)process.env.TAVILY_API_KEY=\"tvly-...\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-6)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-7)import{TavilySearchResults}from\"@langchain/community/tools/tavily_search\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-8)import{ChatOpenAI}from\"@langchain/openai\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-9)import{MemorySaver}from\"@langchain/langgraph\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-10)import{HumanMessage}from\"@langchain/core/messages\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-11)import{createReactAgent}from\"@langchain/langgraph/prebuilt\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-12)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-13)// Define the tools for the agent to use\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-14)constagentTools=[newTavilySearchResults({maxResults:3})];\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-15)constagentModel=newChatOpenAI({temperature:0});\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-16)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-17)// Initialize memory to persist state between graph runs\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-18)constagentCheckpointer=newMemorySaver();\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-19)constagent=createReactAgent({\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-20)llm:agentModel,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-21)tools:agentTools,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-22)checkpointSaver:agentCheckpointer,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-23)});\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-24)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-25)// Now it\\'s time to use!\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-26)constagentFinalState=awaitagent.invoke(\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-27){messages:[newHumanMessage(\"what is the current weather in sf\")]},\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-28){configurable:{thread_id:\"42\"}},\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-29));\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-30)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-31)console.log(\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-32)agentFinalState.messages[agentFinalState.messages.length-1].content,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-33));\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-34)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-35)constagentNextState=awaitagent.invoke(\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-36){messages:[newHumanMessage(\"what about ny\")]},\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-37){configurable:{thread_id:\"42\"}},\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-38));\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-39)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-40)console.log(\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-41)agentNextState.messages[agentNextState.messages.length-1].content,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-4-42));\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-1)The current weather in San Francisco is as follows:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-2)- Temperature: 82.0Â°F (27.8Â°C)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-3)- Condition: Sunny\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-4)- Wind: 11.9 mph from the NW\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-5)- Humidity: 41%\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-6)- Pressure: 29.98 in\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-7)- Visibility: 9.0 miles\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-8)- UV Index: 6.0\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-9)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-10)For more details, you can visit [Weather in San Francisco](https://www.weatherapi.com/).\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-11)The current weather in New York is as follows:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-12)- Temperature: 84.0Â°F (28.9Â°C)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-13)- Condition: Sunny\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-14)- Wind: 2.2 mph from SSE\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-15)- Humidity: 57%\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-16)- Pressure: 29.89 in\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-17)- Precipitation: 0.01 in\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-18)- Visibility: 9.0 miles\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-19)- UV Index: 6.0\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-20)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-5-21)For more details, you can visit [Weather in New York](https://www.weatherapi.com/).\\nHow does it work?Â¶\\nThe createReactAgent constructor lets you create a simple tool-using LangGraph agent in a single line of code. Here\\'s a visual representation of the graph:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-1)// Note: tslab only works inside a jupyter notebook. Don\\'t worry about running this code yourself!\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-2)import*astslabfrom\"tslab\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-3)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-4)constgraph=agent.getGraph();\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-5)constimage=awaitgraph.drawMermaidPng();\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-6)constarrayBuffer=awaitimage.arrayBuffer();\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-7)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-6-8)awaittslab.display.png(newUint8Array(arrayBuffer));\\n\\nCustomizing agent behaviorÂ¶\\ncreateReactAgent can be great for simple agents, but sometimes you need something more powerful.\\nLangGraph really shines when you need fine-grained control over an agent\\'s behavior. The following code creates an agent with the same behavior as the example above, but you can clearly see the execution logic and how you could customize it.\\nUpdate the code in your agent.ts file to match the example below. Once again, be sure to update the environment variables at the top.\\nAfter you\\'ve updated your environment variables and saved the file, you can run it with the same command as before:\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-7-1)npxtsxagent.ts\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-1)// agent.ts\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-2)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-3)// IMPORTANT - Add your API keys here. Be careful not to publish them.\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-4)process.env.OPENAI_API_KEY=\"sk-...\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-5)process.env.TAVILY_API_KEY=\"tvly-...\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-6)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-7)import{TavilySearchResults}from\"@langchain/community/tools/tavily_search\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-8)import{ChatOpenAI}from\"@langchain/openai\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-9)import{HumanMessage,AIMessage}from\"@langchain/core/messages\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-10)import{ToolNode}from\"@langchain/langgraph/prebuilt\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-11)import{StateGraph,MessagesAnnotation}from\"@langchain/langgraph\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-12)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-13)// Define the tools for the agent to use\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-14)consttools=[newTavilySearchResults({maxResults:3})];\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-15)consttoolNode=newToolNode(tools);\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-16)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-17)// Create a model and give it access to the tools\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-18)constmodel=newChatOpenAI({\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-19)model:\"gpt-4o-mini\",\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-20)temperature:0,\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-21)}).bindTools(tools);\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-22)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-23)// Define the function that determines whether to continue or not\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-24)functionshouldContinue({messages}:typeofMessagesAnnotation.State){\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-25)constlastMessage=messages[messages.length-1]asAIMessage;\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-26)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-27)// If the LLM makes a tool call, then we route to the \"tools\" node\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-28)if(lastMessage.tool_calls?.length){\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-29)return\"tools\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-30)}\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-31)// Otherwise, we stop (reply to the user) using the special \"__end__\" node\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-32)return\"__end__\";\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-33)}\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-34)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-35)// Define the function that calls the model\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-36)asyncfunctioncallModel(state:typeofMessagesAnnotation.State){\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-37)constresponse=awaitmodel.invoke(state.messages);\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-38)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-39)// We return a list, because this will get added to the existing list\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-40)return{messages:[response]};\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-41)}\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-42)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-43)// Define a new graph\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-44)constworkflow=newStateGraph(MessagesAnnotation)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-45).addNode(\"agent\",callModel)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-46).addEdge(\"__start__\",\"agent\")// __start__ is a special name for the entrypoint\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-47).addNode(\"tools\",toolNode)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-48).addEdge(\"tools\",\"agent\")\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-49).addConditionalEdges(\"agent\",shouldContinue);\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-50)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-51)// Finally, we compile it into a LangChain Runnable.\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-52)constapp=workflow.compile();\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-53)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-54)// Use the agent\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-55)constfinalState=awaitapp.invoke({\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-56)messages:[newHumanMessage(\"what is the weather in sf\")],\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-57)});\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-58)console.log(finalState.messages[finalState.messages.length-1].content);\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-59)\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-60)constnextState=awaitapp.invoke({\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-61)// Including the messages from the previous run gives the LLM context.\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-62)// This way it knows we\\'re asking about the weather in NY\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-63)messages:[...finalState.messages,newHumanMessage(\"what about ny\")],\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-64)});\\n[](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/#__codelineno-8-65)console.log(nextState.messages[nextState.messages.length-1].content);\\nThere are a few new things going on in this version of our ReAct Agent.\\nA ToolNode enables the LLM to use tools. In this example, we made a shouldContinue function and passed it to addConditionalEdge so our ReAct Agent can either call a tool or respond to the request.\\nAnnotations are how graph state is represented in LangGraph. We\\'re using MessagesAnnotation, a helper that implements a common pattern: keeping the message history in an array.\\nNext StepsÂ¶\\nGreat job creating your first AI agent using LangGraph! If you\\'re ready to build something more, check out our other tutorials to learn how to implement other end-to-end agentic workflows such as:\\n\\nRetrieval-Augmented Generation (RAG)\\nMulti-agent collaboration\\nReflection, where the agent evaluates its work\\n\\nIf you\\'d rather improve your agent we have how-to guides to help, including:\\n\\nTool calling that enables agents to interact with APIs\\ngive your agent persistent memory to continue conversations and debug unexpected behavior\\nPut a human in the loop for actions you want a human to verify\\nStreaming the agent output to make your application feel more responsive\\nChange the AI model in one line of code\\n\\nBack to top\\nPrevious TutorialsNext Workflows and Agents\\nMade with Material for MkDocs Insiders\\n'},\n",
       " {'title': 'How to call tools using ToolNode',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/how-tos/tool-calling/',\n",
       "  'content': \"How to call tools using ToolNodeÂ¶\\nThis guide covers how to use LangGraph's prebuilt ToolNode for tool calling.\\nToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph's prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).\\nSetupÂ¶ [...] Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started here.\\nDefine toolsÂ¶\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-2-1)from langchain_core.messages import AIMessage\",\n",
       "  'score': 0.51839714448,\n",
       "  'raw_content': 'How to call tools using ToolNode\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nHow to call tools using ToolNode\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\nLearn the basics\\nDeployment\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\n\\n[ ] \\nHow-to Guides\\nHow-to Guides\\n\\n\\n[ ]  LangGraph\\nLangGraph\\n\\nLangGraph\\nGraph API Basics\\nControllability\\nPersistence\\nMemory\\nHuman-in-the-loop\\nStreaming\\n\\n[ ]  Tool calling\\nTool calling\\n\\nTool calling\\n\\n[ ]  How to call tools using ToolNode How to call tools using ToolNode\\nTable of contents\\n\\nSetup\\nDefine tools\\nManually call ToolNode\\nUsing with chat models\\nReAct Agent\\n\\n\\n\\nHow to handle tool calling errors\\n\\nHow to pass runtime values to tools\\nHow to update graph state from tools\\nHow to pass config to tools\\nHow to handle large numbers of tools\\n\\n\\n\\nSubgraphs\\n\\nMulti-agent\\nState Management\\nOther\\nPrebuilt ReAct Agent\\n\\n\\n\\nLangGraph Platform\\n\\n\\n\\n\\nConcepts\\n\\nTutorials\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\nDefine tools\\nManually call ToolNode\\nUsing with chat models\\n\\nReAct Agent\\n\\n\\nHome\\n\\nGuides\\nHow-to Guides\\nLangGraph\\nTool calling\\n\\n\\nHow to call tools using ToolNodeÂ¶\\nThis guide covers how to use LangGraph\\'s prebuilt ToolNode for tool calling.\\nToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph\\'s prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).\\nSetupÂ¶\\nFirst, let\\'s install the required packages and set our API keys\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-0-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-0-2)%pip install --quiet -U langgraph langchain_anthropic\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-1)import getpass\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-2)import os\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-5)def _set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-1-10)_set_env(\"ANTHROPIC_API_KEY\")\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started here.\\nDefine toolsÂ¶\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-2-1)from langchain_core.messages import AIMessage\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-2-2)from langchain_core.tools import tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-2-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-2-4)from langgraph.prebuilt import ToolNode\\nAPI Reference: AIMessage | tool | ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-1)@tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-2)def get_weather(location: str):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-3)\"\"\"Call to get the current weather.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-4)    if location.lower() in [\"sf\", \"san francisco\"]:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-5)        return \"It\\'s 60 degrees and foggy.\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-6)    else:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-7)        return \"It\\'s 90 degrees and sunny.\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-10)@tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-11)def get_coolest_cities():\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-12)\"\"\"Get a list of coolest cities\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-3-13)    return \"nyc, sf\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-4-1)tools = [get_weather, get_coolest_cities]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-4-2)tool_node = ToolNode(tools)\\nManually call ToolNodeÂ¶\\nToolNode operates on graph state with a list of messages. It expects the last message in the list to be an AIMessage with tool_calls parameter.\\nLet\\'s first see how to invoke the tool node manually:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-1)message_with_single_tool_call = AIMessage(\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-2)    content=\"\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-3)    tool_calls=[\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-4)        {\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-5)            \"name\": \"get_weather\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-6)            \"args\": {\"location\": \"sf\"},\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-7)            \"id\": \"tool_call_id\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-8)            \"type\": \"tool_call\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-9)        }\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-10)    ],\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-11))\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-5-13)tool_node.invoke({\"messages\": [message_with_single_tool_call]})\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-6-1){\\'messages\\': [ToolMessage(content=\"It\\'s 60 degrees and foggy.\", name=\\'get_weather\\', tool_call_id=\\'tool_call_id\\')]}\\nNote that typically you don\\'t need to create AIMessage manually, and it will be automatically generated by any LangChain chat model that supports tool calling.\\nYou can also do parallel tool calling using ToolNode if you pass multiple tool calls to AIMessage\\'s tool_calls parameter:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-1)message_with_multiple_tool_calls = AIMessage(\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-2)    content=\"\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-3)    tool_calls=[\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-4)        {\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-5)            \"name\": \"get_coolest_cities\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-6)            \"args\": {},\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-7)            \"id\": \"tool_call_id_1\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-8)            \"type\": \"tool_call\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-9)        },\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-10)        {\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-11)            \"name\": \"get_weather\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-12)            \"args\": {\"location\": \"sf\"},\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-13)            \"id\": \"tool_call_id_2\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-14)            \"type\": \"tool_call\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-15)        },\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-16)    ],\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-17))\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-18)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-7-19)tool_node.invoke({\"messages\": [message_with_multiple_tool_calls]})\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-8-1){\\'messages\\': [ToolMessage(content=\\'nyc, sf\\', name=\\'get_coolest_cities\\', tool_call_id=\\'tool_call_id_1\\'),\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-8-2)  ToolMessage(content=\"It\\'s 60 degrees and foggy.\", name=\\'get_weather\\', tool_call_id=\\'tool_call_id_2\\')]}\\nUsing with chat modelsÂ¶\\nWe\\'ll be using a small chat model from Anthropic in our example. To use chat models with tool calling, we need to first ensure that the model is aware of the available tools. We do this by calling .bind_tools method on ChatAnthropic model\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-1)from typing import Literal\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-3)from langchain_anthropic import ChatAnthropic\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-4)from langgraph.graph import StateGraph, MessagesState\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-5)from langgraph.prebuilt import ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-6)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-7)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-8)model_with_tools = ChatAnthropic(\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-9)    model=\"claude-3-haiku-20240307\", temperature=0\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-9-10)).bind_tools(tools)\\nAPI Reference: ChatAnthropic | StateGraph | ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-10-1)model_with_tools.invoke(\"what\\'s the weather in sf?\").tool_calls\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-11-1)[{\\'name\\': \\'get_weather\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-11-2)  \\'args\\': {\\'location\\': \\'San Francisco\\'},\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-11-3)  \\'id\\': \\'toolu_01Fwm7dg1mcJU43Fkx2pqgm8\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-11-4)  \\'type\\': \\'tool_call\\'}]\\nAs you can see, the AI message generated by the chat model already has tool_calls populated, so we can just pass it directly to ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-12-1)tool_node.invoke({\"messages\": [model_with_tools.invoke(\"what\\'s the weather in sf?\")]})\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-13-1){\\'messages\\': [ToolMessage(content=\"It\\'s 60 degrees and foggy.\", name=\\'get_weather\\', tool_call_id=\\'toolu_01LFvAVT3xJMeZS6kbWwBGZK\\')]}\\nReAct AgentÂ¶\\nNext, let\\'s see how to use ToolNode inside a LangGraph graph. Let\\'s set up a graph implementation of the ReAct agent. This agent takes some query as input, then repeatedly call tools until it has enough information to resolve the query. We\\'ll be using ToolNode and the Anthropic model with tools we just defined\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-1)from typing import Literal\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-3)from langgraph.graph import StateGraph, MessagesState, START, END\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-6)def should_continue(state: MessagesState):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-7)    messages = state[\"messages\"]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-8)    last_message = messages[-1]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-9)    if last_message.tool_calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-10)        return \"tools\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-11)    return END\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-13)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-14)def call_model(state: MessagesState):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-15)    messages = state[\"messages\"]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-16)    response = model_with_tools.invoke(messages)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-17)    return {\"messages\": [response]}\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-18)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-19)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-20)workflow = StateGraph(MessagesState)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-21)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-22)# Define the two nodes we will cycle between\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-23)workflow.add_node(\"agent\", call_model)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-24)workflow.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-25)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-26)workflow.add_edge(START, \"agent\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-27)workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-28)workflow.add_edge(\"tools\", \"agent\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-29)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-14-30)app = workflow.compile()\\nAPI Reference: StateGraph | START | END\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-1)from IPython.display import Image, display\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-3)try:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-4)    display(Image(app.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-15-7)    pass\\n\\nLet\\'s try it out!\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-16-1)# example with a single tool call\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-16-2)for chunk in app.stream(\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-16-3)    {\"messages\": [(\"human\", \"what\\'s the weather in sf?\")]}, stream_mode=\"values\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-16-4)):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-16-5)    chunk[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-3)what\\'s the weather in sf?\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-6)[{\\'text\\': \"Okay, let\\'s check the weather in San Francisco:\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01LdmBXYeccWKdPrhZSwFCDX\\', \\'input\\': {\\'location\\': \\'San Francisco\\'}, \\'name\\': \\'get_weather\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-8)  get_weather (toolu_01LdmBXYeccWKdPrhZSwFCDX)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-9) Call ID: toolu_01LdmBXYeccWKdPrhZSwFCDX\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-11)    location: San Francisco\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-12)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-13)Name: get_weather\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-14)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-15)It\\'s 60 degrees and foggy.\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-17)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-17-18)The weather in San Francisco is currently 60 degrees with foggy conditions.\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-1)# example with a multiple tool calls in succession\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-3)for chunk in app.stream(\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-4)    {\"messages\": [(\"human\", \"what\\'s the weather in the coolest cities?\")]},\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-5)    stream_mode=\"values\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-6)):\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-18-7)    chunk[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-3)what\\'s the weather in the coolest cities?\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-6)[{\\'text\\': \"Okay, let\\'s find out the weather in the coolest cities:\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01LFZUWTccyveBdaSAisMi95\\', \\'input\\': {}, \\'name\\': \\'get_coolest_cities\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-7)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-8)  get_coolest_cities (toolu_01LFZUWTccyveBdaSAisMi95)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-9) Call ID: toolu_01LFZUWTccyveBdaSAisMi95\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-10)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-11)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-12)Name: get_coolest_cities\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-13)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-14)nyc, sf\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-15)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-16)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-17)[{\\'text\\': \"Now let\\'s get the weather for those cities:\", \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01RHPQBhT1u6eDnPqqkGUpsV\\', \\'input\\': {\\'location\\': \\'nyc\\'}, \\'name\\': \\'get_weather\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-18)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-19)  get_weather (toolu_01RHPQBhT1u6eDnPqqkGUpsV)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-20) Call ID: toolu_01RHPQBhT1u6eDnPqqkGUpsV\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-21)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-22)    location: nyc\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-23)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-24)Name: get_weather\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-25)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-26)It\\'s 90 degrees and sunny.\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-27)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-28)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-29)[{\\'id\\': \\'toolu_01W5sFGF8PfgYzdY4CqT5c6e\\', \\'input\\': {\\'location\\': \\'sf\\'}, \\'name\\': \\'get_weather\\', \\'type\\': \\'tool_use\\'}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-30)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-31)  get_weather (toolu_01W5sFGF8PfgYzdY4CqT5c6e)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-32) Call ID: toolu_01W5sFGF8PfgYzdY4CqT5c6e\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-33)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-34)    location: sf\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-35)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-36)Name: get_weather\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-37)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-38)It\\'s 60 degrees and foggy.\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-39)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-40)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-41)Based on the results, it looks like the weather in the coolest cities is:\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-42)- New York City: 90 degrees and sunny\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-43)- San Francisco: 60 degrees and foggy\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-44)\\n[](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/#__codelineno-19-45)So the weather in the coolest cities is a mix of warm and cool temperatures, with some sunny and some foggy conditions.\\nToolNode can also handle errors during tool execution. You can enable / disable this by setting handle_tool_errors=True (enabled by default). See our guide on handling errors in ToolNode here\\nComments\\nBack to top\\nPrevious How to disable streaming for models that don\\'t support itNext How to handle tool calling errors\\nMade with Material for MkDocs Insiders\\n'},\n",
       " {'title': 'How to handle large numbers of tools',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/how-tos/many-tools/',\n",
       "  'content': '[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-6)    Document(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-7)        page_content=tool.description,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-8)        id=id,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-9)        metadata={\"tool_name\": tool.name},',\n",
       "  'score': 0.487639602,\n",
       "  'raw_content': 'How to handle large numbers of tools\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nHow to handle large numbers of tools\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\nLearn the basics\\nDeployment\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\n\\n[ ] \\nHow-to Guides\\nHow-to Guides\\n\\n\\n[ ]  LangGraph\\nLangGraph\\n\\nLangGraph\\nGraph API Basics\\nControllability\\nPersistence\\nMemory\\nHuman-in-the-loop\\nStreaming\\n\\n[ ]  Tool calling\\nTool calling\\n\\nTool calling\\nHow to call tools using ToolNode\\nHow to handle tool calling errors\\nHow to pass runtime values to tools\\nHow to update graph state from tools\\nHow to pass config to tools\\n\\n[ ]  How to handle large numbers of tools How to handle large numbers of tools\\nTable of contents\\n\\nSetup\\nDefine the tools\\n\\nDefine the graph\\n\\nTool selection\\nIncorporating with an agent\\n\\n\\n\\nRepeating tool selection\\n\\nNext steps\\n\\n\\n\\n\\n\\nSubgraphs\\n\\nMulti-agent\\nState Management\\nOther\\nPrebuilt ReAct Agent\\n\\n\\n\\nLangGraph Platform\\n\\n\\n\\n\\nConcepts\\n\\nTutorials\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nAdopters\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\nDefine the tools\\n\\nDefine the graph\\n\\nTool selection\\nIncorporating with an agent\\n\\n\\n\\nRepeating tool selection\\n\\n\\nNext steps\\n\\n\\nHome\\n\\nGuides\\nHow-to Guides\\nLangGraph\\nTool calling\\n\\n\\nHow to handle large numbers of toolsÂ¶\\nPrerequisites\\nThis guide assumes familiarity with the following:\\n\\nTools\\nChat Models\\nEmbedding Models\\nVectorstores\\nDocument\\n\\nThe subset of available tools to call is generally at the discretion of the model (although many providers also enable the user to specify or constrain the choice of tool). As the number of available tools grows, you may want to limit the scope of the LLM\\'s selection, to decrease token consumption and to help manage sources of error in LLM reasoning.\\nHere we will demonstrate how to dynamically adjust the tools available to a model. Bottom line up front: like RAG and similar methods, we prefix the model invocation by retrieving over available tools. Although we demonstrate one implementation that searches over tool descriptions, the details of the tool selection can be customized as needed.\\nSetupÂ¶\\nFirst, let\\'s install the required packages and set our API keys\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-0-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-0-2)%pip install --quiet -U langgraph langchain_openai numpy\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-1)importgetpass\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-2)importos\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-5)def_set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-1-10)_set_env(\"OPENAI_API_KEY\")\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started here.\\nDefine the toolsÂ¶\\nLet\\'s consider a toy example in which we have one tool for each publicly traded company in the S&P 500 index. Each tool fetches company-specific information based on the year provided as a parameter.\\nWe first construct a registry that associates a unique identifier with a schema for each tool. We will represent the tools using JSON schema, which can be bound directly to chat models supporting tool calling.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-1)importre\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-2)importuuid\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-4)fromlangchain_core.toolsimport StructuredTool\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-6)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-7)defcreate_tool(company: str) -> dict:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-8)\"\"\"Create schema for a placeholder tool.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-9)    # Remove non-alphanumeric characters and replace spaces with underscores for the tool name\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-10)    formatted_company = re.sub(r\"[^\\\\w\\\\s]\", \"\", company).replace(\" \", \"_\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-11)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-12)    defcompany_tool(year: int) -> str:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-13)        # Placeholder function returning static revenue information for the company and year\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-14)        return f\"{company} had revenues of $100 in {year}.\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-15)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-16)    return StructuredTool.from_function(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-17)        company_tool,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-18)        name=formatted_company,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-19)        description=f\"Information about {company}\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-20)    )\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-21)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-22)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-23)# Abbreviated list of S&P 500 companies for demonstration\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-24)s_and_p_500_companies = [\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-25)    \"3M\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-26)    \"A.O. Smith\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-27)    \"Abbott\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-28)    \"Accenture\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-29)    \"Advanced Micro Devices\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-30)    \"Yum! Brands\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-31)    \"Zebra Technologies\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-32)    \"Zimmer Biomet\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-33)    \"Zoetis\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-34)]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-35)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-36)# Create a tool for each company and store it in a registry with a unique UUID as the key\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-37)tool_registry = {\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-38)    str(uuid.uuid4()): create_tool(company) for company in s_and_p_500_companies\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-2-39)}\\nAPI Reference: StructuredTool\\nDefine the graphÂ¶\\nTool selectionÂ¶\\nWe will construct a node that retrieves a subset of available tools given the information in the state-- such as a recent user message. In general, the full scope of retrieval solutions are available for this step. As a simple solution, we index embeddings of tool descriptions in a vector store, and associate user queries to tools via semantic search.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-1)fromlangchain_core.documentsimport Document\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-2)fromlangchain_core.vectorstoresimport InMemoryVectorStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-3)fromlangchain_openaiimport OpenAIEmbeddings\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-5)tool_documents = [\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-6)    Document(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-7)        page_content=tool.description,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-8)        id=id,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-9)        metadata={\"tool_name\": tool.name},\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-10)    )\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-11)    for id, tool in tool_registry.items()\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-12)]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-13)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-14)vector_store = InMemoryVectorStore(embedding=OpenAIEmbeddings())\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-3-15)document_ids = vector_store.add_documents(tool_documents)\\nAPI Reference: Document | InMemoryVectorStore | OpenAIEmbeddings\\nIncorporating with an agentÂ¶\\nWe will use a typical React agent graph (e.g., as used in the quickstart), with some modifications:\\n\\nWe add a selected_tools key to the state, which stores our selected subset of tools;\\nWe set the entry point of the graph to be a select_tools node, which populates this element of the state;\\nWe bind the selected subset of tools to the chat model within the agent node.\\n\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-3)fromlangchain_openaiimport ChatOpenAI\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-4)fromtyping_extensionsimport TypedDict\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-6)fromlanggraph.graphimport StateGraph, START\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-7)fromlanggraph.graph.messageimport add_messages\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-8)fromlanggraph.prebuiltimport ToolNode, tools_condition\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-10)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-11)# Define the state structure using TypedDict.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-12)# It includes a list of messages (processed by add_messages)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-13)# and a list of selected tool IDs.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-14)classState(TypedDict):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-15)    messages: Annotated[list, add_messages]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-16)    selected_tools: list[str]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-17)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-18)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-19)builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-20)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-21)# Retrieve all available tools from the tool registry.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-22)tools = list(tool_registry.values())\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-23)llm = ChatOpenAI()\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-24)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-25)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-26)# The agent function processes the current state\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-27)# by binding selected tools to the LLM.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-28)defagent(state: State):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-29)    # Map tool IDs to actual tools\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-30)    # based on the state\\'s selected_tools list.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-31)    selected_tools = [tool_registry[id] for id in state[\"selected_tools\"]]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-32)    # Bind the selected tools to the LLM for the current interaction.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-33)    llm_with_tools = llm.bind_tools(selected_tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-34)    # Invoke the LLM with the current messages and return the updated message list.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-35)    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-36)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-37)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-38)# The select_tools function selects tools based on the user\\'s last message content.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-39)defselect_tools(state: State):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-40)    last_user_message = state[\"messages\"][-1]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-41)    query = last_user_message.content\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-42)    tool_documents = vector_store.similarity_search(query)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-43)    return {\"selected_tools\": [document.id for document in tool_documents]}\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-44)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-45)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-46)builder.add_node(\"agent\", agent)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-47)builder.add_node(\"select_tools\", select_tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-48)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-49)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-50)builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-51)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-52)builder.add_conditional_edges(\"agent\", tools_condition, path_map=[\"tools\", \"__end__\"])\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-53)builder.add_edge(\"tools\", \"agent\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-54)builder.add_edge(\"select_tools\", \"agent\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-55)builder.add_edge(START, \"select_tools\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-4-56)graph = builder.compile()\\nAPI Reference: ChatOpenAI | StateGraph | START | add_messages | ToolNode | tools_condition\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-3)try:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-5-7)    pass\\n\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-6-1)user_input = \"Can you give me some information about AMD in 2022?\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-6-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-6-3)result = graph.invoke({\"messages\": [(\"user\", user_input)]})\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-7-1)print(result[\"selected_tools\"])\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-8-1)[\\'ab9c0d59-3d16-448d-910c-73cf10a26020\\', \\'f5eff8f6-7fb9-47b6-b54f-19872a52db84\\', \\'2962e168-9ef4-48dc-8b7c-9227e7956d39\\', \\'24a9fb82-19fe-4a88-944e-47bc4032e94a\\']\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-9-1)for message in result[\"messages\"]:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-9-2)    message.pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-3)Can you give me some information about AMD in 2022?\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-5)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-6)  Advanced_Micro_Devices (call_CRxQ0oT7NY7lqf35DaRNTJ35)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-7) Call ID: call_CRxQ0oT7NY7lqf35DaRNTJ35\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-8)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-9)    year: 2022\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-11)Name: Advanced_Micro_Devices\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-13)Advanced Micro Devices had revenues of $100 in 2022.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-15)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-10-16)In 2022, Advanced Micro Devices (AMD) had revenues of $100.\\nRepeating tool selectionÂ¶\\nTo manage errors from incorrect tool selection, we could revisit the select_tools node. One option for implementing this is to modify select_tools to generate the vector store query using all messages in the state (e.g., with a chat model) and add an edge routing from tools to select_tools.\\nWe implement this change below. For demonstration purposes, we simulate an error in the initial tool selection by adding a hack_remove_tool_condition to the select_tools node, which removes the correct tool on the first iteration of the node. Note that on the second iteration, the agent finishes the run as it has access to the correct tool.\\nUsing Pydantic with LangChain\\nThis notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-1)fromlangchain_core.messagesimport HumanMessage, SystemMessage, ToolMessage\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-2)fromlanggraph.pregel.retryimport RetryPolicy\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-4)frompydanticimport BaseModel, Field\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-6)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-7)classQueryForTools(BaseModel):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-8)\"\"\"Generate a query for additional tools.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-10)    query: str = Field(..., description=\"Query for additional tools.\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-11)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-13)defselect_tools(state: State):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-14)\"\"\"Selects tools based on the last message in the conversation state.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-15)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-16)    If the last message is from a human, directly uses the content of the message\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-17)    as the query. Otherwise, constructs a query using a system message and invokes\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-18)    the LLM to generate tool suggestions.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-19)    \"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-20)    last_message = state[\"messages\"][-1]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-21)    hack_remove_tool_condition = False  # Simulate an error in the first tool selection\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-22)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-23)    if isinstance(last_message, HumanMessage):\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-24)        query = last_message.content\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-25)        hack_remove_tool_condition = True  # Simulate wrong tool selection\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-26)    else:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-27)        assert isinstance(last_message, ToolMessage)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-28)        system = SystemMessage(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-29)            \"Given this conversation, generate a query for additional tools. \"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-30)            \"The query should be a short string containing what type of information \"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-31)            \"is needed. If no further information is needed, \"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-32)            \"set more_information_needed False and populate a blank string for the query.\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-33)        )\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-34)        input_messages = [system] + state[\"messages\"]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-35)        response = llm.bind_tools([QueryForTools], tool_choice=True).invoke(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-36)            input_messages\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-37)        )\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-38)        query = response.tool_calls[0][\"args\"][\"query\"]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-39)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-40)    # Search the tool vector store using the generated query\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-41)    tool_documents = vector_store.similarity_search(query)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-42)    if hack_remove_tool_condition:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-43)        # Simulate error by removing the correct tool from the selection\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-44)        selected_tools = [\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-45)            document.id\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-46)            for document in tool_documents\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-47)            if document.metadata[\"tool_name\"] != \"Advanced_Micro_Devices\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-48)        ]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-49)    else:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-50)        selected_tools = [document.id for document in tool_documents]\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-51)    return {\"selected_tools\": selected_tools}\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-52)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-53)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-54)graph_builder = StateGraph(State)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-55)graph_builder.add_node(\"agent\", agent)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-56)graph_builder.add_node(\"select_tools\", select_tools, retry=RetryPolicy(max_attempts=3))\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-57)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-58)tool_node = ToolNode(tools=tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-59)graph_builder.add_node(\"tools\", tool_node)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-60)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-61)graph_builder.add_conditional_edges(\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-62)    \"agent\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-63)    tools_condition,\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-64))\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-65)graph_builder.add_edge(\"tools\", \"select_tools\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-66)graph_builder.add_edge(\"select_tools\", \"agent\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-67)graph_builder.add_edge(START, \"select_tools\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-11-68)graph = graph_builder.compile()\\nAPI Reference: HumanMessage | SystemMessage | ToolMessage\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-1)fromIPython.displayimport Image, display\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-3)try:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-4)    display(Image(graph.get_graph().draw_mermaid_png()))\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-5)except Exception:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-6)    # This requires some extra dependencies and is optional\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-12-7)    pass\\n\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-13-1)user_input = \"Can you give me some information about AMD in 2022?\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-13-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-13-3)result = graph.invoke({\"messages\": [(\"user\", user_input)]})\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-14-1)for message in result[\"messages\"]:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-14-2)    message.pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-3)Can you give me some information about AMD in 2022?\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-5)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-6)  Accenture (call_qGmwFnENwwzHOYJXiCAaY5Mx)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-7) Call ID: call_qGmwFnENwwzHOYJXiCAaY5Mx\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-8)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-9)    year: 2022\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-11)Name: Accenture\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-13)Accenture had revenues of $100 in 2022.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-15)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-16)  Advanced_Micro_Devices (call_u9e5UIJtiieXVYi7Y9GgyDpn)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-17) Call ID: call_u9e5UIJtiieXVYi7Y9GgyDpn\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-18)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-19)    year: 2022\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-20)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-21)Name: Advanced_Micro_Devices\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-22)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-23)Advanced Micro Devices had revenues of $100 in 2022.\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-24)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-25)\\n[](https://langchain-ai.github.io/langgraph/how-tos/many-tools/#__codelineno-15-26)In 2022, AMD had revenues of $100.\\nNext stepsÂ¶\\nThis guide provides a minimal implementation for dynamically selecting tools. There is a host of possible improvements and optimizations:\\n\\nRepeating tool selection: Here, we repeated tool selection by modifying the select_tools node. Another option is to equip the agent with a reselect_tools tool, allowing it to re-select tools at its discretion.\\nOptimizing tool selection: In general, the full scope of retrieval solutions are available for tool selection. Additional options include:\\nGroup tools and retrieve over groups;\\nUse a chat model to select tools or groups of tool.\\n\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nComments\\nBack to top\\nPrevious How to pass config to toolsNext How to use subgraphs\\nCopyright Â© 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! â¤ï¸\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
       " {'title': 'How to pass runtime values to tools',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/',\n",
       "  'content': 'This guide targets **LangChain tool calling** assumes familiarity with the following:',\n",
       "  'score': 0.4759640028,\n",
       "  'raw_content': 'How to pass runtime values to tools\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nHow to pass runtime values to tools\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\nLearn the basics\\nDeployment\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\n\\n[ ] \\nHow-to Guides\\nHow-to Guides\\n\\n\\n[ ]  LangGraph\\nLangGraph\\n\\nLangGraph\\nGraph API Basics\\nControllability\\nPersistence\\nMemory\\nHuman-in-the-loop\\nStreaming\\n\\n[ ]  Tool calling\\nTool calling\\n\\nTool calling\\nHow to call tools using ToolNode\\nHow to handle tool calling errors\\n\\n[ ]  How to pass runtime values to tools How to pass runtime values to tools\\nTable of contents\\n\\nSetup\\n\\nPass graph state to tools\\n\\nDefine the tools\\nDefine the graph\\nUse it!\\n\\n\\n\\nPass shared memory (store) to the graph\\n\\nDefine the tools\\nDefine the graph\\nUse it!\\n\\n\\n\\n\\n\\nHow to update graph state from tools\\n\\nHow to pass config to tools\\nHow to handle large numbers of tools\\n\\n\\n\\nSubgraphs\\n\\nMulti-agent\\nState Management\\nOther\\nPrebuilt ReAct Agent\\n\\n\\n\\nLangGraph Platform\\n\\n\\n\\n\\nConcepts\\n\\nTutorials\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nSetup\\n\\nPass graph state to tools\\n\\nDefine the tools\\nDefine the graph\\nUse it!\\n\\n\\n\\nPass shared memory (store) to the graph\\n\\nDefine the tools\\nDefine the graph\\nUse it!\\n\\n\\n\\nHome\\n\\nGuides\\nHow-to Guides\\nLangGraph\\nTool calling\\n\\n\\nHow to pass runtime values to toolsÂ¶\\nSometimes, you want to let a tool-calling LLM populate a subset of the tool functions\\' arguments and provide the other values for the other arguments at runtime. If you\\'re using LangChain-style tools, an easy way to handle this is by annotating function parameters with InjectedArg. This annotation excludes that parameter from being shown to the LLM.\\nIn LangGraph applications you might want to pass the graph state or shared memory (store) to the tools at runtime. This type of stateful tools is useful when a tool\\'s output is affected by past agent steps (e.g. if you\\'re using a sub-agent as a tool, and want to pass the message history in to the sub-agent), or when a tool\\'s input needs to be validated given context from past agent steps.\\nIn this guide we\\'ll demonstrate how to do so using LangGraph\\'s prebuilt ToolNode.\\nPrerequisites\\nThis guide targets **LangChain tool calling** assumes familiarity with the following:\\n\\nTools\\nState\\nTool-calling\\n\\nYou can still use tool calling in LangGraph using your provider SDK without losing any of LangGraph\\'s core features.\\nThe core technique the examples below is to annotate a parameter as \"injected\", meaning it will be injected by your program and should not be seen or populated by the LLM. Let the following codesnippet serve as a tl;dr:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-1)fromtypingimport Annotated\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-3)fromlangchain_core.runnablesimport RunnableConfig\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-4)fromlangchain_core.toolsimport InjectedToolArg\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-5)fromlanggraph.store.baseimport BaseStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-6)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-7)fromlanggraph.prebuiltimport InjectedState, InjectedStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-10)# Can be sync or async; @tool decorator not required\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-11)async defmy_tool(\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-12)    # These arguments are populated by the LLM\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-13)    some_arg: str,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-14)    another_arg: float,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-15)    # The config: RunnableConfig is always available in LangChain calls\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-16)    # This is not exposed to the LLM\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-17)    config: RunnableConfig,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-18)    # The following three are specific to the prebuilt ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-19)    # (and `create_react_agent` by extension). If you are invoking the\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-20)    # tool on its own (in your own node), then you would need to provide these yourself.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-21)    store: Annotated[BaseStore, InjectedStore],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-22)    # This passes in the full state.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-23)    state: Annotated[State, InjectedState],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-24)    # You can also inject single fields from your state if you\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-25)    messages: Annotated[list, InjectedState(\"messages\")]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-26)    # The following is not compatible with create_react_agent or ToolNode\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-27)    # You can also exclude other arguments from being shown to the model.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-28)    # These must be provided manually and are useful if you call the tools/functions in your own node\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-29)    # some_other_arg=Annotated[\"MyPrivateClass\", InjectedToolArg],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-30)):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-31)\"\"\"Call my_tool to have an impact on the real world.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-32)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-33)    Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-34)        some_arg: a very important argument\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-35)        another_arg: another argument the LLM will provide\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-36)    \"\"\" # The docstring becomes the description for your tool and is passed to the model\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-37)    print(some_arg, another_arg, config, store, state, messages)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-38)    # Config, some_other_rag, store, and state  are all \"hidden\" from\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-39)    # LangChain models when passed to bind_tools or with_structured_output\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-0-40)    return \"... some response\"\\nAPI Reference: RunnableConfig | InjectedToolArg | InjectedState\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-1-1)\\nSetupÂ¶\\nFirst we need to install the packages required\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-2-1)%%capture --no-stderr\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-2-2)%pip install --quiet -U langgraph langchain-openai\\nNext, we need to set API keys for OpenAI (the chat model we will use).\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-1)importgetpass\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-2)importos\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-5)def_set_env(var: str):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-6)    if not os.environ.get(var):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-9)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-3-10)_set_env(\"OPENAI_API_KEY\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-4-1)OPENAI_API_KEY:  Â·Â·Â·Â·Â·Â·Â·Â·\\nSet up LangSmith for LangGraph development\\nSign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started here.\\nPass graph state to toolsÂ¶\\nLet\\'s first take a look at how to give our tools access to the graph state. We\\'ll need to define our graph state:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-1)fromtypingimport List\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-3)# this is the state schema used by the prebuilt create_react_agent we\\'ll be using below\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-4)fromlanggraph.prebuilt.chat_agent_executorimport AgentState\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-5)fromlangchain_core.documentsimport Document\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-6)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-7)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-8)classState(AgentState):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-5-9)    docs: List[str]\\nAPI Reference: Document\\nDefine the toolsÂ¶\\nWe\\'ll want our tool to take graph state as an input, but we don\\'t want the model to try to generate this input when calling the tool. We can use the InjectedState annotation to mark arguments as required graph state (or some field of graph state. These arguments will not be generated by the model. When using ToolNode, graph state will automatically be passed in to the relevant tools and arguments.\\nIn this example we\\'ll create a tool that returns Documents and then another tool that actually cites the Documents that justify a claim.\\nUsing Pydantic with LangChain\\nThis notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-1)fromtypingimport List, Tuple\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-2)fromtyping_extensionsimport Annotated\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-3)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-4)fromlangchain_core.messagesimport ToolMessage\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-5)fromlangchain_core.toolsimport tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-6)fromlanggraph.prebuiltimport InjectedState\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-7)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-8)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-9)@tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-10)defget_context(question: str, state: Annotated[dict, InjectedState]):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-11)\"\"\"Get relevant context for answering the question.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-6-12)    return \"\\\\n\\\\n\".join(doc for doc in state[\"docs\"])\\nAPI Reference: ToolMessage | tool | InjectedState\\nIf we look at the input schemas for these tools, we\\'ll see that state is still listed:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-7-1)get_context.get_input_schema().schema()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-1){\\'description\\': \\'Get relevant context for answering the question.\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-2) \\'properties\\': {\\'question\\': {\\'title\\': \\'Question\\', \\'type\\': \\'string\\'},\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-3)  \\'state\\': {\\'title\\': \\'State\\', \\'type\\': \\'object\\'}},\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-4) \\'required\\': [\\'question\\', \\'state\\'],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-5) \\'title\\': \\'get_context\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-8-6) \\'type\\': \\'object\\'}\\nBut if we look at the tool call schema, which is what is passed to the model for tool-calling, state has been removed:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-9-1)get_context.tool_call_schema.schema()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-10-1){\\'description\\': \\'Get relevant context for answering the question.\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-10-2) \\'properties\\': {\\'question\\': {\\'title\\': \\'Question\\', \\'type\\': \\'string\\'}},\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-10-3) \\'required\\': [\\'question\\'],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-10-4) \\'title\\': \\'get_context\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-10-5) \\'type\\': \\'object\\'}\\nDefine the graphÂ¶\\nIn this example we will be using a prebuilt ReAct agent. We\\'ll first need to define our model and a tool-calling node (ToolNode):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-1)fromlangchain_openaiimport ChatOpenAI\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-2)fromlanggraph.prebuiltimport ToolNode, create_react_agent\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-3)fromlanggraph.checkpoint.memoryimport MemorySaver\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-5)model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-6)tools = [get_context]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-7)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-8)# ToolNode will automatically take care of injecting state into tools\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-9)tool_node = ToolNode(tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-10)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-11)checkpointer = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-11-12)graph = create_react_agent(model, tools, state_schema=State, checkpointer=checkpointer)\\nAPI Reference: ChatOpenAI | ToolNode | create_react_agent | MemorySaver\\nUse it\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-1)docs = [\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-2)    \"FooBar company just raised 1 Billion dollars!\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-3)    \"FooBar company was founded in 2019\",\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-4)]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-6)inputs = {\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-7)    \"messages\": [{\"type\": \"user\", \"content\": \"what\\'s the latest news about FooBar\"}],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-8)    \"docs\": docs,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-9)}\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-10)config = {\"configurable\": {\"thread_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-11)for chunk in graph.stream(inputs, config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-12-12)    chunk[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-3)what\\'s the latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-5)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-6)  get_context (call_UkqfR7z2cLJQjhatUpDeEa5H)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-7) Call ID: call_UkqfR7z2cLJQjhatUpDeEa5H\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-8)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-9)    question: latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-11)Name: get_context\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-13)FooBar company just raised 1 Billion dollars!\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-14)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-15)FooBar company was founded in 2019\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-16)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-17)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-13-18)The latest news about FooBar is that the company has just raised 1 billion dollars.\\nPass shared memory (store) to the graphÂ¶\\nYou might also want to give tools access to memory that is shared across multiple conversations or users. We can do it by passing LangGraph Store to the tools using a different annotation -- InjectedStore.\\nLet\\'s modify our example to save the documents in an in-memory store and retrieve them using get_context tool. We\\'ll also make the documents accessible based on a user ID, so that some documents are only visible to certain users. The tool will then use the user_id provided in the config to retrieve a correct set of documents.\\nNote\\n\\nSupport for Store API and InjectedStore used in this notebook was added in LangGraph v0.2.34.\\nInjectedStore annotation requires langchain-core >= 0.3.8\\n\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-1)fromlanggraph.store.memoryimport InMemoryStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-3)doc_store = InMemoryStore()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-5)namespace = (\"documents\", \"1\")  # user ID\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-6)doc_store.put(\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-7)    namespace, \"doc_0\", {\"doc\": \"FooBar company just raised 1 Billion dollars!\"}\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-8))\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-9)namespace = (\"documents\", \"2\")  # user ID\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-14-10)doc_store.put(namespace, \"doc_1\", {\"doc\": \"FooBar company was founded in 2019\"})\\nDefine the toolsÂ¶\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-1)fromlanggraph.store.baseimport BaseStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-2)fromlangchain_core.runnablesimport RunnableConfig\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-3)fromlanggraph.prebuiltimport InjectedStore\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-4)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-6)@tool\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-7)defget_context(\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-8)    question: str,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-9)    config: RunnableConfig,\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-10)    store: Annotated[BaseStore, InjectedStore()],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-11)) -> Tuple[str, List[Document]]:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-12)\"\"\"Get relevant context for answering the question.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-13)    user_id = config.get(\"configurable\", {}).get(\"user_id\")\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-14)    docs = [item.value[\"doc\"] for item in store.search((\"documents\", user_id))]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-15-15)    return \"\\\\n\\\\n\".join(doc for doc in docs)\\nAPI Reference: RunnableConfig\\nWe can also verify that the tool-calling model will ignore store arg of get_context tool:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-16-1)get_context.tool_call_schema.schema()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-17-1){\\'description\\': \\'Get relevant context for answering the question.\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-17-2) \\'properties\\': {\\'question\\': {\\'title\\': \\'Question\\', \\'type\\': \\'string\\'}},\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-17-3) \\'required\\': [\\'question\\'],\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-17-4) \\'title\\': \\'get_context\\',\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-17-5) \\'type\\': \\'object\\'}\\nDefine the graphÂ¶\\nLet\\'s update our ReAct agent:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-1)tools = [get_context]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-3)# ToolNode will automatically take care of injecting Store into tools\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-4)tool_node = ToolNode(tools)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-5)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-6)checkpointer = MemorySaver()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-7)# NOTE: we need to pass our store to `create_react_agent` to make sure our graph is aware of it\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-18-8)graph = create_react_agent(model, tools, checkpointer=checkpointer, store=doc_store)\\nUse it\\nLet\\'s try running our graph with a \"user_id\" in the config.\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-19-1)messages = [{\"type\": \"user\", \"content\": \"what\\'s the latest news about FooBar\"}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-19-2)config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-19-3)for chunk in graph.stream({\"messages\": messages}, config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-19-4)    chunk[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-3)what\\'s the latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-5)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-6)  get_context (call_ocyHBpGgF3LPFOgRKURBfkGG)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-7) Call ID: call_ocyHBpGgF3LPFOgRKURBfkGG\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-8)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-9)    question: latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-11)Name: get_context\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-13)FooBar company just raised 1 Billion dollars!\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-15)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-20-16)The latest news about FooBar is that the company has just raised 1 billion dollars.\\nWe can see that the tool only retrieved the correct document for user \"1\" when looking up the information in the store. Let\\'s now try it again for a different user:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-21-1)messages = [{\"type\": \"user\", \"content\": \"what\\'s the latest news about FooBar\"}]\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-21-2)config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"2\"}}\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-21-3)for chunk in graph.stream({\"messages\": messages}, config, stream_mode=\"values\"):\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-21-4)    chunk[\"messages\"][-1].pretty_print()\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-1)================================\\x1b[1m Human Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-2)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-3)what\\'s the latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-4)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-5)Tool Calls:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-6)  get_context (call_zxO9KVlL8UxFQUMb8ETeHNvs)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-7) Call ID: call_zxO9KVlL8UxFQUMb8ETeHNvs\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-8)  Args:\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-9)    question: latest news about FooBar\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-10)=================================\\x1b[1m Tool Message \\x1b[0m=================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-11)Name: get_context\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-12)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-13)FooBar company was founded in 2019\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-14)==================================\\x1b[1m Ai Message \\x1b[0m==================================\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-15)\\n[](https://langchain-ai.github.io/langgraph/how-tos/pass-run-time-values-to-tools/#__codelineno-22-16)FooBar company was founded in 2019. If you need more specific or recent news, please let me know!\\nWe can see that the tool pulled in a different document this time.\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nComments\\nBack to top\\nPrevious How to handle tool calling errorsNext How to update graph state from tools\\nCopyright Â© 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! â¤ï¸\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰\n",
    "tool.invoke({\"query\": \"LangChain Tools ì— ëŒ€í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image ìƒì„± ë„êµ¬ (DALL-E)\n",
    "\n",
    "- `DallEAPIWrapper í´ëž˜ìŠ¤`: OpenAIì˜ DALL-E ì´ë¯¸ì§€ ìƒì„±ê¸°ë¥¼ ìœ„í•œ ëž˜í¼(wrapper)ìž…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë©´ DALL-E APIë¥¼ ì‰½ê²Œ í†µí•©í•˜ì—¬ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ì„ êµ¬í˜„í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì„¤ì • ì˜µì…˜ì„ í†µí•´ ìœ ì—°í•˜ê³  ê°•ë ¥í•œ ì´ë¯¸ì§€ ìƒì„± ë„êµ¬ë¡œ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ì†ì„±**\n",
    "\n",
    "- `model`: ì‚¬ìš©í•  DALL-E ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: \"dall-e-2\", \"dall-e-3\")\n",
    "\n",
    "- `n`: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 1)\n",
    "\n",
    "- `size`: ìƒì„±í•  ì´ë¯¸ì§€ í¬ê¸°\n",
    "  - \"dall-e-2\": \"1024x1024\", \"512x512\", \"256x256\"\n",
    "  - \"dall-e-3\": \"1024x1024\", \"1792x1024\", \"1024x1792\"\n",
    "\n",
    "- `style`: ìƒì„±ë  ì´ë¯¸ì§€ì˜ ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’: \"natural\", \"vivid\")\n",
    "\n",
    "- `quality`: ìƒì„±ë  ì´ë¯¸ì§€ì˜ í’ˆì§ˆ (ê¸°ë³¸ê°’: \"standard\", \"hd\")\n",
    "\n",
    "- `max_retries`: ìƒì„± ì‹œ ìµœëŒ€ ìž¬ì‹œë„ íšŸìˆ˜\n",
    "\n",
    "**ì£¼ìš” ê¸°ëŠ¥**\n",
    "- DALL-E APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„¤ëª…ì— ê¸°ë°˜í•œ ì´ë¯¸ì§€ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**íë¦„ ì •ë¦¬**\n",
    "\n",
    "ë‹¤ìŒì€ DALL-E Image Generator ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì˜ˆì œìž…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì—ëŠ” `DallEAPIWrapper` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë•Œ ìž…ë ¥ í”„ë¡¬í”„íŠ¸ëŠ” LLM ëª¨ë¸ì—ê²Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìž‘ì„±í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a neo-classical painting that satirizes people looking at smartphones. The scene should depict a diverse group of individuals in an elegant, classical setting, reminiscent of ancient Greek or Roman architecture. They should be dressed in traditional attire with flowing robes and intricate details, but each person is fixated on their smartphones, creating a humorous contrast between the classical style and modern technology. Soft, natural lighting should illuminate their expressions of fascination and distraction. Include elements like columns, a marble fountain, and lush greenery in the background, blending the grandeur of neo-classical art with the absurdity of contemporary smartphone culture. The overall tone should be both whimsical and thought-provoking, inviting viewers to reflect on the juxtaposition of past and present.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.9, max_tokens=1000)\n",
    "\n",
    "# DALL-E ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, LLM, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "image_prompt = chain.invoke(\n",
    "    {\"image_desc\": \"ìŠ¤ë§ˆíŠ¸í°ì„ ë°”ë¼ë³´ëŠ” ì‚¬ëžŒë“¤ì„ í’ìží•œ neo-classicism painting\"}\n",
    ")\n",
    "\n",
    "# ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì¶œë ¥\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¼, ì´ì „ì— ìƒì„±í•œ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ `DallEAPIWrapper` ì— ìž…ë ¥í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DallEAPIWrapper` ì— ëŒ€í•œ ìž„ì‹œ ë²„ê·¸ ì•ˆë‚´ì‚¬í•­** (ìž‘ì„±ì¼: 2024-10-13)\n",
    "\n",
    "- í˜„ìž¬ langchain 0.3.x ì´ìƒ ë²„ì „ì—ì„œ `DallEAPIWrapper` ì— ëŒ€í•œ ìž„ì‹œ ë²„ê·¸ê°€ ìžˆìŠµë‹ˆë‹¤. (`401 ì˜¤ë¥˜: invalid API key`)\n",
    "\n",
    "ë”°ë¼ì„œ, ì•„ëž˜ì˜ ì½”ë“œë¥¼ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” LangChain ë²„ì „ì„ 0.2.16 ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ëž˜ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰í•˜ë©´ LangChain ë²„ì „ì„ 0.2.16 ìœ¼ë¡œ ë³€ê²½ë©ë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ, ì´í›„ ë‚´ìš©ì—ì„œëŠ” LangChain ë²„ì „ì„ 0.3.x ì´ìƒìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì—\n",
    "\n",
    "`poetry shell` ëª…ë ¹ì–´ë¥¼ í†µí•´ ë‹¤ì‹œ ìµœì‹  langchain ë²„ì „ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê³¼ì •ì´ ë²ˆê±°ë¡œìš´ ë¶„ë“¤ì€ ì¼ë‹¨ `DallEAPIWrapper` ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§„í–‰í•˜ì…”ë„ ë¬´ë°©í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì—…ê·¸ë ˆì´ë“œ/ë‹¤ìš´ê·¸ë ˆì´ë“œ** í›„ì—ëŠ” ë°˜ë“œì‹œ ìƒë‹¨ ë©”ë‰´ì˜ \"Restart\" ë²„íŠ¼ì„ í´ë¦­í•œ ë’¤ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìž„ì‹œ ë²„ì „ ë‹¤ìš´ê·¸ë ˆì´ë“œ ëª…ë ¹ì–´ (ì‹¤í–‰ í›„ restart)\n",
    "# !pip install langchain==0.2.16 langchain-community==0.2.16 langchain-text-splitters==0.2.4 langchain-experimental==0.0.65 langchain-openai==0.1.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-7c9J2OAcOUFTXC5xFVsaZjns/user-gUTWYjUBJ8idGcqbhboJaxVx/img-oYy3vusZlaxcG97WPLyiGONt.png?st=2025-03-20T18%3A03%3A30Z&se=2025-03-20T20%3A03%3A30Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-03-20T06%3A00%3A07Z&ske=2025-03-21T06%3A00%3A07Z&sks=b&skv=2024-08-04&sig=fFDOhJkTES7AmO0wmekQY0gOaPU6bhsYHDsWOqu7Ks8%3D\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DALL-E API ëž˜í¼ ê°€ì ¸ì˜¤ê¸°\n",
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "# DALL-E API ëž˜í¼ ì´ˆê¸°í™”\n",
    "# model: ì‚¬ìš©í•  DALL-E ëª¨ë¸ ë²„ì „\n",
    "# size: ìƒì„±í•  ì´ë¯¸ì§€ í¬ê¸°\n",
    "# quality: ì´ë¯¸ì§€ í’ˆì§ˆ\n",
    "# n: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜\n",
    "dalle = DallEAPIWrapper(\n",
    "    model=\"dall-e-3\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# ì§ˆë¬¸\n",
    "query = \"ì•„ì´ìœ  ì½˜ì„œíŠ¸ë¥¼ ë°”ë¼ë³´ëŠ” ì‚¬ëžŒë“¤ì„ ëª¨ìŠµì„ ê·¸ë ¤\"\n",
    "\n",
    "# ì´ë¯¸ì§€ ìƒì„± ë° URL ë°›ê¸°\n",
    "# chain.invoke()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì„¤ëª…ì„ DALL-E í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜\n",
    "# dalle.run()ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„±\n",
    "image_url = dalle.run(chain.invoke({\"image_desc\": query}))\n",
    "\n",
    "# ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "Image(url=image_url, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‚¬ìš©ìž ì •ì˜ ë„êµ¬(Custom Tool)\n",
    "\n",
    "LangChain ì—ì„œ ì œê³µí•˜ëŠ” ë¹ŒíŠ¸ì¸ ë„êµ¬ ì™¸ì—ë„ ì‚¬ìš©ìžê°€ ì§ì ‘ ë„êµ¬ë¥¼ ì •ì˜í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¥¼ ìœ„í•´ì„œëŠ” `langchain.tools` ëª¨ë“ˆì—ì„œ ì œê³µí•˜ëŠ” `tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### @tool ë°ì½”ë ˆì´í„°\n",
    "\n",
    "ì´ ë°ì½”ë ˆì´í„°ëŠ” í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì˜µì…˜ì„ í†µí•´ ë„êµ¬ì˜ ë™ìž‘ì„ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì‚¬ìš© ë°©ë²•**\n",
    "1. í•¨ìˆ˜ ìœ„ì— `@tool` ë°ì½”ë ˆì´í„° ì ìš©\n",
    "2. í•„ìš”ì— ë”°ë¼ ë°ì½”ë ˆì´í„° ë§¤ê°œë³€ìˆ˜ ì„¤ì •\n",
    "\n",
    "ì´ ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ ê°•ë ¥í•œ ë„êµ¬ë¡œ ì‰½ê²Œ ë³€í™˜í•  ìˆ˜ ìžˆìœ¼ë©°, ìžë™í™”ëœ ë¬¸ì„œí™”ì™€ ìœ ì—°í•œ ì¸í„°íŽ˜ì´ìŠ¤ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰\n",
    "add_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë„êµ¬ ì‹¤í–‰\n",
    "multiply_numbers.invoke({\"a\": 3, \"b\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### êµ¬ê¸€ ë‰´ìŠ¤ê¸°ì‚¬ ê²€ìƒ‰ ë„êµ¬\n",
    "\n",
    "`langchain-teddynote` íŒ¨í‚¤ì§€ì—ì„œ ì œê³µí•˜ëŠ” `GoogleNews` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ê¸€ ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤.\n",
    "\n",
    "**ì°¸ê³ **\n",
    "- API í‚¤ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (RSS í”¼ë“œë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸)\n",
    "\n",
    "news.google.com ì—ì„œ ì œê³µí•˜ëŠ” ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤.\n",
    "\n",
    "**ì„¤ëª…**\n",
    "- êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "- í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "- ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë§¤ê°œë³€ìˆ˜**\n",
    "- `k` (int): ë°˜í™˜í•  ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ìš©í•˜ê¸° ì „ íŒ¨í‚¤ì§€ë¥¼ ì—…ë°ì´íŠ¸ í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -qU langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import GoogleNews\n",
    "\n",
    "# ë„êµ¬ ìƒì„±\n",
    "news_tool = GoogleNews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMijwFBVV95cUxOcUQtVGthbHRPN01QSTlNWlV6bmtiU2VLZURFSl93MTlKdWZ2LTN5YXA1MnV0M1Y2UFFWTmUwNFZ4NGNkSGsydjVCcFZtUXFzYnJqT2FHM0R5WVVtUHQ5RDNBdzVQTW9pYWFnNHdoQng2RFhFMk9qUjdFZnY1d3VwMTI4d2tsMjZEYkJZd1BrSdIBowFBVV95cUxNSVAxNXJVeGN3LW9IQkxSby1Yd0tFbVdjRERUVnNvMkpNUWljdFBKUkRKS2lFNXNiOUVOM2pUaDRicXJyUld1QWU3TzdCbVlSM2VOcEZOcVpHb1NuUDZWZ21pUWhCbEFTc3YySXhJWGpmbUNncFF1b3BDRmtJR0Z4aTZMSWVSVFBrYmVKYTRaUkNwaTRxQjNCbWt2a3N1N1NURkJJ?oc=5',\n",
       "  'content': 'ì›”ê¸‰ 309ë§Œì› ì‹ ê·œ, 2707ë§Œì› ë” ë‚´ê³  2170ë§Œì› ë” ë°›ëŠ”ë‹¤ - ì¡°ì„ ì¼ë³´'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMickFVX3lxTE9TVktVYTdYZVFiVkduSmx3RXNFa0FaUmVaQmdLbEtVMTRUaGNwd0JRX2xKMDlHRUdodEI0VmN2S0c0cElCZFVUcFUyNWt2OU9hQmlDT0NZNWxOTWFkRmpTZ2JtMi1kdWt2bUt2UXhaVC12Zw?oc=5',\n",
       "  'content': 'â€˜ìœ¤ì„ì—´ íŒŒë©´â€™ ì´í›„ ë‚´ë‹¤ë´¤ë‚˜â€¦í•œë•ìˆ˜ ë¨¼ì € íƒ„í•µì‹¬íŒ ì„ ê³ , ì™œ - í•œê²¨ë ˆ'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMidEFVX3lxTE1GU2FSNU90MHZwSHM4dFNILW5QUzBwdExhaC1HU0FuT056cm02WlNBRmk5UVBYNFZTUDRydmJ1bmFWeWZSMUkzbTNHQ2t2Q01Wc3g5NVdfdVBoZTU0cmxxMHJaM0MtUFVZb2RBajlLMXVYVmk1?oc=5',\n",
       "  'content': '[ì†ë³´] â€˜ê¹€ê±´í¬ ìƒì„¤íŠ¹ê²€â€™ ë³¸íšŒì˜ í†µê³¼â€¦êµ­íž˜ ë‹¹ë¡  ë°˜ëŒ€ - í•œê²¨ë ˆ'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiWkFVX3lxTE5NT3pfTFpYTVZPYi1KR3c5NTBaSENCLS15aEtOWTBxX21GNmZPOE9pbUxjLUxjbTlVYWhyX01ZRnlkMHdrcmVFZ19QdFZkNnZndnNOanZIczdNUdIBVEFVX3lxTE1CSEpGR2tkYTBlaWl0aWd1RW9PRmlxSkRtSzZVV0dYVlhmSDU5RkhZWV9KSjRBWXh3M0tsci1tUXZ5TW9WUldkeEZ3QjY5MzlRQmJZVw?oc=5',\n",
       "  'content': '\\'íŽ˜ë„í‹°\\' ì—†ì• ìž \"ê²°í˜¼í•˜ë©´ ì´ë“\"â€¦\\'90ë…„ëŒ€ìƒ\\' í™• ë‹¬ë¼ì¡Œë‹¤ - í•œêµ­ê²½ì œ'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiSkFVX3lxTE5LdmtzYl9JVTdNZHdIbkxHNi1ZU0l5M2JKNGR0S2hfYi1CQ3J5czY0aHBpN2hpQ25FdFc3Z2diV3VwcWNXZ2xSUEpB?oc=5',\n",
       "  'content': '[í˜„ìž¥ì—ì„œ] ìœ¤ì„ì—´ì˜ ë§ìƒê³¼ 12Â·3 ê·¸ë‚  ëŒ€í•œë¯¼êµ­ì˜ ì§„ì§œ í’ê²½ - ë‰´ìŠ¤íƒ€íŒŒ'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰\n",
    "news_tool.search_latest(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMiaEFVX3lxTFB3NzRrZ2JfU2dXV1lVSEtSSG96N2xlMDlURUh0T215UzE2MlQwMzNnSGZtQ0ZkOEhNdmlieUpPQmw4ZC1fNmw2RmJoRW9fT3h2bERVVnp5UFpGSkpLdHhnamVBTXhWUkY30gFsQVVfeXFMTk1BajBPdHBoSU1mMVZRM1E2SWU4N01HZHhDY0JMMDY3cVZ5NEYyOVpUZjlrVjdWamxSZHhkOUtuYVo0dkQ1TnZrQm5Ydkd2bWJfRTZTa2h3T1FRQnlyQ25QV1dQalJ0dTViMENr?oc=5',\n",
       "  'content': \"'AI ì „ëžµ íˆ¬ìž' ëŠ˜ë¦¬ëŠ” SKT, ê²½ìŸë ¥Â·ì§€ë¶„ê°€ì¹˜ ëª¨ë‘ ìž¡ëŠ”ë‹¤ - ë¸”ë¡œí„°\"},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiYkFVX3lxTE5DeG0zT25CUjkyVGx4MVp2cTlGS1ZVWXFLcWRDTmo3V2dQTlduR05DRjd5dFBUeDZzVTR2WkxLemcxdkIxU3JDRzQ2cmpNSjBaOU9Za0RZUXZCTEI4ZHU3eTVB?oc=5',\n",
       "  'content': 'ì—”ë¹„ë””ì•„Â·xAIÂ·ë¸”ëž™ë¡Â·MS, AI ì¸í”„ë¼ ë™ë§¹â€¦\"ìµœëŒ€ 146ì¡° íˆ¬ìž\" - ë”êµ¬ë£¨'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiU0FVX3lxTE9kRVRWQmNrOUZYQ2J3NzhFVmhyM1hxMENsSUFJTWF3VHBWMEhNYkF5aTMxN0ZXeHlJRW9ORXY3OEJuYTZ3VG1RZWNqbWxvWjU0SmxV0gFYQVVfeXFMT1JjQ2VRX01TYUdxZlhoaEVVQkNYLUZfeXlIaHF0S0M3UENQZUJyUGw5U0pfV3Bnb3BXTS1ZQk8yMV9jWDF2cjhDclY1dUU3TnhPU3hpemd1dA?oc=5',\n",
       "  'content': '[ê°•ì •ìˆ˜ì˜ AI íˆ¬ìžì „ëžµ] ìµœê·¼ ì¡°ì • ë°›ì•˜ë˜ ë‰´ìš•ì¦ì‹œâ€¦ì§„ì§œ ë°”ë‹¥ì€ ì•„ì§? - SBS Biz'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰\n",
    "news_tool.search_by_keyword(\"AI íˆ¬ìž\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import GoogleNews\n",
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ ìƒì„±\n",
    "@tool\n",
    "def search_keyword(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Look up news by keyword\"\"\"\n",
    "    print(query)\n",
    "    news_tool = GoogleNews()\n",
    "    return news_tool.search_by_keyword(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://news.google.com/rss/articles/CBMibkFVX3lxTE1qMC1EYjRZOEpMNVBEVVpSNm1BX3A4a3FrdmEyOTdDNWdjMGR1ZEgzWlpHZnRFZ1pSUXdKa3JnOXBQZU5qU3dKS3Q5VUNwLVZxRFZmbG1SZzJVSUoyM2lJbnZRbzhYYUJJcnFHWmp3?oc=5',\n",
       "  'content': 'ëž­ì²´ì¸ LangChain ì´ëž€ ë¬´ì—‡ì¸ê°€? | ì¸ì‚¬ì´íŠ¸ë¦¬í¬íŠ¸ | ì‚¼ì„±SDS - Samsung SDS'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiRkFVX3lxTE9uUGJ0bWNwMlE4M1ZRcVJRckl3R3c5anZHdDRkWU5UeTYtRkFrWGtWLVY0ZVBQcENHSHlMZXlWV3d6akxtalE?oc=5',\n",
       "  'content': '06í™” 5. ì§€ì‹œíŠœë‹ê³¼ RLHF - ë¸ŒëŸ°ì¹˜'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiXEFVX3lxTE1FejJlRDF0QXZwME9YMHhGZkxEOXpKS045ZWhISFRYRHJWNDIyRlM4bk5MUXNTanA4T2JtWVF1aXhTcE5ReVFaR3M1ZDVJemtteE9UMVdRTkxCRk9u?oc=5',\n",
       "  'content': 'LangChainì´ëž€ ë¬´ì—‡ì¸ê°€ìš”? - IBM'},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiU0FVX3lxTFB4elpEOFRybFZUY0Q5WmJRYUJxdVBUdldjU3lkVDdHVno4ek9rbWxlVUhvQXp2bU5weU9iZVJZZ3lIYVctVFdGdDZ6eW5wSDZHMnNB?oc=5',\n",
       "  'content': \"ì†¡íŒŒìƒˆì¼ì„¼í„°, 'JAVA&Spring ë°±ì—”ë“œ ê°œë°œìž(LangChain LLM í”„ë¡œì íŠ¸)' ê³¼ì • í›ˆë ¨ìƒ ëª¨ì§‘ - ë„¤ì´íŠ¸ ë‰´ìŠ¤\"},\n",
       " {'url': 'https://news.google.com/rss/articles/CBMiRkFVX3lxTE04LVVxZF8wc09QVGxFWjRURWktdTdRNE5VYWYweVkteHdxaDRDbjY1OUpLeDUtbWxTVnRWT3gwTWVsSk5OUHc?oc=5',\n",
       "  'content': '20í™” 19. RAG(ê²€ìƒ‰ì¦ê°•ìƒì„±) ì§€ì› - ë¸ŒëŸ°ì¹˜'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤í–‰ ê²°ê³¼\n",
    "search_keyword.invoke({\"query\": \"LangChain AI\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-h6vp0ZFq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
