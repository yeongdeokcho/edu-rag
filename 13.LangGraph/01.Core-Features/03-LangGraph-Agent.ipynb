{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec680f5",
   "metadata": {},
   "source": [
    "# LangGraph 활용 Agent 구축\n",
    "\n",
    "이번 튜토리얼에서는 웹 검색 도구를 통해 챗봇에 웹 검색 기능수행하는 Agent 을 추가합니다.\n",
    "\n",
    "LLM 에 도구를 바인딩하여 LLM 에 입력된 요청에 따라 필요시 웹 검색 도구(Tool)를 호출하는 Agent 을 구축합니다.\n",
    "\n",
    "뿐만아니라, 조건부 엣지를 통해 도구 호출 여부에 따라 다른 노드로 라우팅하는 방법도 함께 배워봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de9d9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5c6228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH13-LangGraph-Modules\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH13-LangGraph-Modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5376bf",
   "metadata": {},
   "source": [
    "## 도구(Tool) 사용하기\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [도구(Tools)](https://wikidocs.net/262582)\n",
    "\n",
    "챗봇이 \"기억\"에서 답변할 수 없는 질문을 처리하기 위해 웹 검색 도구를 통합할 것입니다. 이 도구를 사용하여 관련 정보를 찾아 더 나은 응답을 제공할 수 있습니다.\n",
    "\n",
    "### 검색 API 도구\n",
    "\n",
    "Tavily 검색 API를 활용하여 검색 기능을 구현하는 도구입니다. 이 도구는 두 가지 주요 클래스를 제공합니다: `TavilySearchResults`와 `TavilyAnswer`.\n",
    "\n",
    "**API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "발급한 API 키를 환경변수에 설정합니다.\n",
    "\n",
    "`.env` 파일에 아래와 같이 설정합니다.\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**설명**\n",
    "- Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환합니다.\n",
    "- 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진입니다.\n",
    "- 현재 이벤트에 대한 질문에 답변할 때 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbcea8",
   "metadata": {},
   "source": [
    "다음으로 웹 검색 도구인 `TavilySearchResults`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163da255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-teddynote in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (0.3.44)\n",
      "Requirement already satisfied: langchain in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.3.20)\n",
      "Requirement already satisfied: langgraph in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.3.11)\n",
      "Requirement already satisfied: kiwipiepy in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.17.1)\n",
      "Requirement already satisfied: rank_bm25 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: pinecone-client[grpc] in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (5.0.1)\n",
      "Requirement already satisfied: pinecone-text in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.10.0)\n",
      "Requirement already satisfied: olefile in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: pdf2image in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: openai in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (1.66.3)\n",
      "Requirement already satisfied: anthropic in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.49.0)\n",
      "Requirement already satisfied: deepl in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: feedparser in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (6.0.11)\n",
      "Requirement already satisfied: tavily-python in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (0.5.1)\n",
      "Requirement already satisfied: pandas in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-teddynote) (2.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anthropic->langchain-teddynote) (4.12.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from deepl->langchain-teddynote) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from feedparser->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: kiwipiepy-model<0.18,>=0.17 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (0.17.0)\n",
      "Requirement already satisfied: numpy in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from kiwipiepy->langchain-teddynote) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.3.45)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain->langchain-teddynote) (0.1.147)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain->langchain-teddynote) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain->langchain-teddynote) (6.0.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (2.0.20)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (0.1.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langgraph->langchain-teddynote) (0.1.57)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pandas->langchain-teddynote) (2025.1)\n",
      "Requirement already satisfied: pillow in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pdf2image->langchain-teddynote) (10.4.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (2025.1.31)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.69.2)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.71.0)\n",
      "Requirement already satisfied: lz4>=3.1.3 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.4.3)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.7)\n",
      "Requirement already satisfied: protobuf<5.0,>=4.25 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (4.25.6)\n",
      "Requirement already satisfied: protoc-gen-openapiv2<0.0.2,>=0.0.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (0.0.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-client[grpc]->langchain-teddynote) (2.3.0)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (1.0.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pinecone-text->langchain-teddynote) (2.32.0.20250306)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from tavily-python->langchain-teddynote) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->anthropic->langchain-teddynote) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->anthropic->langchain-teddynote) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic->langchain-teddynote) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain->langchain-teddynote) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain->langchain-teddynote) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain->langchain-teddynote) (23.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->langchain-teddynote) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->langchain-teddynote) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: click in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain-teddynote) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->anthropic->langchain-teddynote) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from requests<3,>=2->deepl->langchain-teddynote) (3.4.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->langchain-teddynote) (3.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/doong2s/Library/Caches/pypoetry/virtualenvs/edu-rag-h6vp0ZFq-py3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain->langchain-teddynote) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c04fccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': '② LangChain 한국어 튜토리얼 바로가기 👀 ③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌 ④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌 ⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 2023년 09월 28일 5 분 소요 목차 🌱 랭체인의 주요 기능 🌱 환경설정 API KEY 발급 모듈 설치(openai, langchain) 🔥 ChatOpenAI 🔥 프롬프트 템플릿의 활용 LLMChain 객체 ① run() ② apply() ③ generate() ④ 2개 이상의 변수를 템플릿 안에 정의 ⑤ 스트리밍(streaming) 언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다. 튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다. 추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다. 특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.', 'score': 0.8548001, 'raw_content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n2023년 09월 28일 5 분 소요\\n목차\\n\\n🌱 랭체인의 주요 기능\\n🌱 환경설정\\nAPI KEY 발급\\n모듈 설치(openai, langchain)\\n\\n\\n🔥 ChatOpenAI\\n🔥 프롬프트 템플릿의 활용\\nLLMChain 객체\\n① run()\\n② apply()\\n③ generate()\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n⑤ 스트리밍(streaming)\\n\\n\\n\\n언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다.\\n튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다.\\n🌱 랭체인의 주요 기능\\n랭체인을 통해 다음과 같은 특징을 갖는 애플리케이션을 개발할 수 있습니다.\\n\\n문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\\n추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\\n\\n랭체인의 가치\\n랭체인의 핵심적인 가치는 여러 가지가 있지만, 그 중에서도 두 가지 주요한 점을 꼽자면 다음과 같습니다.\\n\\n구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\\n사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다.\\n\\n특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.\\n🌱 환경설정\\nAPI KEY 발급\\n먼저, openai 의 API KEY 를 발급 받아야 합니다. 발급은 다음의 절차를 통해 진행할 수 있습니다.\\nhttps://platform.openai.com/account/api-keys 로 접속합니다.\\n\\nLog in 버튼을 클릭 후 계정에 로그인 합니다. 계정이 아직 생성되지 않은 경우에는 Sign up 으로 회원가입 후 로그인 합니다.\\n\\n\\n\\n“Create new secret key” 버튼을 클릭하여 새로운 키를 발급합니다.\\n\\n\\n\\nName 에는 발급하는 키에 대한 별칭을 입력합니다.\\n\\n\\n\\n새롭게 발급한 키를 복사합니다. 잃어버리면 다시 발급하여야 하므로, 안전한 곳에 저장해 둡니다.\\n\\n\\n모듈 설치(openai, langchain)\\npip 명령어로 모듈을 설치 합니다. 아나콘다 가상환경에서 설치해도 좋습니다.\\n```\\nopenai 파이썬 패키지 설치\\npip install openai langchain\\n```\\n먼저, 설치한 openai 모듈을 import 한 뒤, 발급받은 API KEY를 다음과 같이 설정합니다.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY 입력'\\n```\\n사용 가능한 모델 리스트 출력\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\n🔥 ChatOpenAI\\nOpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\\n객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\\ntemperature\\n\\n사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\\n\\nmax_tokens\\n\\n채팅 완성에서 생성할 토큰의 최대 개수입니다.\\n\\nmodel_name: 적용 가능한 모델 리스트\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                )\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n질의\\nprint(f'[답변]: {llm.predict(question)}')\\n```\\n[답변]: 대한민국의 수도는 서울입니다.\\n🔥 프롬프트 템플릿의 활용\\nPromptTemplate\\n\\n\\n사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\\n\\n\\n사용법\\n\\n\\ntemplate: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\\n\\n\\ninput_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\\n\\n\\n사용법: 리스트 형식으로 변수 이름을 정의합니다.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\n질문 템플릿 형식 정의\\ntemplate = '{country}의 수도는 뭐야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain 객체\\nLLMChain\\n\\n\\nLLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\\n\\n\\n사용법\\n\\n\\nprompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\\n\\n\\nllm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\\n\\n\\n\\n\\n```\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n① run()\\nrun() 함수로 템플릿 프롬프트 실행\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='일본'))\\n```\\n일본의 수도는 도쿄입니다.\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='캐나다'))\\n```\\n캐나다의 수도는 오타와(Ottawa)입니다.\\n② apply()\\napply() 함수로 여러개의 입력을 한 번에 실행\\n```\\ninput_list = [\\n    {'country': '호주'},\\n    {'country': '중국'},\\n    {'country': '네덜란드'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': '호주의 수도는 캔버라입니다.'},\\n {'text': '중국의 수도는 베이징(北京)입니다.'},\\n {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]\\ntext 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\\n이를 반복문으로 출력한다면 다음과 같습니다.\\n```\\ninput_list 에 대한 결과 반환\\nresult = llm_chain.apply(input_list)\\n반복문으로 결과 출력\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n③ generate()\\ngenerate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\\nLLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\\n```\\ninput_list 에 대한 결과 반환\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]\\n```\\n토큰 사용량 출력\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID 출력\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\\n이번에는 2개 이상의 변수(input_variables) 를 활용하여 템플릿 구성을 해보겠습니다.\\n```\\n질문 템플릿 형식 정의\\ntemplate = '{area1} 와 {area2} 의 시차는 몇시간이야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\n체인 실행: run()\\nprint(llm_chain.run(area1='서울', area2='파리'))\\n```\\n서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\\n```\\ninput_list = [\\n    {'area1': '파리', 'area2': '뉴욕'},\\n    {'area1': '서울', 'area2': '하와이'},\\n    {'area1': '켄버라', 'area2': '베이징'}\\n]\\n반복문으로 결과 출력\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n파리와 뉴욕의 시차는 일반적으로 6시간입니다. 파리가 뉴욕보다 6시간 앞서 있습니다. 예를 들어, 파리가 오전 9시라면 뉴욕은 오전 3시입니다.\\n서울과 하와이의 시차는 서울이 하와이보다 19시간 빠릅니다. 예를 들어, 서울이 오전 9시라면 하와이는 전날 오후 2시입니다.\\n켄버라와 베이징의 시차는 2시간입니다. 켄버라는 오스트레일리아의 수도로 UTC+10 시간대에 위치하고, 베이징은 중국의 수도로 UTC+8 시간대에 위치합니다.\\n⑤ 스트리밍(streaming)\\n스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\\n다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n스트리밍으로 답변 출력\\nresponse = llm.predict(question)\\n```\\n대한민국의 수도는 서울입니다.\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\\n카테고리: langchain\\n업데이트: 2023년 09월 28일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {'title': '랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': '② LangChain 한국어 튜토리얼 바로가기 👀 ③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌 ④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌 ⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 2023년 09월 28일 5 분 소요 목차 🌱 랭체인의 주요 기능 🌱 환경설정 API KEY 발급 모듈 설치(openai, langchain) 🔥 ChatOpenAI 🔥 프롬프트 템플릿의 활용 LLMChain 객체 ① run() ② apply() ③ generate() ④ 2개 이상의 변수를 템플릿 안에 정의 ⑤ 스트리밍(streaming) 언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다. 튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다. 추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다. 특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.', 'score': 0.8548001, 'raw_content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n2023년 09월 28일 5 분 소요\\n목차\\n\\n🌱 랭체인의 주요 기능\\n🌱 환경설정\\nAPI KEY 발급\\n모듈 설치(openai, langchain)\\n\\n\\n🔥 ChatOpenAI\\n🔥 프롬프트 템플릿의 활용\\nLLMChain 객체\\n① run()\\n② apply()\\n③ generate()\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n⑤ 스트리밍(streaming)\\n\\n\\n\\n언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다.\\n튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다.\\n🌱 랭체인의 주요 기능\\n랭체인을 통해 다음과 같은 특징을 갖는 애플리케이션을 개발할 수 있습니다.\\n\\n문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\\n추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\\n\\n랭체인의 가치\\n랭체인의 핵심적인 가치는 여러 가지가 있지만, 그 중에서도 두 가지 주요한 점을 꼽자면 다음과 같습니다.\\n\\n구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\\n사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다.\\n\\n특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.\\n🌱 환경설정\\nAPI KEY 발급\\n먼저, openai 의 API KEY 를 발급 받아야 합니다. 발급은 다음의 절차를 통해 진행할 수 있습니다.\\nhttps://platform.openai.com/account/api-keys 로 접속합니다.\\n\\nLog in 버튼을 클릭 후 계정에 로그인 합니다. 계정이 아직 생성되지 않은 경우에는 Sign up 으로 회원가입 후 로그인 합니다.\\n\\n\\n\\n“Create new secret key” 버튼을 클릭하여 새로운 키를 발급합니다.\\n\\n\\n\\nName 에는 발급하는 키에 대한 별칭을 입력합니다.\\n\\n\\n\\n새롭게 발급한 키를 복사합니다. 잃어버리면 다시 발급하여야 하므로, 안전한 곳에 저장해 둡니다.\\n\\n\\n모듈 설치(openai, langchain)\\npip 명령어로 모듈을 설치 합니다. 아나콘다 가상환경에서 설치해도 좋습니다.\\n```\\nopenai 파이썬 패키지 설치\\npip install openai langchain\\n```\\n먼저, 설치한 openai 모듈을 import 한 뒤, 발급받은 API KEY를 다음과 같이 설정합니다.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY 입력'\\n```\\n사용 가능한 모델 리스트 출력\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\n🔥 ChatOpenAI\\nOpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\\n객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\\ntemperature\\n\\n사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\\n\\nmax_tokens\\n\\n채팅 완성에서 생성할 토큰의 최대 개수입니다.\\n\\nmodel_name: 적용 가능한 모델 리스트\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                )\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n질의\\nprint(f'[답변]: {llm.predict(question)}')\\n```\\n[답변]: 대한민국의 수도는 서울입니다.\\n🔥 프롬프트 템플릿의 활용\\nPromptTemplate\\n\\n\\n사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\\n\\n\\n사용법\\n\\n\\ntemplate: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\\n\\n\\ninput_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\\n\\n\\n사용법: 리스트 형식으로 변수 이름을 정의합니다.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\n질문 템플릿 형식 정의\\ntemplate = '{country}의 수도는 뭐야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain 객체\\nLLMChain\\n\\n\\nLLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\\n\\n\\n사용법\\n\\n\\nprompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\\n\\n\\nllm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\\n\\n\\n\\n\\n```\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n① run()\\nrun() 함수로 템플릿 프롬프트 실행\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='일본'))\\n```\\n일본의 수도는 도쿄입니다.\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='캐나다'))\\n```\\n캐나다의 수도는 오타와(Ottawa)입니다.\\n② apply()\\napply() 함수로 여러개의 입력을 한 번에 실행\\n```\\ninput_list = [\\n    {'country': '호주'},\\n    {'country': '중국'},\\n    {'country': '네덜란드'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': '호주의 수도는 캔버라입니다.'},\\n {'text': '중국의 수도는 베이징(北京)입니다.'},\\n {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]\\ntext 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\\n이를 반복문으로 출력한다면 다음과 같습니다.\\n```\\ninput_list 에 대한 결과 반환\\nresult = llm_chain.apply(input_list)\\n반복문으로 결과 출력\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n③ generate()\\ngenerate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\\nLLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\\n```\\ninput_list 에 대한 결과 반환\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]\\n```\\n토큰 사용량 출력\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID 출력\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\\n이번에는 2개 이상의 변수(input_variables) 를 활용하여 템플릿 구성을 해보겠습니다.\\n```\\n질문 템플릿 형식 정의\\ntemplate = '{area1} 와 {area2} 의 시차는 몇시간이야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\n체인 실행: run()\\nprint(llm_chain.run(area1='서울', area2='파리'))\\n```\\n서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\\n```\\ninput_list = [\\n    {'area1': '파리', 'area2': '뉴욕'},\\n    {'area1': '서울', 'area2': '하와이'},\\n    {'area1': '켄버라', 'area2': '베이징'}\\n]\\n반복문으로 결과 출력\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n파리와 뉴욕의 시차는 일반적으로 6시간입니다. 파리가 뉴욕보다 6시간 앞서 있습니다. 예를 들어, 파리가 오전 9시라면 뉴욕은 오전 3시입니다.\\n서울과 하와이의 시차는 서울이 하와이보다 19시간 빠릅니다. 예를 들어, 서울이 오전 9시라면 하와이는 전날 오후 2시입니다.\\n켄버라와 베이징의 시차는 2시간입니다. 켄버라는 오스트레일리아의 수도로 UTC+10 시간대에 위치하고, 베이징은 중국의 수도로 UTC+8 시간대에 위치합니다.\\n⑤ 스트리밍(streaming)\\n스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\\n다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n스트리밍으로 답변 출력\\nresponse = llm.predict(question)\\n```\\n대한민국의 수도는 서울입니다.\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\\n카테고리: langchain\\n업데이트: 2023년 09월 28일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.70531887, 'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'}, {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.70531887, 'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'}, {'title': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...', 'url': 'https://github.com/teddylee777/langchain-kr', 'content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python', 'score': 0.4948006, 'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\n📘 LangChain 한국어 튜토리얼\\n\\n\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\n📔 위키독스 전자책(무료)\\n\\n\\n위키독스에 무료 전자책을 등록하였습니다✌️\\n위키독스 페이지에서 책 \"추천\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\n\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\n\\n🍿 유튜브\\n\\n\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\n마법같은 문법 LangChain Expression Language(LCEL)\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\n\\n✏️ 블로그 글 목록\\n\\nGeneral\\n\\n\\nOpenAI API 모델 리스트 / 요금표\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API 키 발급방법, 요금체계\\n채팅(chat) 함수 사용하기(1)\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\n허깅페이스(HuggingFace) 모델 사용법\\n챗(chat) - ConversationChain, 템플릿 사용법\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n웹사이트 크롤링 - 웹사이트 문서 요약\\n웹사이트 정보 추출 - 스키마 활용법\\nPDF 문서요약, Map-Reduce\\nPDF 기반 질의응답(Question-Answering)\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n👥 LangChain 밋업 2024 Q1 발표자료\\n\\n\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\nOpenAI SORA 살짝 맛보기 - 박정현님\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\nLlama2-koen을 만들기까지 - 최태균님\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\n랭체인 네이버 기사 크롤링 - 우성우님\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\n\\n📜 라이선스\\n\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\n🚫 라이선스 고지\\n\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\n```\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\n인용 및 출처 표기\\n\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\n\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n📚 출처\\n\\n\\nlangchain-ai 📖\\nOpenAI API Reference 🤖\\n\\n🌐 추가 자료\\n\\n\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\n블로그: 테디노트 📝\\nPlayground: LangChain LLM Playground 🎮\\n\\n🚀 시작하기\\n\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\nStart History\\n\\n\\n💡 컨트리뷰션\\n\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\n\\nAbout\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\n© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.'}, {'title': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 ...', 'url': 'https://github.com/teddylee777/langchain-kr', 'content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. GitHub Copilot Write better code with AI GitHub Copilot Enterprise-grade AI features Search code, repositories, users, issues, pull requests... LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!! 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!! 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다. langchain-ai 📖 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. tutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python', 'score': 0.4948006, 'raw_content': 'GitHub - teddylee777/langchain-kr: LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nSkip to content \\nNavigation Menu\\nToggle navigation\\n\\nSign in\\n\\n\\nProduct\\n\\nGitHub Copilot Write better code with AI\\nSecurity Find and fix vulnerabilities\\nActions Automate any workflow\\nCodespaces Instant dev environments\\nIssues Plan and track work\\nCode Review Manage code changes\\nDiscussions Collaborate outside of code\\nCode Search Find more, search less\\n\\nExplore\\n\\nAll features\\nDocumentation\\nGitHub Skills\\nBlog\\n\\n\\n\\nSolutions\\nBy company size\\n\\nEnterprises\\nSmall and medium teams\\nStartups\\nNonprofits\\n\\nBy use case\\n\\nDevSecOps\\nDevOps\\nCI/CD\\nView all use cases\\n\\nBy industry\\n\\nHealthcare\\nFinancial services\\nManufacturing\\nGovernment\\nView all industries\\n\\nView all solutions\\n\\n\\nResources\\nTopics\\n\\nAI\\nDevOps\\nSecurity\\nSoftware Development\\nView all\\n\\nExplore\\n\\nLearning Pathways\\nWhite papers, Ebooks, Webinars\\nCustomer Stories\\nPartners\\nExecutive Insights\\n\\n\\n\\nOpen Source\\n\\n\\nGitHub Sponsors Fund open source developers\\n\\n\\nThe ReadME Project GitHub community articles\\n\\n\\nRepositories\\n\\nTopics\\nTrending\\nCollections\\n\\n\\n\\nEnterprise\\n\\nEnterprise platform AI-powered developer platform\\n\\nAvailable add-ons\\n\\nAdvanced Security Enterprise-grade security features\\nGitHub Copilot Enterprise-grade AI features\\nPremium Support Enterprise-grade 24/7 support\\n\\n\\n\\nPricing\\n\\n\\nSearch or jump to...\\nSearch code, repositories, users, issues, pull requests...\\nSearch\\nClear\\nSearch syntax tips\\nProvide feedback\\nWe read every piece of feedback, and take your input very seriously.\\nInclude my email address so I can be contacted\\nCancel Submit feedback\\nSaved searches\\nUse saved searches to filter your results more quickly\\nName  \\nQuery \\nTo see all available qualifiers, see our documentation.\\nCancel Create saved search\\nSign in\\nSign up Reseting focus\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n{{ message }}\\nteddylee777 / langchain-kr Public\\n\\nNotifications You must be signed in to change notification settings\\nFork 407\\nStar 1.4k\\n\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nLicense\\nApache-2.0 license\\n1.4k stars 407 forks Branches Tags Activity\\nStar\\nNotifications You must be signed in to change notification settings\\n\\nCode\\nIssues 2\\nPull requests 0\\nActions\\nProjects 0\\nSecurity\\nInsights\\n\\nAdditional navigation options\\n\\nCode\\nIssues\\nPull requests\\nActions\\nProjects\\nSecurity\\nInsights\\n\\nteddylee777/langchain-kr\\nmain\\nBranchesTags\\n\\nGo to file\\nCode\\nFolders and files\\n| Name | Name | \\nLast commit message\\n| \\nLast commit date\\n|\\n| --- | --- | --- | --- |\\n| \\nLatest commit\\nHistory\\n391 Commits\\n\\n|\\n| \\n01-Basic\\n| \\n01-Basic\\n| \\n| \\n|\\n| \\n02-Prompt\\n| \\n02-Prompt\\n| \\n| \\n|\\n| \\n03-OutputParser\\n| \\n03-OutputParser\\n| \\n| \\n|\\n| \\n04-Model\\n| \\n04-Model\\n| \\n| \\n|\\n| \\n05-Memory\\n| \\n05-Memory\\n| \\n| \\n|\\n| \\n06-DocumentLoader\\n| \\n06-DocumentLoader\\n| \\n| \\n|\\n| \\n07-TextSplitter\\n| \\n07-TextSplitter\\n| \\n| \\n|\\n| \\n08-Embeddings\\n| \\n08-Embeddings\\n| \\n| \\n|\\n| \\n09-VectorStore\\n| \\n09-VectorStore\\n| \\n| \\n|\\n| \\n10-Retriever\\n| \\n10-Retriever\\n| \\n| \\n|\\n| \\n11-Reranker\\n| \\n11-Reranker\\n| \\n| \\n|\\n| \\n12-RAG\\n| \\n12-RAG\\n| \\n| \\n|\\n| \\n13-LangChain-Expression-Language\\n| \\n13-LangChain-Expression-Language\\n| \\n| \\n|\\n| \\n14-Chains\\n| \\n14-Chains\\n| \\n| \\n|\\n| \\n15-Agent\\n| \\n15-Agent\\n| \\n| \\n|\\n| \\n16-Evaluations\\n| \\n16-Evaluations\\n| \\n| \\n|\\n| \\n17-LangGraph\\n| \\n17-LangGraph\\n| \\n| \\n|\\n| \\n18-FineTuning\\n| \\n18-FineTuning\\n| \\n| \\n|\\n| \\n19-Streamlit\\n| \\n19-Streamlit\\n| \\n| \\n|\\n| \\n20-Projects/01-ParsingOutput\\n| \\n20-Projects/01-ParsingOutput\\n| \\n| \\n|\\n| \\n22-OpenAI\\n| \\n22-OpenAI\\n| \\n| \\n|\\n| \\n99-Projects\\n| \\n99-Projects\\n| \\n| \\n|\\n| \\nimages\\n| \\nimages\\n| \\n| \\n|\\n| \\n.env_sample\\n| \\n.env_sample\\n| \\n| \\n|\\n| \\n.gitignore\\n| \\n.gitignore\\n| \\n| \\n|\\n| \\nLICENSE\\n| \\nLICENSE\\n| \\n| \\n|\\n| \\nREADME.md\\n| \\nREADME.md\\n| \\n| \\n|\\n| \\npoetry.lock\\n| \\npoetry.lock\\n| \\n| \\n|\\n| \\npyproject.toml\\n| \\npyproject.toml\\n| \\n| \\n|\\n| \\nrequirements-mini.txt\\n| \\nrequirements-mini.txt\\n| \\n| \\n|\\n| \\nrequirements-onnx.txt\\n| \\nrequirements-onnx.txt\\n| \\n| \\n|\\n| \\nrequirements.txt\\n| \\nrequirements.txt\\n| \\n| \\n|\\n| \\nView all files\\n|\\nRepository files navigation\\n\\nREADME\\nApache-2.0 license\\n\\n📘 LangChain 한국어 튜토리얼\\n\\n\\n🌟 LangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다.\\n본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\n📔 위키독스 전자책(무료)\\n\\n\\n위키독스에 무료 전자책을 등록하였습니다✌️\\n위키독스 페이지에서 책 \"추천\" 버튼 한 번씩만 눌러 주시면 제작에 큰 힘이 됩니다. 미리 감사 드립니다🫶\\n틈나는대로 열심히 업데이트 하고 있습니다. 앞으로도 신규 기능이 추가 될 때마다 빠르게 x100 업데이트 예정입니다.\\n\\n랭체인LangChain 노트 by 테디노트 구경하러 가기\\n\\n🍿 유튜브\\n\\n\\n🤗 huggingface 에 공개된 오픈모델을 💻 로컬PC 에서 빠르게 실행🔥 해보고 테스트 하는 방법 + 모델 서빙🚀 + 업무자동화🤖 에 적용하는 방법까지!\\n👀 코드 기반 답변하는 💻 GitHub 소스코드 기반 Q&A 챗봇🤖 제작기\\nllama3 출시🔥 로컬에서 Llama3-8B 모델 돌려보기👀\\n🔥성능이 놀라워요🔥 무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(#LangServe) + #RAG 까지!!\\n무료로 한국어🇰🇷 파인튜닝 모델 받아서 나만의 로컬 LLM 호스팅 하기(LangServe) + RAG 까지!!\\nStreamlit 으로 ChatGPT 클론 서비스 제작하는 방법\\n대화내용을 기록하는 LLM Chain 생성 방법 + 도큐먼트 참조하는 tip!\\n(Self Learning GPT) LangSmith 피드백으로 원하는 형식의 답변을 학습하는 GPT\\n(LangServe 리뷰) 초간편 LLM 웹앱 제작 & 배포기능까지! 과연, Streamlit 대체할 수 있을까?\\nAI vs AI 의대 증원에 대한 모의 찬반토론 (AI 더빙본)\\n토론 AI 에이전트 - 의대 입학정원 증원에 대한 찬반토론을 AI 끼리 한다면?\\n긴 문서(long context) 에 대한 참신한 RAG 방법론: RAPTOR! 논문 리뷰와 코드를 준비했습니다\\nLangChain 밋업 발표 / R.A.G. 우리가 절대 쉽게결과물을 얻을 수 없는 이유\\n노코딩으로 쇼핑몰 리뷰 분석 (크롤링 + Q&A 챗봇)\\nChatGPT 의 GPTS 에 API 호출기능을 붙이면 어떻게 될까?\\nLangChain Agent 를 활용하여 ChatGPT를 업무자동화 에 적용하는 방법🔥🔥\\nPrivate GPT! 나만의 ChatGPT 만들기 (HuggingFace Open LLM 활용)\\nLangGraph 의 멀티 에이전트 콜라보레이션 찍먹하기\\n마법같은 문법 LangChain Expression Language(LCEL)\\n이미지를 matplotlib 파이썬 코드로, 원하는 문장을 입력하면 파이썬 코드로 변환하는 방법\\nRAG 파이프라인 이해해보기 - 네이버 뉴스기사 기반 Q&A 챗봇 제작\\nOpenAI 의 새로운 기능 Assistant API 완벽히 이해해보기\\nOpenAI 의 새로운 기능 Assistant API 3가지 도구 활용법\\n\\n✏️ 블로그 글 목록\\n\\nGeneral\\n\\n\\nOpenAI API 모델 리스트 / 요금표\\n\\nOpenAI Python API\\n\\n\\nOpenAI Python API 키 발급방법, 요금체계\\n채팅(chat) 함수 사용하기(1)\\nDALL·E를 사용하여 이미지 생성, 수정, 다양화하기(2)\\nWhisper API를 사용하여 TTS, STT 구현하기(3)\\n\\nLangChain\\n\\n\\nOpenAI GPT 모델(ChatOpenAI) 사용법\\n허깅페이스(HuggingFace) 모델 사용법\\n챗(chat) - ConversationChain, 템플릿 사용법\\n정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n웹사이트 크롤링 - 웹사이트 문서 요약\\n웹사이트 정보 추출 - 스키마 활용법\\nPDF 문서요약, Map-Reduce\\nPDF 기반 질의응답(Question-Answering)\\n문장을 파이썬 코드로, 이미지를 파이썬 코드로 변경하는 방법\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\nRAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n\\nLangGraph\\n\\n\\nMulti-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n👥 LangChain 밋업 2024 Q1 발표자료\\n\\n\\nRAG - 우리가 절대 쉽게 원하는 결과물을 얻을 수 없는 이유 - 테디노트\\n프름프트 흐름과 LLM 모델 평가 - 이재석님\\n인공지능을 통한 게임 제작 파이프라인의 변화 - 김한얼님\\nOpenAI SORA 살짝 맛보기 - 박정현님\\nSemantic Kernel로 만드는 AI Copilot - 이종인님\\nStreamlit 과 langchain으로 나만의 웹서비스 개발하기 - 최재혁님\\nLlama2-koen을 만들기까지 - 최태균님\\n올바른 한국어 언어 모델 평가를 위해: HAE-RAE Bench, KMMLU - 손규진님\\n랭체인 네이버 기사 크롤링 - 우성우님\\nGemma와 LangChain을 이용한 SQL 체인만들기 - 김태영님\\n\\n📜 라이선스\\n\\n본 프로젝트는 Apache License 2.0에 따라 라이선스가 부여됩니다.\\n🚫 라이선스 고지\\n\\n🔒 본 내용의 저작권은 2024년 테디노트에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com 으로 문의할 수 있습니다.\\n```\\nCopyright 2024 테디노트(teddylee777@gmail.com)\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\nhttp://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n```\\n인용 및 출처 표기\\n\\n본 저작물의 내용을 블로그, 유튜브 등 온라인 매체에 인용하여 게재하는 경우, 저작권법에 따라 반드시 출처를 명시 해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다.\\n\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다. 본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n📚 출처\\n\\n\\nlangchain-ai 📖\\nOpenAI API Reference 🤖\\n\\n🌐 추가 자료\\n\\n\\n유튜브 채널: LangChain 한국어 튜토리얼 🎥\\n블로그: 테디노트 📝\\nPlayground: LangChain LLM Playground 🎮\\n\\n🚀 시작하기\\n\\n본 튜토리얼을 시작하기 전에, LangChain과 관련된 기본적인 지식을 갖추는 것이 좋습니다. 위의 출처 링크를 통해 기본적인 정보를 얻을 수 있습니다.\\nStart History\\n\\n\\n💡 컨트리뷰션\\n\\n본 튜토리얼에 기여하고자 하는 분들은 언제든지 풀 리퀘스트를 보내주시거나, 이슈를 등록하여 의견을 공유해 주시기 바랍니다. 모든 기여는 본 프로젝트의 발전에 큰 도움이 됩니다. 💖\\n\\nAbout\\nLangChain 공식 Document, Cookbook, 그 밖의 실용 예제를 바탕으로 작성한 한국어 튜토리얼입니다. 본 튜토리얼을 통해 LangChain을 더 쉽고 효과적으로 사용하는 방법을 배울 수 있습니다.\\nwikidocs.net/book/14314\\nTopics\\ntutorial cookbook openai huggingface gpt-3 openai-api gpt-4 generative-ai chatgpt langchain chatgpt-api langchain-python\\nResources\\nReadme\\nLicense\\nApache-2.0 license\\nActivity\\nStars\\n1.4k stars\\nWatchers\\n37 watching\\nForks\\n407 forks\\nReport repository\\nReleases\\nNo releases published\\nPackages 0\\nNo packages published  \\nContributors 5\\nLanguages\\n\\nJupyter Notebook 97.8%\\nPython 2.0%\\nHTML 0.2%\\n\\nFooter\\n© 2025 GitHub,\\xa0Inc.\\nFooter navigation\\n\\nTerms\\nPrivacy\\nSecurity\\nStatus\\nDocs\\nContact\\nManage cookies\\nDo not share my personal information\\n\\nYou can’t perform that action at this time.'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 검색 도구 생성\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록에 추가\n",
    "tools = [tool]\n",
    "\n",
    "# 도구 실행\n",
    "# print(tool.invoke(\"테디노트 랭체인 튜토리얼\"))\n",
    "print(tool.invoke(\"kt 5G 요금제 크루즈 로밍에 대해 알려주세요.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b6ca3",
   "metadata": {},
   "source": [
    "결과는 챗봇이 질문에 답할 수 있도록 사용할 수 있는 페이지 요약입니다.\n",
    "\n",
    "이번에는 LLM에 `bind_tools`를 추가하여 **LLM + 도구** 를 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6166da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의\n",
    "class State(TypedDict):\n",
    "    # list 타입에 add_messages 적용(list 에 message 추가)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9e3c7",
   "metadata": {},
   "source": [
    "LLM 을 정의하고 도구를 바인딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c65ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# LLM 에 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c2841",
   "metadata": {},
   "source": [
    "노드를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028d36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 함수 정의\n",
    "def chatbot(state: State):\n",
    "    answer = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 메시지 목록 반환\n",
    "    return {\"messages\": [answer]}  # 자동으로 add_messages 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c798e0",
   "metadata": {},
   "source": [
    "그래프 생성 및 노드를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8d16a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11c257050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034ee74",
   "metadata": {},
   "source": [
    "## 도구 노드(Tool Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b08e3f",
   "metadata": {},
   "source": [
    "다음으로, 도구가 호출될 경우 실제로 실행할 수 있는 함수를 만들어야 합니다. 이를 위해 새로운 노드에 도구를 추가합니다.\n",
    "\n",
    "가장 최근의 메시지를 확인하고 메시지에 `tool_calls`가 포함되어 있으면 도구를 호출하는 `BasicToolNode`를 구현합니다. \n",
    "\n",
    "지금은 직접 구현하지만, 나중에는 LangGraph의 pre-built 되어있는 [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode) 로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1437765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Run tools requested in the last AIMessage node\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # 도구 리스트\n",
    "        self.tools_list = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # 메시지가 존재할 경우 가장 최근 메시지 1개 추출\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # 도구 호출 결과\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 도구 호출 후 결과 저장\n",
    "            print(\"========\" + \"tool_call : begin\" + \"=========\")\n",
    "            print(tool_call)\n",
    "            print(\"========\" + \"tool_call : end \" + \"=========\")\n",
    "            tool_result = self.tools_list[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            outputs.append(\n",
    "                # 도구 호출 결과를 메시지로 저장\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(\n",
    "                        tool_result, ensure_ascii=False\n",
    "                    ),  # 도구 호출 결과를 문자열로 변환\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# 도구 노드 생성\n",
    "# tool_node = BasicToolNode(tools=[tool])\n",
    "tool_node1 = BasicToolNode(tools=[tool])\n",
    "\n",
    "# # 그래프에 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ecda",
   "metadata": {},
   "source": [
    "## 조건부 엣지(Conditional Edge)\n",
    "\n",
    "도구 노드가 추가되면 `conditional_edges`를 정의할 수 있습니다.\n",
    "\n",
    "**Edges**는 한 노드에서 다음 노드로 제어 흐름을 라우팅합니다. \n",
    "\n",
    "**Conditional edges**는 일반적으로 \"if\" 문을 포함하여 현재 그래프 상태에 따라 다른 노드로 라우팅합니다. 이러한 함수는 현재 그래프 `state`를 받아 다음에 호출할 Node 를 나타내는 **문자열 또는 문자열 목록** 을 반환합니다.\n",
    "\n",
    "아래에서는 `route_tools`라는 라우터 함수를 정의하여 챗봇의 출력에서 `tool_calls`를 확인합니다. \n",
    "\n",
    "이 함수를 `add_conditional_edges`를 호출하여 그래프에 제공하면, `chatbot` 노드가 완료될 때마다 이 함수를 확인하여 다음으로 어디로 갈지 결정합니다.\n",
    "\n",
    "조건은 도구 호출이 있으면 `tools`로, 없으면 `END`로 라우팅됩니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- langgraph 에 pre-built 되어 있는 [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) 으로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758bf4f",
   "metadata": {},
   "source": [
    "### `add_conditional_edges`\n",
    "\n",
    "![add_conditional_edges](./image/langgraph-02.png)\n",
    "\n",
    "`add_conditional_edges` 메서드는 시작 노드에서 여러 대상 노드로의 조건부 엣지를 추가합니다.\n",
    "\n",
    "**매개변수**\n",
    "- `source` (str): 시작 노드. 이 노드를 나갈 때 조건부 엣지가 실행됩니다.\n",
    "- `path` (Union[Callable, Runnable]): 다음 노드를 결정하는 호출 가능한 객체 또는 Runnable. `path_map`을 지정하지 않으면 하나 이상의 노드를 반환해야 합니다. `END`를 반환하면 그래프 실행이 중지됩니다.\n",
    "- `path_map` (Optional[Union[dict[Hashable, str], list[str]]]): 경로와 노드 이름 간의 매핑. 생략하면 `path`가 반환하는 값이 노드 이름이어야 합니다.\n",
    "- `then` (Optional[str]): `path`로 선택된 노드 실행 후 실행할 노드의 이름.\n",
    "\n",
    "**반환값**\n",
    "- Self: 메서드 체이닝을 위해 자기 자신을 반환합니다.\n",
    "\n",
    "**주요 기능**\n",
    "1. 조건부 엣지를 그래프에 추가합니다.\n",
    "2. `path_map`을 딕셔너리로 변환합니다.\n",
    "3. `path` 함수의 반환 타입을 분석하여 자동으로 `path_map`을 생성할 수 있습니다.\n",
    "4. 조건부 분기를 그래프에 저장합니다.\n",
    "\n",
    "**참고**\n",
    "- 이미 컴파일된 그래프에 엣지를 추가하면 경고 메시지가 출력됩니다.\n",
    "- `path` 함수의 반환 값에 대한 타입 힌트가 없거나 `path_map`이 제공되지 않으면, 그래프 시각화 시 해당 엣지가 그래프의 모든 노드로 전환될 수 있다고 가정합니다.\n",
    "- 동일한 이름의 분기가 이미 존재하는 경우 `ValueError`가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a964c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        # 가장 최근 AI 메시지 추출\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        # 입력 상태에 메시지가 없는 경우 예외 발생\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # AI 메시지에 도구 호출이 있는 경우 \"tools\" 반환\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # 도구 호출이 있는 경우 \"tools\" 반환\n",
    "        return \"tools\"\n",
    "    # 도구 호출이 없는 경우 \"END\" 반환\n",
    "    return END\n",
    "\n",
    "\n",
    "# `tools_condition` 함수는 챗봇이 도구 사용을 요청하면 \"tools\"를 반환하고, 직접 응답이 가능한 경우 \"END\"를 반환\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    # route_tools 의 반환값이 \"tools\" 인 경우 \"tools\" 노드로, 그렇지 않으면 END 노드로 라우팅\n",
    "    path_map={\"tools\": \"tools\", END: END},\n",
    ")\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab199c",
   "metadata": {},
   "source": [
    "**조건부 엣지**가 단일 노드에서 시작해야 합니다.\n",
    "\n",
    "이는 그래프에 \"`chatbot`\" 노드가 실행될 때마다 도구를 호출하면 'tools'로 이동하고, 직접 응답하면 루프를 종료하라는 의미입니다. \n",
    "\n",
    "사전 구축된 `tools_condition`처럼, 함수는 도구 호출이 없을 경우 `END` 문자열을 반환(그래프 종료) 합니다. 그래프가 `END`로 전환되면 더 이상 완료할 작업이 없으며 실행을 중지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d4d1118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb06f338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736b473",
   "metadata": {},
   "source": [
    "이제 봇에게 훈련 데이터 외의 질문을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31343b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='kt 5G 요금제 크루즈 로밍에 대해 알려주세요.' additional_kwargs={} response_metadata={} id='a79ded86-3c49-4b31-a5db-33d5fd2dacff'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_CHHiPk3son78rfuOa5NSQ2zc', 'function': {'arguments': '{\"query\":\"kt 5G 요금제 크루즈 로밍\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 108, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-025bb5ab-471c-427b-9b62-5000837e99c1-0' tool_calls=[{'name': 'tavily_web_search', 'args': {'query': 'kt 5G 요금제 크루즈 로밍'}, 'id': 'call_CHHiPk3son78rfuOa5NSQ2zc', 'type': 'tool_call'}] usage_metadata={'input_tokens': 108, 'output_tokens': 29, 'total_tokens': 137, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "========tool_call : begin=========\n",
      "{'name': 'tavily_web_search', 'args': {'query': 'kt 5G 요금제 크루즈 로밍'}, 'id': 'call_CHHiPk3son78rfuOa5NSQ2zc', 'type': 'tool_call'}\n",
      "========tool_call : end =========\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='[{\"title\": \"Kt 로밍 요금 진짜 합리적일까? Kt 데이터 로밍 완전 분석! : 네이버 블로그\", \"url\": \"https://m.blog.naver.com/ummmooh/223758907972\", \"content\": \"kt는 여행 목적이나 데이터 사용량에 따라 다양한 로밍 요금제를 제공합니다. 이를 잘 활용하면 해외에서도 부담 없이 데이터를 이용할 수 있습니다. 하루종일 로밍 요금제 (일 단위 요금제)-베이직: 11,000원/일 (400mb, 이후 저속)-플러스: 13,000원/일 (800mb, 이후 저속)\", \"score\": 0.7077487, \"raw_content\": \"블로그\\\\n\\\\n카테고리 이동\\\\n\\\\n\\\\n\\\\n\\\\n모아이부부의 하이테크 홈\\\\n\\\\nKT 로밍 요금 진짜 합리적일까? KT 데이터 로밍 완전 분석!\\\\n\\\\n2025. 2. 13. 9:29\\\\n\\\\n해외여행이나 출장 중 스마트폰 데이터를 사용하려면 가장 먼저 고려해야 할 것이 로밍 요금제입니다. 무심코 데이터를 사용했다가 예상치 못한 요금 폭탄을 맞는 경우도 많습니다. 저도 해외 출장을 갈 때마다 로밍 요금제 선택이 고민이었는데요. 데이터 사용량이 많다면 요금제가 적절하지 않을 경우 금액 부담이 상당할 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n오늘은 KT의 로밍 요금제 종류와 데이터 사용 패턴에 따라 어떤 요금제가 합리적인지 꼼꼼히 분석해보겠습니다. 각 요금제별 특징을 살펴보고, 비용 대비 효율성을 비교하여 최적의 선택 방법까지 알려드리겠습니다.\\\\n\\\\n\\u200b\\\\n\\\\n목차\\\\n\\\\n1. KT 로밍 요금제 종류 및 특징\\\\n\\\\n2. 데이터 로밍, 정말 경제적인가?\\\\n\\\\n3. 로밍 요금제 선택 가이드\\\\n\\\\n4. 로밍 요금 아끼는 팁\\\\n\\\\n5. 마무리\\\\n\\\\n\\u200b\\\\n\\\\n1. KT 로밍 요금제 종류 및 특징\\\\n\\\\nKT는 여행 목적이나 데이터 사용량에 따라 다양한 로밍 요금제를 제공합니다. 이를 잘 활용하면 해외에서도 부담 없이 데이터를 이용할 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n✅ 하루종일 로밍 요금제 (일 단위 요금제)\\\\n\\\\n-베이직: 11,000원/일 (400MB, 이후 저속)\\\\n\\\\n-플러스: 13,000원/일 (800MB, 이후 저속)\\\\n\\\\n-프리미엄: 15,000원/일 (5GB, 이후 저속)\\\\n\\\\n\\u200b\\\\n\\\\n📌 추천 대상: 짧은 여행(1~7일) 시 적합, 일정에 맞춰 하루 단위 결제 가능\\\\n\\\\n\\u200b\\\\n\\\\n하루종일 로밍은 짧은 여행이나 출장을 떠나는 사람들에게 적합합니다. 데이터 사용량이 많지 않다면 베이직 요금제도 충분하지만, 동영상 시청이나 업무용 자료 전송이 많다면 프리미엄 요금제가 더 나을 수도 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n✅ 함께 쓰는 로밍 (장기 여행자용 데이터 공유 요금제)\\\\n\\\\n-아시아/미주 4GB: 33,000원 (15일 사용)\\\\n\\\\n-아시아/미주 8GB: 44,000원 (30일 사용)\\\\n\\\\n-글로벌 3GB: 33,000원 (15일 사용)\\\\n\\\\n-글로벌 6GB: 44,000원 (30일 사용)\\\\n\\\\n\\u200b\\\\n\\\\n📌 추천 대상: 장기 출장 & 가족 여행 시 유용, 데이터 공유 가능\\\\n\\\\n\\u200b\\\\n\\\\n이 요금제는 최대 5명이 데이터를 공유할 수 있어 가족 여행이나 출장 팀이 함께 사용하기에 좋습니다. 하지만 데이터를 많이 사용하는 사람과 적게 사용하는 사람이 함께 쓸 경우, 일부 사용자에게 불리할 수도 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n✅ 하루종일 로밍 톡 (메신저 전용 요금제)\\\\n\\\\n-요금: 3,300원/일\\\\n\\\\n-속도: 200Kbps (카카오톡, 라인 등 텍스트 전송 가능)\\\\n\\\\n\\u200b\\\\n\\\\n📌 추천 대상: 저렴한 비용으로 메신저 사용만 필요한 경우\\\\n\\\\n\\u200b\\\\n\\\\n저는 개인적으로 하루종일 로밍 톡을 추천하지 않습니다. 200Kbps 속도는 메신저 사용에는 문제가 없지만, 사진 전송이나 간단한 웹 검색도 어려운 속도이기 때문입니다.\\\\n\\\\n\\u200b\\\\n\\\\n✅ 데이터로밍 12시간 요금제\\\\n\\\\n-요금: 6,600원/12시간\\\\n\\\\n-데이터: 100MB (이후 저속)\\\\n\\\\n\\u200b\\\\n\\\\n📌 추천 대상: 공항에서 잠깐 쓰거나, 데이터 사용이 많지 않은 경우\\\\n\\\\n\\u200b\\\\n\\\\n이 요금제는 공항에서 잠깐 사용할 용도로는 괜찮지만, 100MB는 상당히 빠르게 소진될 수 있습니다. 짧은 시간 내에 데이터를 많이 사용할 계획이라면 하루종일 로밍 요금제가 더 나을 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n2. 데이터 로밍, 정말 경제적인가?\\\\n\\\\nKT 로밍 요금제는 편리하지만, 현지 유심(USIM)이나 eSIM(디지털 유심)과 비교하면 비용이 높은 편입니다.\\\\n\\\\n\\u200b\\\\n\\\\n-현지 유심 구매: 보통 10~30달러 수준으로 10GB 이상 제공\\\\n\\\\n-eSIM 사용: QR코드로 간편하게 개통 가능, 가격이 현지 유심과 비슷함\\\\n\\\\n\\u200b\\\\n\\\\n개인적으로 해외 체류 기간이 5일 이상이라면 현지 유심을 사용하는 것이 훨씬 경제적이라고 생각합니다. 하지만 단기 여행이나 여러 나라를 방문하는 경우라면 KT 로밍이 편리할 수도 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n3. 로밍 요금제 선택 가이드\\\\n\\\\n✔ 단기 여행 (1~7일) → 하루종일 로밍 (베이직/플러스/프리미엄)\\\\n\\\\n✔ 장기 여행 (2주 이상) → 함께 쓰는 로밍 (아시아/미주/글로벌)\\\\n\\\\n✔ 메신저만 사용 → 하루종일 로밍 톡\\\\n\\\\n✔ 공항에서 잠깐 사용 → 데이터로밍 12시간\\\\n\\\\n\\u200b\\\\n\\\\n4. 로밍 요금 아끼는 팁\\\\n\\\\n-Wi-Fi 적극 활용: 호텔, 공항, 카페 Wi-Fi 이용\\\\n\\\\n-데이터 절약 모드 활성화: 유튜브, SNS 자동 재생 차단\\\\n\\\\n-필요 없는 앱 백그라운드 데이터 차단\\\\n\\\\n\\u200b\\\\n\\\\n5. 마무리\\\\n\\\\n✔ KT 로밍 요금제는 여행 일정과 데이터 사용량에 따라 신중하게 선택해야 합니다.\\\\n\\\\n✔ 장기 체류라면 현지 유심(eSIM 포함)이 더 경제적일 수 있습니다.\\\\n\\\\n✔ 출국 전 미리 로밍 요금제를 신청하면 더욱 편리하게 이용할 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n해외에서도 데이터 걱정 없이 KT 로밍을 활용해 보세요!\\\\n\\\\n\\u200b\\\\n\\\\n#KT로밍요금 #KT데이터로밍 #KT로밍할인 #KT로밍방법 #데이터로밍 #통신사로밍 #로밍가격\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n카테고리\\\\n\\\\n\"}, {\"title\": \"Kt 5g 사용자라면, 해외 로밍하지 않아도 된다?! : 네이버 블로그\", \"url\": \"https://m.blog.naver.com/aiwositai/221579847166\", \"content\": \"슈퍼플랜 요금제 확인 사항 ... 또한, 프리미엄 요금제가 아니여도 kt 5g 사용자라면 받을 수 있는 추가 적용되는 혜택도 넉넉하니, 잘 비교해보시고 추가 서비스 가입할지 말지 고민해보세요. 저는 7월이 되기 전에 여행을 다녀와서 로밍 에그를 빌려갔었는데요\", \"score\": 0.5582553, \"raw_content\": \"블로그\\\\n\\\\n카테고리 이동\\\\n\\\\n\\\\n\\\\n\\\\n코예커플 IT\\\\n\\\\nKT 5G 사용자라면, 해외 로밍하지 않아도 된다?!\\\\n\\\\n2019. 7. 7. 17:52\\\\n\\\\n안녕하세요. 코예커플입니다. 요즘 날이 더워지고 있어, 여행 준비하시는 분들이 많을텐데요. 국내말고 해외로 멀리 떠나려고 계획하시는 분들도 많죠? 저희는 성수기가 오기 전에 다녀온 터라, 다시 여행을 떠나고 싶네요. ㅎㅎ\\\\n\\\\n\\u200b\\\\n\\\\n오늘 포스팅에서는 해외로 여행을 떠날 준비를 하시는 분들에게 도움이 될 포스팅입니다. 바로 KT 5G 사용자를 위한 로밍과 관련된 내용입니다. 그럼 조금 더 자세히 알아보도록 하겠습니다.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n해외 로밍 신청 안해도 된다고?\\\\n\\\\nKT 5G 요금제는 출시부터 다른 통신사와는 다른 파격적인 모습으로 많은 사람들의 관심을 끌었는데요. 사용하시는 분들 중에도 해외 로밍과 관련된 서비스가 포함되어 있다는 것을 모르는 경우가 있더라고요. 별도로 가입하거나 할인해주는 것이 아니라 포함된 서비스이기 때문에 그대로 이용하시면 됩니다. ㅎㅎ 짱!\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n요금제는 슈퍼플랜(프리미엄, 스페셜, 베이직)과 슬림으로 나뉘어 있습니다. 요금제에 따라서 데이터로밍 속도 제한이 다르긴 한데, 슈퍼플랜 사용자는 데이터를 무제한으로 이용할 수 있다는 점이 눈에 띄네요.\\\\n\\\\n\\u200b\\\\n\\\\n슈퍼플랜 관련 유의사항\\\\n\\\\n\\u200b\\\\n\\\\n저의 경우에는 슬림 요금제를 사용하고 있어, 기존에 받을 수 있는 혜택이 없는 상황이었는데요. kt에서 여름 휴가시즌을 맞이하여 7월부터 아주 넉넉한 12월 31일까지 다양한 프로모션을 통해 데이터 로밍 혜택을 쏩니다.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n | 기존 | 추가 적용\\\\n슈퍼플랜 프리미엄 | 데이터로밍 최대3Mbps 무제한 무료\\\\n슈퍼플랜 스페셜/베이직 | 데이터로밍 최대100kbps 무제한 무료 | 데이터 로밍 1Mbps 무제한 무료*7/1~12/31\\\\n슬림 | - | 데이터 로밍 하루종일 톡 무료 이용*별도 가입 시 청구 할인*7/1~12/31\\\\n매월 30분 통화 무료 (미/일/중)*7/1~8/31\\\\n기존\\\\n\\\\n추가 적용\\\\n\\\\n슈퍼플랜 프리미엄\\\\n\\\\n데이터로밍 최대3Mbps 무제한 무료\\\\n\\\\n슈퍼플랜 스페셜/베이직\\\\n\\\\n데이터로밍 최대100kbps 무제한 무료\\\\n\\\\n데이터 로밍 1Mbps 무제한 무료\\\\n\\\\n*7/1~12/31\\\\n\\\\n슬림\\\\n\\\\n-\\\\n\\\\n데이터 로밍 하루종일 톡 무료 이용\\\\n\\\\n*별도 가입 시 청구 할인\\\\n\\\\n*7/1~12/31\\\\n\\\\n매월 30분 통화 무료 (미/일/중)\\\\n\\\\n*7/1~8/31\\\\n\\\\n표로 정리하면 위 내용과 같습니다. 저의 경우에는 슬림 요금제를 쓰고 있어서, 받을 수 있는 부분이 없겠구나 하고 조금 아쉬웠는데요. 올해 안으로 업그레이드된 혜택을 받을 수 있겠더라고요.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n슈퍼플랜 스페셜 또는 베이직을 사용하시는 분들이라면, 기간 동안은 로밍 최대 속도가 업그레이드되어 자동 적용되는데요. 기존에는 카톡 정도만 보낼 수 있는 수준이었다면, 이제는 코예커플 블로그 웹서핑도 가능한 수준이 된 거예요. 별도 신청없이 185 개의 국가에서 사용할 수 있으니 정말 편하게 쓸 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n슬림 요금제의 경우에는 하루종일 톡 무료를 별도로 가입하면, 톡이 가능한 수준으로 데이터 로밍을 활용할 수 있고요. 미국, 일본, 중국에 여행을 떠나는 경우에는 매월 30분의 통화 비용이 자동으로 청구할인 된다는 점도 놓치지 말고 이용하세요! 참고로 통화 무료 서비스는 8월 31일까지만 이용할 수 있습니다.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n물론 데이터 사용량이 많은 분들이라면, 별도의 서비스를 가입하는 것도 좋겠습니다. 하지만, 5G를 쓰는 분들 중에서 프리미엄 요금제를 쓰시는 분들은 유튜브 재생도 가능한 최대 속도를 무제한으로, 그것도 무료로 이용할 수 있습니다. 그러므로 별도의 금액을 내는 것은 아까울 수 있을 것같아요!! 잘 계산해보세요. ㅎㅎ\\\\n\\\\n\\u200b\\\\n\\\\n슈퍼플랜 요금제 확인 사항\\\\n\\\\n\\u200b\\\\n\\\\n* 스마트기기/테더링 데이터는 별도 제공하며 (프리미엄 100GB, 스페셜 50GB, 베이직 20GB) 소진 후\\\\n\\\\n최대 200kbps 속도로 이용 가능합니다.\\\\n\\\\n*  데이터 로밍 무제한은 프리미엄 최대 3Mbps, 스페셜/베이직 최대 100kbps 속도로 이용 가능합니다.\\\\n\\\\n또한, 프리미엄 요금제가 아니여도 KT 5G 사용자라면 받을 수 있는 추가 적용되는 혜택도 넉넉하니, 잘 비교해보시고 추가 서비스 가입할지 말지 고민해보세요. 저는 7월이 되기 전에 여행을 다녀와서 로밍 에그를 빌려갔었는데요!  개인적으로 너무 만족하며 사용했거든요. 도움될 분들이 있을 거란 생각이 들어, 포스팅 URL도 첨부하였습니다.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n안녕하세요. 코예커플입니다. 여행 다녀온 지가 꽤 되었는데, 아직도 여독이 있는 걸 보면 저희 부부는 집...\\\\n\\\\nblog.naver.com\\\\n\\\\n\\u200b\\\\n\\\\n슈퍼플랜으로 해외 로밍이 무료로 적용되는 국가는 185개이고, 슬림의 경우에는 하루종일 톡 지원국가와 동일한 180개 국이에요. 일일이적어드릴 수 없을 정도로 대부분의 국가에 적용된다라고 표현할 수 있겠어요. ^^;  아시아, 미주, 남미, 유럽, 중동, 아프리카, 오세아니아 대륙에서 쓸 수 있어요.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n적용 국가 등 궁금한 내용은 kt 홈페이지에서 확인할 수 있습니다. 사용할 수 있는 국가정보는 물론이고, 해외 도착시 로밍 서비스를 어떻게 이용할 수 있는지 등을 간단 명료하게 정리해두었으니, 꼭 참고하세요.\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n저는 kt쓰고, 남편은 다른 통신사를 사용 중인데요. ㅎㅎ 이런 혜택이 있다고 알려주니까 엄청 부러워하더라고요. 게다가 슈퍼플랜 요금제일 경우에는 별도 서비스 가입하는 번거로움 없이 자동으로 활용할 수 있다니 너무 편할 것같아요!!!\\\\n\\\\n\\u200b\\\\n\\\\n모바일에서 안보일까봐 이미지로도 한번 더 올려요!\\\\n\\\\nkt 5g 사용하시나요? 그렇다면 여러분들도 이번 여름 휴가 그리고 겨울 휴가까지 해외 로밍 서비스 신청하지 않으셔도  되겠어요. ㅎㅎ 모르고 지나치면 너무 아까운 혜택에 대한 정보였습니다. 즐거운 여행길 되시기 바랍니다. 끝!\\\\n\\\\n\\u200b\\\\n\\\\n\\u200b\\\\n\\\\n카테고리\\\\n\\\\n\"}, {\"title\": \"로밍 한눈에 보기 | Kt\", \"url\": \"https://globalroaming.kt.com/\", \"content\": \"[kt][로밍] 한눈에 알아보기 - 여행 국가/일정 선택에 맞춰 이용 가능한 로밍상품의 spec과 요금을 비교해드립니다. 본문 바로가기 주메뉴 바로 가기 가족/친구와 같이 해외 여행 간다면, KT 함께 쓰는 로밍\", \"score\": 0.36107516, \"raw_content\": null}]' name='tavily_web_search' id='42e4ad00-134f-4912-838f-6703eeb02893' tool_call_id='call_CHHiPk3son78rfuOa5NSQ2zc'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='KT의 5G 요금제와 관련된 크루즈 로밍 정보는 다음과 같습니다.\\n\\n1. **KT 로밍 요금제**:\\n   - KT는 다양한 로밍 요금제를 제공하여 여행 목적이나 데이터 사용량에 맞게 선택할 수 있습니다.\\n   - 예를 들어, 하루 단위 요금제는 다음과 같습니다:\\n     - **베이직**: 11,000원/일 (400MB, 이후 저속)\\n     - **플러스**: 13,000원/일 (800MB, 이후 저속)\\n     - **프리미엄**: 15,000원/일 (5GB, 이후 저속)\\n\\n2. **5G 사용자 혜택**:\\n   - KT의 5G 요금제(슈퍼플랜)를 사용하는 경우, 해외 로밍이 자동으로 포함되어 있어 별도로 신청할 필요가 없습니다.\\n   - 슈퍼플랜 프리미엄 요금제를 이용하면 데이터 로밍 속도가 최대 3Mbps로 무제한 제공되며, 스페셜/베이직 요금제는 최대 100Kbps로 무제한 사용할 수 있습니다.\\n\\n3. **로밍 국가**:\\n   - KT의 로밍 서비스는 185개 국가에서 이용 가능하며, 슬림 요금제 사용자는 하루종일 톡 서비스가 지원되는 180개 국가에서 메신저 사용이 가능합니다.\\n\\n4. **참고 링크**:\\n   - 더 자세한 내용은 [KT 로밍 한눈에 보기](https://globalroaming.kt.com/)를 방문하시면 확인할 수 있습니다.\\n\\n이 정보를 바탕으로 자신의 여행 계획에 맞춰 적절한 로밍 요금제를 선택하시면 좋겠습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 370, 'prompt_tokens': 3896, 'total_tokens': 4266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b8bc95a0ac', 'finish_reason': 'stop', 'logprobs': None} id='run-78c0cf9c-182b-476a-8784-1302030f28eb-0' usage_metadata={'input_tokens': 3896, 'output_tokens': 370, 'total_tokens': 4266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# inputs = {\"messages\": \"테디노트 YouTube 채널에 대해서 검색해 줘\"}\n",
    "inputs = {\"messages\": \"kt 5G 요금제 크루즈 로밍에 대해 알려주세요.\"}\n",
    "\n",
    "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
    "        # display_message_tree(value[\"messages\"][-1])\n",
    "        print(value[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6c5ac",
   "metadata": {},
   "source": [
    "도구 호출 후 구조에 대한 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23623eec",
   "metadata": {},
   "source": [
    "![](./image/tool-message-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff003852",
   "metadata": {},
   "source": [
    "- [이전 실행에 대한 LangSmith 추적](https://smith.langchain.com/public/4f82ddfa-a452-40f3-ab09-4eb088b812a4/r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-h6vp0ZFq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
