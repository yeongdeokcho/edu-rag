{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec680f5",
   "metadata": {},
   "source": [
    "# 중간 단계의 상태(State) 수동 업데이트\n",
    "\n",
    "LangGraph는 **중간 단계의 상태를 수동으로 업데이트** 할 수 있는 방안을 제공하고 있습니다.\n",
    "\n",
    "상태를 업데이트하면 **에이전트의 행동을 수정하여 경로를 제어** 할 수 있으며, 심지어 과거를 수정할 수도 있습니다. \n",
    "\n",
    "이 기능은 **에이전트의 실수를 수정** 하거나, **대체 경로를 탐색** 하거나, 특정 목표에 따라 **에이전트의 동작을 변경** 할 때 특히 유용합니다.\n",
    "\n",
    "- 참고: 본 튜토리얼에서 사용하는 에이전트는 이전 튜토리얼과 동일한 그래프를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9d9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b5c6228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH17-LangGraph-Modules\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH17-LangGraph-Modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d857b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "\n",
    "########## 1. 상태 정의 ##########\n",
    "# 상태 정의\n",
    "class State(TypedDict):\n",
    "    # 메시지 목록 주석 추가\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. 도구 정의 및 바인딩 ##########\n",
    "# 도구 초기화\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록 정의\n",
    "tools = [tool]\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 도구와 LLM 결합\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. 노드 추가 ##########\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    # 메시지 호출 및 반환\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# 상태 그래프 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 챗봇 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 조건부 엣지\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "########## 4. 엣지 추가 ##########\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# chatbot > END\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "########## 5. 그래프 컴파일 ##########\n",
    "# 메모리 저장소 초기화\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프 빌더 컴파일\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "########## 6. 그래프 시각화 ##########\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0b61953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 질문\n",
    "question = \"LangGraph 가 무엇인지 조사하여 알려주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# config 설정\n",
    "config = RunnableConfig(\n",
    "    configurable={\"thread_id\": \"1\"},  # 스레드 ID 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2ab8a",
   "metadata": {},
   "source": [
    "우선 채널목록을 출력하여 **interrupt_before** 와 **interrupt_after** 를 적용할 수 있는 목록을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005ec550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messages',\n",
       " '__start__',\n",
       " 'chatbot',\n",
       " 'tools',\n",
       " 'branch:__start__:__self__:chatbot',\n",
       " 'branch:__start__:__self__:tools',\n",
       " 'branch:chatbot:__self__:chatbot',\n",
       " 'branch:chatbot:__self__:tools',\n",
       " 'branch:tools:__self__:chatbot',\n",
       " 'branch:tools:__self__:tools',\n",
       " 'start:chatbot',\n",
       " 'branch:chatbot:tools_condition:tools']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 채널 목록 출력\n",
    "list(graph.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1b5314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_1pgRJffCf58kwgQCbIkw0XXp)\n",
      " Call ID: call_1pgRJffCf58kwgQCbIkw0XXp\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림 호출\n",
    "events = graph.stream(\n",
    "    input=input, config=config, interrupt_before=[\"tools\"], stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8250e",
   "metadata": {},
   "source": [
    "현재 단계는 `ToolNode` 에 의해 중단되었습니다.\n",
    "\n",
    "가장 최근 메시지를 확인하면 `ToolNode` 가 검색을 수행하기 전 `query` 를 포함하고 있음을 알 수 있습니다.\n",
    "\n",
    "여기서는 `query` 가 단순하게 `LangGraph` 라는 단어만을 포함하고 있습니다. (기존의 질문은 `\"LangGraph 가 무엇인지 조사하여 알려주세요!\"` 였습니다.)\n",
    "\n",
    "당연하게도, 웹 검색 결과가 우리가 원하는 결과와 다를 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731587a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_1pgRJffCf58kwgQCbIkw0XXp)\n",
      " Call ID: call_1pgRJffCf58kwgQCbIkw0XXp\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 가장 최근 메시지 추출\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 출력\n",
    "last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad6839",
   "metadata": {},
   "source": [
    "## 사람의 개입 (Human-in-the-loop)\n",
    "\n",
    "- `TavilySearch` 도구에서 **검색 결과** 를 수정\n",
    "\n",
    "우리는 종종 `ToolMessage` 의 결과가 마음에 들지 않는 경우가 있습니다.\n",
    "\n",
    "특히, 웹 검색하여 얻은 답변은 얼마든지 잘못된 정보가 포함될 수 있고, 이는 곧 챗봇의 답변에도 영향을 미칠 수 있습니다.\n",
    "\n",
    "만약, 사람이 중간에 개입하여 웹 검색 도구인 `Tavily Tool` 의 검색 결과인 `ToolMessage` 를 수정하여 LLM 에게 전달하고 싶다면 어떻게 해야 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e301863",
   "metadata": {},
   "source": [
    "![](./image/langgraph-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0d4cc",
   "metadata": {},
   "source": [
    "아래는 원래의 웹 검색 결과와는 조금 다른 수정한 가상의 웹 검색 결과를 만들어 보았습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8efa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "modified_search_result = \"\"\"[수정된 웹 검색 결과] \n",
    "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
    "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
    "\n",
    "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
    "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\"\"\"\n",
    "\n",
    "print(modified_search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cff2a",
   "metadata": {},
   "source": [
    "다음으로는 수정한 검색 결과를 `ToolMessage` 에 주입합니다.\n",
    "\n",
    "**중요**\n",
    "\n",
    "- 여기서 메시지를 수정하려면 수정하고자 하는 Message 와 일치하는 `tool_call_id` 를 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52368d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_1pgRJffCf58kwgQCbIkw0XXp\n"
     ]
    }
   ],
   "source": [
    "# 수정하고자 하는 `ToolMessage` 의 `tool_call_id` 추출\n",
    "tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "print(tool_call_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1acabaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "new_messages = [\n",
    "    # LLM API의 도구 호출과 일치하는 ToolMessage 필요\n",
    "    ToolMessage(\n",
    "        content=modified_search_result,\n",
    "        tool_call_id=tool_call_id,\n",
    "    ),\n",
    "    # LLM의 응답에 직접적으로 내용 추가\n",
    "    # AIMessage(content=modified_search_result),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970602d",
   "metadata": {},
   "source": [
    "### StateGraph의 `update_state` 메서드\n",
    "\n",
    "`update_state` 메서드는 주어진 값으로 그래프의 상태를 업데이트합니다. 이 메서드는 마치 `as_node`에서 값이 온 것처럼 동작합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `config` (RunnableConfig): 실행 구성\n",
    "- `values` (Optional[Union[dict[str, Any], Any]]): 업데이트할 값들\n",
    "- `as_node` (Optional[str]): 값의 출처로 간주할 노드 이름. 기본값은 None\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- RunnableConfig\n",
    "\n",
    "**주요 기능**\n",
    "\n",
    "1. 체크포인터를 통해 이전 상태를 로드하고 새로운 상태를 저장합니다.\n",
    "2. 서브그래프에 대한 상태 업데이트를 처리합니다.\n",
    "3. `as_node`가 지정되지 않은 경우, 마지막으로 상태를 업데이트한 노드를 찾습니다.\n",
    "4. 지정된 노드의 writer들을 실행하여 상태를 업데이트합니다.\n",
    "5. 업데이트된 상태를 체크포인트에 저장합니다.\n",
    "\n",
    "**주요 로직**\n",
    "\n",
    "1. 체크포인터를 확인하고, 없으면 ValueError를 발생시킵니다.\n",
    "2. 서브그래프에 대한 업데이트인 경우, 해당 서브그래프의 `update_state` 메서드를 호출합니다.\n",
    "3. 이전 체크포인트를 로드하고, 필요한 경우 `as_node`를 결정합니다.\n",
    "4. 지정된 노드의 writer들을 사용하여 상태를 업데이트합니다.\n",
    "5. 업데이트된 상태를 새로운 체크포인트로 저장합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이 메서드는 그래프의 상태를 수동으로 업데이트할 때 사용됩니다.\n",
    "- 체크포인터를 사용하여 상태의 버전 관리와 지속성을 보장합니다.\n",
    "- `as_node`를 지정하지 않으면 자동으로 결정되지만, 모호한 경우 오류가 발생할 수 있습니다.\n",
    "- 상태 업데이트 중 SharedValues에 쓰기 작업은 허용되지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15691b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(최근 1개의 메시지 출력)\n",
      "\n",
      "content='[수정된 웹 검색 결과] \\nLangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\\nLangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\\n\\n자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\\n테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.' id='ecad8d9b-cb6c-4fba-9451-3328c00ab931' tool_call_id='call_1pgRJffCf58kwgQCbIkw0XXp'\n"
     ]
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    # 업데이트할 상태 지정\n",
    "    config,\n",
    "    # 제공할 업데이트된 값. `State`의 메시지는 \"추가 전용\"으로 기존 상태에 추가됨\n",
    "    {\"messages\": new_messages},\n",
    "    as_node=\"tools\",\n",
    ")\n",
    "\n",
    "print(\"(최근 1개의 메시지 출력)\\n\")\n",
    "print(graph.get_state(config).values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b868cb",
   "metadata": {},
   "source": [
    "이제 그래프가 완성되었습니다. \n",
    "\n",
    "최종 응답 메시지를 제공했기 때문입니다! \n",
    "\n",
    "상태 업데이트는 그래프 단계를 시뮬레이션하므로, 해당하는 `traces`도 생성합니다.\n",
    "\n",
    "`messages`를 사전 정의된 `add_messages` 함수로 `Annotated` 처리했습니다. (이는 그래프에 기존 목록을 직접 덮어쓰지 않고 항상 값을 추가합니다.)\n",
    "\n",
    "동일한 논리가 여기에도 적용되어, `update_state`에 전달된 메시지가 동일한 방식으로 메시지가 추가하게 됩니다.\n",
    "\n",
    "`update_state` 함수는 마치 그래프의 노드 중 하나인 것처럼 작동합니다! 기본적으로 업데이트 작업은 마지막으로 실행된 노드를 사용하지만, 아래에서 수동으로 지정할 수 있습니다. 업데이트를 추가하고 그래프에 \"chatbot\"에서 온 것처럼 처리하도록 지시해 봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4c1fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot',)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36223336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "테디노트의 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**LangGraph**는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 복잡한 에이전트 기반 시스템을 개발하는 데 필요한 다양한 기능을 제공합니다.\n",
      "\n",
      "### 주요 기능:\n",
      "\n",
      "1. **상태 관리**: LangGraph는 대화의 맥락을 유지하며, 사용자와의 상호작용에서 지속적인 상태 관리를 가능하게 합니다.\n",
      "2. **사이클 흐름**: 복잡한 작업을 처리하기 위해 사이클 기반의 흐름을 지원하여 에이전트가 동적으로 반응할 수 있도록 합니다.\n",
      "3. **제어 가능성**: 에이전트의 행동을 세밀하게 조정할 수 있는 기능을 제공하여, 다양한 시나리오에 맞추어 사용할 수 있습니다.\n",
      "4. **클라우드 배포**: 클라우드 환경에서의 배포를 지원하여, 확장성과 내결함성을 제공합니다.\n",
      "\n",
      "이러한 기능을 통해 LangGraph는 대화형 에이전트, 복잡한 작업 자동화, 맞춤형 LLM 기반 경험을 구축하는 데 유용하게 사용됩니다.\n",
      "\n",
      "자세한 튜토리얼 및 문서는 아래 링크에서 확인하실 수 있습니다:\n",
      "- [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)\n",
      "- [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)\n"
     ]
    }
   ],
   "source": [
    "# `None`는 현재 상태에 아무것도 추가하지 않음\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62e348",
   "metadata": {},
   "source": [
    "아래는 최종 답변의 상태도 수정하고자 할 경우 사용할 수 있는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 함수가 작동할 노드 지정. 이 노드가 방금 실행된 것처럼 자동으로 처리 계속\n",
    "# graph.update_state(\n",
    "#     config,\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             AIMessage(content=\"마지막으로 최종 메시지를 추가하여 마무리 합니다.\")\n",
    "#         ]\n",
    "#     },\n",
    "#     as_node=\"chatbot\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697183db",
   "metadata": {},
   "source": [
    "그럼, 그래프를 시각화하고 전체 출력을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "458ada94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63f4cf",
   "metadata": {},
   "source": [
    "현재 상태를 이전과 같이 점검하여 체크포인트가 수동 업데이트를 반영하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d31c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 최근 세 개의 메시지 출력\n",
    "for message in snapshot.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457828d2",
   "metadata": {},
   "source": [
    "진행할 다음 노드가 있는지 확인합니다. `()` 가 비어 있는 것으로 확인할 수 있습니다. 즉, 모든 과정이 정상적으로 진행되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6ea87c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chatbot',)\n"
     ]
    }
   ],
   "source": [
    "# 다음 상태 출력\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fcbffe",
   "metadata": {},
   "source": [
    "## Interrupt 후 메시지 상태 업데이트 - 이어서 진행\n",
    "\n",
    "- `TavilySearch` 도구에서 **검색 쿼리** 를 수정\n",
    "\n",
    "이번에는 다음 노드로 진행하기 전 interrupt 를 발생시켜 중단하고, 상태(State) 를 갱신한 뒤 이어서 진행하는 방법을 살펴보겠습니다.\n",
    "\n",
    "먼저, 새로운 `thread_id` 를 생성합니다.\n",
    "\n",
    "여기서는 랜덤한 해시값을 생성하는 `generate_random_hash` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c7fe37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id: adfb12\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_yjNEMMqxr2qjHGtGe4podO6U)\n",
      " Call ID: call_yjNEMMqxr2qjHGtGe4podO6U\n",
      "  Args:\n",
      "    query: LangGraph 소개 및 자료\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import generate_random_hash\n",
    "\n",
    "thread_id = generate_random_hash()\n",
    "print(f\"thread_id: {thread_id}\")\n",
    "\n",
    "question = \"LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# 새로운 config 생성\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49b0e0",
   "metadata": {},
   "source": [
    "다음으로, 에이전트를 위한 도구 호출을 업데이트해 보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88483e9",
   "metadata": {},
   "source": [
    "먼저 `Message ID` 를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72d210f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 를 복사\n",
    "config_copy = config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bac7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID run-2cf14257-1e97-4e3f-b79f-35371975327b-0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 스냅샷 상태 가져오기\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# messages 의 마지막 메시지 가져오기\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"Message ID\", existing_message.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed080b7",
   "metadata": {},
   "source": [
    "마지막 메시지는 `tavily_web_search` 도구 호출과 관련된 메시지 입니다.\n",
    "\n",
    "주요 속성은 다음과 같습니다.\n",
    "\n",
    "- `name`: 도구의 이름\n",
    "- `args`: 검색 쿼리\n",
    "- `id`: 도구 호출 ID\n",
    "- `type`: 도구 호출 유형(tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64c27714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph 소개 및 자료'}, 'id': 'call_yjNEMMqxr2qjHGtGe4podO6U', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 도구 호출 출력\n",
    "print(existing_message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3e04e",
   "metadata": {},
   "source": [
    "위의 속성 값 중 `args` 의 `query` 를 업데이트 해 보겠습니다.\n",
    "\n",
    "기존의 `existing_message` 를 복사하여 새로운 도구인 `new_tool_call` 을 생성합니다.\n",
    "\n",
    "`copy()` 메서드를 사용하여 복사하였기 때문에 모든 속성 값이 복사됩니다.\n",
    "\n",
    "그런 다음, `query` 매개변수에 원하는 **검색 쿼리** 를 입력합니다.\n",
    "\n",
    "**중요**\n",
    "\n",
    "- `id` 는 기존 메시지의 `id` 를 그대로 사용합니다. (`id` 가 달라지면 message 리듀서가 동작하여 메시지를 갱신하지 않고, 추가하게 됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b66610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph site:teddylee777.github.io'},\n",
       " 'id': 'call_yjNEMMqxr2qjHGtGe4podO6U',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool_calls 를 복사하여 새로운 도구 호출 생성\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "\n",
    "# 쿼리 매개변수 업데이트(갱신)\n",
    "new_tool_call[\"args\"] = {\"query\": \"LangGraph site:teddylee777.github.io\"}\n",
    "new_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8891040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-2cf14257-1e97-4e3f-b79f-35371975327b-0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_yjNEMMqxr2qjHGtGe4podO6U)\n",
      " Call ID: call_yjNEMMqxr2qjHGtGe4podO6U\n",
      "  Args:\n",
      "    query: LangGraph site:teddylee777.github.io\n"
     ]
    }
   ],
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    # 중요! ID는 메시지를 상태에 추가하는 대신 교체하는 방법\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "print(new_message.id)\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18fa63",
   "metadata": {},
   "source": [
    "검색 쿼리가 갱신된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dbb6442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph site:teddylee777.github.io'}, 'id': 'call_yjNEMMqxr2qjHGtGe4podO6U', 'type': 'tool_call'}\n",
      "\n",
      "Message ID run-2cf14257-1e97-4e3f-b79f-35371975327b-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'adfb12',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f00852c-c7c1-694c-8002-12157f7a7a48'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 도구 호출 출력\n",
    "print(new_message.tool_calls[0])\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"\\nMessage ID\", new_message.id)\n",
    "\n",
    "# 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [new_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f791a61",
   "metadata": {},
   "source": [
    "업데이트된 마지막 message 의 `tool_calls` 를 확인합니다.\n",
    "\n",
    "- `args` 의 `query` 가 수정된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9dbecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph site:teddylee777.github.io'},\n",
       "  'id': 'call_yjNEMMqxr2qjHGtGe4podO6U',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 메시지의 도구 호출 가져오기\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae770e",
   "metadata": {},
   "source": [
    "기존 검색어인 **\"LangGraph\"** 대신 변경된 검색 쿼리인 **\"LangGraph site:teddylee777.github.io\"** 로 검색되는 것을 확인할 수 있습니다.\n",
    "\n",
    "기존 설정과 `None` 입력을 사용하여 그래프 이어서 스트리밍 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80be43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_yjNEMMqxr2qjHGtGe4podO6U)\n",
      " Call ID: call_yjNEMMqxr2qjHGtGe4podO6U\n",
      "  Args:\n",
      "    query: LangGraph site:teddylee777.github.io\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"테디노트\", \"url\": \"https://teddylee777.github.io/\", \"content\": \"테디노트 Skip to primary navigation Skip to content Skip to footer 테디노트 데이터와 인공지능을 좋아하는 개발자 노트 검색 카테고리 태그 연도 강의 어바웃미 토글 메뉴 Teddy 💻 Creator & Data Lover 팔로우 Pangyo, South Korea Email Website YouTube GitHub Instagram 최근 포스트 poetry 의 거의 모든것 (튜토리얼) 2024년 03월 30일 5 분 소요 Python 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다. LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리 2024년 03월 06일 10 분 소요 LangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다. [Assistants API] Code Interpreter, Retrieval, Functions 활용법 2024년 02월 13일 34 분 소요 OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다.\", \"score\": 0.52802294, \"raw_content\": \"테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nTeddy\\n💻 Creator & Data Lover\\n팔로우\\n\\nPangyo, South Korea\\nEmail\\nWebsite\\nYouTube\\nGitHub\\nInstagram\\n\\n최근 포스트\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 34 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\nLangChain으로 네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\n2024년 02월 06일 7 분 소요\\nLangChain을 활용하여 간단하게 네이버 뉴스기사를 바탕으로 Q&A 애플리케이션을 만드는 방법을 다룹니다.\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n2024년 02월 05일 9 분 소요\\n문서 관리를 위한 메타데이터 태깅은 필수적이지만 번거로울 수 있습니다. OpenAI 기반의 자동화된 메타데이터 태깅 방법을 통해 이 과정을 효율적으로 만드는 방법을 알아보도록 하겠습니다.\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n2024년 02월 04일 21 분 소요\\n이번 글은 LangChain 을 활용하여 문서를 요약하는 방법에 대하여 다룹니다. 특히, 문서 요약의 3가지 방식은 Stuff, Map-Reduce, Refine 방식에 대하여 알아보고, 각각의 방식 간의 차이점에 대하여 다룹니다.\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\n2024년 02월 03일 3 분 소요\\n이 블로그 글에서는 LangChain Expression Language(LCEL) 원리 이해와 LCEL 에 기반한 파이프라인 구축의 기본을 소개합니다.\\nOpenAI API 모델 리스트 / 요금표\\n2024년 02월 02일 2 분 소요\\n최신 버전의 업데이트 된 OpenAI Model 리스트와 API 사용요금(Pricing) 입니다.\\n\\n이전\\n1\\n2\\n3\\n…\\n24\\n\\n다음\\n\\n\\n팔로우:\\n\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"테디노트\", \"url\": \"https://teddylee777.github.io/\", \"content\": \"테디노트 Skip to primary navigation Skip to content Skip to footer 테디노트 데이터와 인공지능을 좋아하는 개발자 노트 검색 카테고리 태그 연도 강의 어바웃미 토글 메뉴 Teddy 💻 Creator & Data Lover 팔로우 Pangyo, South Korea Email Website YouTube GitHub Instagram 최근 포스트 poetry 의 거의 모든것 (튜토리얼) 2024년 03월 30일 5 분 소요 Python 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다. LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리 2024년 03월 06일 10 분 소요 LangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다. [Assistants API] Code Interpreter, Retrieval, Functions 활용법 2024년 02월 13일 34 분 소요 OpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다.\", \"score\": 0.52802294, \"raw_content\": \"테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nTeddy\\n💻 Creator & Data Lover\\n팔로우\\n\\nPangyo, South Korea\\nEmail\\nWebsite\\nYouTube\\nGitHub\\nInstagram\\n\\n최근 포스트\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 34 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\nLangChain으로 네이버 뉴스 기반 Q&A 애플리케이션 구축하기 - 기본편\\n2024년 02월 06일 7 분 소요\\nLangChain을 활용하여 간단하게 네이버 뉴스기사를 바탕으로 Q&A 애플리케이션을 만드는 방법을 다룹니다.\\n자동화된 메타데이터 태깅으로 문서의 메타데이터(metadata) 생성 및 자동 라벨링\\n2024년 02월 05일 9 분 소요\\n문서 관리를 위한 메타데이터 태깅은 필수적이지만 번거로울 수 있습니다. OpenAI 기반의 자동화된 메타데이터 태깅 방법을 통해 이 과정을 효율적으로 만드는 방법을 알아보도록 하겠습니다.\\nLLMs를 활용한 문서 요약 가이드: Stuff, Map-Reduce, Refine 방법 총정리\\n2024년 02월 04일 21 분 소요\\n이번 글은 LangChain 을 활용하여 문서를 요약하는 방법에 대하여 다룹니다. 특히, 문서 요약의 3가지 방식은 Stuff, Map-Reduce, Refine 방식에 대하여 알아보고, 각각의 방식 간의 차이점에 대하여 다룹니다.\\nLangChain Expression Language(LCEL) 원리 이해와 파이프라인 구축 가이드\\n2024년 02월 03일 3 분 소요\\n이 블로그 글에서는 LangChain Expression Language(LCEL) 원리 이해와 LCEL 에 기반한 파이프라인 구축의 기본을 소개합니다.\\nOpenAI API 모델 리스트 / 요금표\\n2024년 02월 02일 2 분 소요\\n최신 버전의 업데이트 된 OpenAI Model 리스트와 API 사용요금(Pricing) 입니다.\\n\\n이전\\n1\\n2\\n3\\n…\\n24\\n\\n다음\\n\\n\\n팔로우:\\n\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"LangGraph - Multi-Agent Collaboration(다중 협업 ... - 테디노트\", \"url\": \"https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/\", \"content\": \"failed\", \"score\": 0.29042256, \"raw_content\": \"LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n2024년 01월 29일 26 분 소요\\n목차\\n\\nReference\\n실습파일\\n요약\\n튜토리얼 영상\\n\\n\\n기본 다중 에이전트 협업\\n에이전트 생성\\nTool(도구) 정의\\n그래프 생성\\n상태 정의\\n에이전트 노드 정의하기\\nTool Node (도구 노드) 정의\\n에지 로직 정의\\n그래프 정의하기\\n\\n\\n호출\\n라이선스\\n\\nLangChain 에서 야심차게 LangGraph 를 새롭게 출시하였습니다. LangGraph 라이브러리가 출시하게 된 가장 큰 이유는 “복잡한 문제들은 단일 AI 에이전트만으로 해결하기 어렵다” 라는 문장에서 시작합니다.\\n이 글에서는 LangGraph의 다중 에이전트 협업을 통해 이러한 문제들을 효과적으로 해결하는 방법을 소개합니다. 특히, LangGraph를 활용한 새로운 접근법을 중점적으로 다룹니다.\\nReference\\n본 튜토리얼은 LangGraph 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다. 라이센스는 하단에 고지하였습니다.\\n원문 바로가기\\n\\n실습파일\\n\\n요약\\n주요내용\\n\\n🤖 다중 에이전트 협업: 각기 다른 도메인의 전문 에이전트들이 협력하여 복잡한 문제를 해결합니다.\\n🔧 도구 정의와 활용: 특정 작업에 적합한 도구들을 정의하고, 이를 에이전트가 활용하는 방법을 설명합니다.\\n📊 그래프 기반 시스템 구축: LangGraph를 사용하여 에이전트들이 서로 통신하고 협력하는 그래프를 생성합니다.\\n\\n튜토리얼 영상\\n기본 다중 에이전트 협업\\n단일 에이전트는 일반적으로 단일 도메인 내에서 소수의 도구를 사용하여 효과적으로 작동할 수 있지만, gpt-4와 같은 강력한 모델을 사용하더라도 많은 도구를 사용하는 데에는 덜 효과적일 수 있습니다.\\n복잡한 작업에 접근하는 한 가지 방법은 ‘나누고 정복하기(divide-and-conquer)’ 접근법입니다. 각 작업이나 도메인에 대해 전문화된 에이전트를 만들고 작업을 올바른 ‘전문가’에게 라우팅합니다.\\n이 노트북은 Wu 등이 작성한 논문 AutoGen: 다중 에이전트 대화를 통한 차세대 LLM 애플리케이션 가능하게 하기에서 영감을 받아 LangGraph를 사용하여 이를 수행하는 한 가지 방법을 보여줍니다.\\n결과적으로 생성된 그래프는 다음 다이어그램과 같은 모습일 것입니다.\\n\\n필요한 패키지를 설치합니다.\\n```\\nlangchain, langchain_openai, langsmith, pandas, langchain_experimental, matplotlib 패키지를 설치합니다.\\n이 코드는 패키지 설치를 위한 pip 명령어를 포함하고 있습니다.\\n```\\npython-dotenv 라이브러리를 사용하여 환경 변수에서 토큰 정보를 로드합니다.\\n이 라이브러리는 .env 파일에 저장된 환경 변수를 읽어와서 Python 프로그램에서 사용할 수 있게 해줍니다. load_dotenv 함수를 호출하여 .env 파일의 내용을 로드합니다.\\n```\\n토큰 정보를 로드하기 위한 라이브러리\\n설치 명령어: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n토큰 정보 로드\\nload_dotenv()\\n```\\nTrue\\n_set_if_undefined는 환경 변수가 설정되어 있지 않을 경우 사용자로부터 해당 환경 변수의 값을 입력받아 설정하는 역할을 합니다. 이 함수는 OPENAI_API_KEY, LANGCHAIN_API_KEY, TAVILY_API_KEY 세 개의 API 키에 대해 환경 변수가 설정되어 있는지 확인하고, 없을 경우 사용자에게 입력을 요청합니다.\\n또한, LangSmith 추적 기능을 활성화하고 프로젝트 이름을 ‘Multi-agent Collaboration’으로 설정합니다.\\n```\\nimport getpass\\nimport os\\ndef _set_if_undefined(var: str):\\n    # 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\\n    if not os.environ.get(var):\\n        os.environ[var] = getpass.getpass(f\\\"Please provide your {var}\\\")\\nOPENAI_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"OPENAI_API_KEY\\\")\\nLANGCHAIN_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"LANGCHAIN_API_KEY\\\")\\nTAVILY_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"TAVILY_API_KEY\\\")\\nLangSmith 추적 기능을 활성화합니다. (선택적)\\nos.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\nos.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Multi-agent Collaboration\\\"\\n```\\n에이전트 생성\\ncreate_agent는 AI 에이전트를 생성하는 데 사용됩니다. 이 에이전트는 다른 AI 보조자들과 협력하여 제공된 도구들을 사용해 질문에 대한 답변을 진행합니다. 에이전트는 최종 답변을 할 수 있는 경우 응답 앞에 ‘FINAL ANSWER’라고 표시하여 팀이 작업을 멈출 수 있도록 합니다.\\ncreate_agent 함수는 llm, tools, system_message 세 개의 매개변수를 받으며, 각 도구의 이름을 포함한 프롬프트를 생성하여 에이전트에게 전달합니다.\\nformat_tool_to_openai_function 함수는 도구를 OpenAI 함수 형식으로 변환하는 데 사용되며, ChatPromptTemplate.from_messages는 에이전트에게 전달될 메시지 템플릿을 생성합니다. 마지막으로, 생성된 프롬프트는 llm.bind_functions을 통해 에이전트의 기능과 결합됩니다.\\n```\\nimport json\\nfrom langchain_core.messages import (\\n    BaseMessage,\\n    FunctionMessage,\\n    HumanMessage,\\n)\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langgraph.graph import END, StateGraph\\nfrom langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\\ndef create_agent(llm, tools, system_message: str):\\n    # 에이전트를 생성합니다.\\n    functions = [format_tool_to_openai_function(t) for t in tools]\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\\n            \\\"system\\\",\\n            \\\"You are a helpful AI assistant, collaborating with other assistants.\\\"\\n            \\\" Use the provided tools to progress towards answering the question.\\\"\\n            \\\" If you are unable to fully answer, that's OK, another assistant with different tools \\\"\\n            \\\" will help where you left off. Execute what you can to make progress.\\\"\\n            \\\" If you or any of the other assistants have the final answer or deliverable,\\\"\\n            \\\" prefix your response with FINAL ANSWER so the team knows to stop.\\\"\\n            \\\" You have access to the following tools: {tool_names}.\\\\n{system_message}\\\",\\n        ),\\n        MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n    ]\\n)\\nprompt = prompt.partial(system_message=system_message)\\nprompt = prompt.partial(tool_names=\\\", \\\".join(\\n    [tool.name for tool in tools]))\\nreturn prompt | llm.bind_functions(functions)\\n\\n```\\nTool(도구) 정의\\n우리의 에이전트들이 미래에 사용할 몇 가지 도구들을 정의할 것입니다\\n함수 python_repl은 주어진 파이썬 코드를 실행하고 그 결과를 반환합니다. 이 함수는 tool 데코레이터로 장식되어 있으며, 사용자가 제공한 코드를 PythonREPL 인스턴스를 통해 실행합니다.\\n실행 결과는 표준 출력으로 반환되며, 실행 중 발생한 예외는 오류 메시지와 함께 반환됩니다. 사용자는 print(...) 함수를 사용하여 값을 출력할 수 있습니다.\\n이 함수는 차트 생성과 같은 작업에 사용될 수 있습니다.\\n```\\nfrom langchain_core.tools import tool\\nfrom typing import Annotated\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\ntavily_tool = TavilySearchResults(max_results=5)\\nrepl = PythonREPL()\\n@tool\\ndef python_repl(\\n    code: Annotated[str, \\\"The python code to execute to generate your chart.\\\"]\\n):\\n    \\\"\\\"\\\"Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with print(...). This is visible to the user.\\\"\\\"\\\"\\n    try:\\n        result = repl.run(code)\\n    except BaseException as e:\\n        return f\\\"Failed to execute. Error: {repr(e)}\\\"\\n    return f\\\"Succesfully executed:\\\\npython\\\\n{code}\\\\n\\\\nStdout: {result}\\\"\\n```\\n그래프 생성\\n이제 우리는 도구를 정의하고 몇 가지 헬퍼 함수를 만들었으므로, 아래에서 개별 에이전트를 생성하고 LangGraph를 사용하여 서로 통신하는 방법을 알려줄 것입니다.\\n상태 정의\\n우리는 먼저 그래프의 상태를 정의합니다. 이것은 가장 최근의 발신자를 추적하는 키와 함께 메시지의 리스트일 것입니다.\\n이 코드는 langchain 라이브러리를 사용하여 AI 에이전트와 상호작용하는 그래프 기반의 시스템을 구축하기 위한 준비 작업을 포함하고 있습니다.\\nAgentState 클래스는 에이전트의 상태를 나타내며, messages는 BaseMessage 객체의 시퀀스로 구성되며, sender는 메시지를 보낸 사람의 식별자를 나타냅니다.\\nAnnotated와 operator.add를 사용하여 messages 필드에 메시지를 추가할 수 있는 기능을 제공합니다.\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, Tuple, TypedDict, Union\\nfrom langchain_openai import ChatOpenAI\\nfrom typing_extensions import TypedDict\\n각 에이전트와 도구에 대한 다른 노드를 생성할 것입니다. 이 클래스는 그래프의 각 노드 사이에서 전달되는 객체를 정의합니다.\\nclass AgentState(TypedDict):\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n    sender: str\\n```\\n에이전트 노드 정의하기\\n이제 노드를 정의할 필요가 있습니다. 먼저, 에이전트들을 위한 노드를 정의합시다.\\n함수 agent_node는 주어진 에이전트의 상태를 처리하고, 결과 메시지와 발신자 정보를 포함하는 딕셔너리를 반환합니다. FunctionMessage 인스턴스인 경우에는 특별한 처리를 하지 않고, 그렇지 않은 경우에는 HumanMessage 인스턴스로 변환합니다.\\nChatOpenAI 클래스의 인스턴스 llm은 모델 gpt-4-1106-preview를 사용하여 생성됩니다.\\nresearch_agent와 chart_agent는 각각 연구자와 차트 생성기를 위한 에이전트를 생성하며, 이들은 llm을 사용하고 특정 도구(tavily_tool, python_repl)와 시스템 메시지를 설정합니다. research_node와 chart_node는 functools.partial을 사용하여 agent_node 함수에 필요한 인자를 미리 설정한 콜백 함수를 생성합니다.\\n```\\nimport functools\\ndef agent_node(state, agent, name):\\n    result = agent.invoke(state)\\n    if isinstance(result, FunctionMessage):\\n        pass\\n    else:\\n        result = HumanMessage(**result.dict(exclude={\\\"type\\\", \\\"name\\\"}), name=name)\\n    return {\\n        \\\"messages\\\": [result],\\n        \\\"sender\\\": name,\\n    }\\nllm = ChatOpenAI(model=\\\"gpt-4-1106-preview\\\")\\nResearch agent and node\\nresearch_agent = create_agent(\\n    llm,\\n    [tavily_tool],\\n    system_message=\\\"You should provide accurate data for the chart generator to use.\\\",\\n)\\nresearch_node = functools.partial(agent_node, agent=research_agent, name=\\\"Researcher\\\")\\nChart Generator\\nchart_agent = create_agent(\\n    llm,\\n    [python_repl],\\n    system_message=\\\"Any charts you display will be visible by the user.\\\",\\n)\\nchart_node = functools.partial(agent_node, agent=chart_agent, name=\\\"Chart Generator\\\")\\n```\\nTool Node (도구 노드) 정의\\n우리는 이제 도구를 실행하는 노드를 정의합니다\\ntool_node는 상태 객체를 받아 마지막 메시지에서 도구 호출을 추출하고, 해당 도구를 실행한 후 결과를 FunctionMessage 형태로 반환합니다.\\n이 함수는 ToolExecutor 인스턴스를 사용하여 도구를 실행하며, 실행 결과는 새로운 메시지 리스트에 추가되어 반환됩니다.\\n단일 인자 입력은 값으로 직접 전달되며, 복수 인자의 경우 ToolInvocation 객체를 통해 전달됩니다.\\n```\\ntools = [tavily_tool, python_repl]\\ntool_executor = ToolExecutor(tools)\\ndef tool_node(state):\\n    # 그래프에서 도구를 실행하는 함수입니다.\\n    # 에이전트 액션을 입력받아 해당 도구를 호출하고 결과를 반환합니다.\\n    messages = state[\\\"messages\\\"]\\n    # 계속 조건에 따라 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\n    last_message = messages[-1]\\n    # ToolInvocation을 함수 호출로부터 구성합니다.\\n    tool_input = json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    )\\n    # 단일 인자 입력은 값으로 직접 전달할 수 있습니다.\\n    if len(tool_input) == 1 and \\\"__arg1\\\" in tool_input:\\n        tool_input = next(iter(tool_input.values()))\\n    tool_name = last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"]\\n    action = ToolInvocation(\\n        tool=tool_name,\\n        tool_input=tool_input,\\n    )\\n    # 도구 실행자를 호출하고 응답을 받습니다.\\n    response = tool_executor.invoke(action)\\n    # 응답을 사용하여 FunctionMessage를 생성합니다.\\n    function_message = FunctionMessage(\\n        content=f\\\"{tool_name} response: {str(response)}\\\", name=action.tool\\n    )\\n    # 기존 리스트에 추가될 리스트를 반환합니다.\\n    return {\\\"messages\\\": [function_message]}\\n```\\n에지 로직 정의\\n에이전트의 결과에 따라 무엇을 할지 결정하는 데 필요한 일부 에지 로직을 정의할 수 있습니다.\\nrouter는 상태 정보를 받아서 다음 단계를 결정합니다. 상태 정보에서 마지막 메시지를 확인하고, 이 메시지에 특정 키워드가 포함되어 있는지에 따라 다음 단계를 반환합니다.\\n만약 마지막 메시지의 additional_kwargs에 function_call이 포함되어 있다면, 이전 에이전트가 도구를 호출한 것으로 간주하고 \\\"call_tool\\\"을 반환합니다. 만약 마지막 메시지의 내용에 \\\"FINAL ANSWER\\\"가 포함되어 있다면, 작업이 완료되었다고 판단하고 \\\"end\\\"를 반환합니다. 그렇지 않으면 작업을 계속 진행해야 하므로 \\\"continue\\\"를 반환합니다.\\ndef router(state):\\n    # 상태 정보를 기반으로 다음 단계를 결정하는 라우터 함수\\n    messages = state[\\\"messages\\\"]\\n    last_message = messages[-1]\\n    if \\\"function_call\\\" in last_message.additional_kwargs:\\n        # 이전 에이전트가 도구를 호출함\\n        return \\\"call_tool\\\"\\n    if \\\"FINAL ANSWER\\\" in last_message.content:\\n        # 어느 에이전트든 작업이 끝났다고 결정함\\n        return \\\"end\\\"\\n    return \\\"continue\\\"\\n그래프 정의하기\\n이제 모든 것을 종합하여 그래프를 정의할 수 있습니다!\\nStateGraph 클래스를 사용하여 상태 기반 워크플로우를 구성합니다.\\nAgentState를 기반으로 StateGraph 객체를 생성하고, add_node 메서드를 사용하여 여러 노드(Researcher, Chart Generator, call_tool)를 추가합니다.\\nadd_conditional_edges 메서드를 통해 조건부 엣지를 추가하여, 각 노드가 특정 조건에 따라 다른 노드로 이동할 수 있도록 합니다. 예를 들어, Researcher 노드는 router 함수의 결과에 따라 Chart Generator 또는 call_tool로 이동하거나 워크플로우를 종료할 수 있습니다. call_tool 노드는 sender 필드를 기반으로 원래 호출한 노드로 돌아갑니다.\\n마지막으로 set_entry_point 메서드로 시작점을 Researcher로 설정하고, compile 메서드로 워크플로우 그래프를 컴파일합니다.\\n```\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(\\\"Researcher\\\", research_node)\\nworkflow.add_node(\\\"Chart Generator\\\", chart_node)\\nworkflow.add_node(\\\"call_tool\\\", tool_node)\\nworkflow.add_conditional_edges(\\n    \\\"Researcher\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Chart Generator\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"Chart Generator\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Researcher\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"call_tool\\\",\\n    lambda x: x[\\\"sender\\\"],\\n    {\\n        \\\"Researcher\\\": \\\"Researcher\\\",\\n        \\\"Chart Generator\\\": \\\"Chart Generator\\\",\\n    },\\n)\\nworkflow.set_entry_point(\\\"Researcher\\\")\\ngraph = workflow.compile()\\n```\\n호출\\n그래프가 생성되었으니 이제 호출할 수 있습니다! 몇 가지 통계를 차트로 나타내도록 해봅시다.\\n이 코드는 graph 객체의 stream 메소드를 사용하여 데이터를 스트리밍합니다.\\nHumanMessage 객체를 사용하여 대한민국의 2018년부터 2022년까지의 출산율 데이터를 요청하고, 해당 데이터에 대한 그래프를 그리도록 요청합니다. 또한, 코드 실행이 완료되면 종료하도록 메시지에 포함되어 있습니다.\\n스트림은 최대 200번의 재귀 호출로 제한됩니다.\\nfor s in graph.stream(\\n    {\\n        \\\"messages\\\": [\\n            HumanMessage(\\n                content=\\\"대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, \\\"\\n                \\\"그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, \\\"\\n                \\\"마지막으로 수집한 데이터에 대한 그래프를 그려줘. \\\"\\n                \\\"코드 작성을 완료했다면 종료해줘.\\\"\\n            )\\n        ],\\n    },\\n    # 그래프에서 수행할 최대 단계 수\\n    {\\\"recursion_limit\\\": 200},\\n):\\n    print(s)\\n    print(\\\"----\\\")\\n{'Researcher': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher')], 'sender': 'Researcher'}}\\n\\n{'Chart Generator': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'call_tool': {'messages': [FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl')]}}\\n{'Chart Generator': {'messages': [HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'Researcher': {'messages': [HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n{'__end__': {'messages': [HumanMessage(content='대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, 그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, 마지막으로 수집한 데이터에 대한 그래프를 그려줘. 코드 작성을 완료했다면 종료해줘.'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator'), FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl'), HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator'), HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n라이선스\\n```\\nMIT License\\nCopyright (c) LangChain, Inc.\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n```\\n태그: AutoGen, LangChain, LangGraph, LLM, Python, 그래프 기반 시스템, 노드, 다중 에이전트, 데이터 스트리밍, 딥러닝, 랭체인, 머신러닝, 멀티에이전트, 상태 정의, 에지 로직, 협업, 호출\\n카테고리: langgraph\\n업데이트: 2024년 01월 29일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"LangGraph - Multi-Agent Collaboration(다중 협업 ... - 테디노트\", \"url\": \"https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/\", \"content\": \"failed\", \"score\": 0.29042256, \"raw_content\": \"LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph - Multi-Agent Collaboration(다중 협업 에이전트) 로 복잡한 테스크를 수행하는 LLM 어플리케이션 제작\\n2024년 01월 29일 26 분 소요\\n목차\\n\\nReference\\n실습파일\\n요약\\n튜토리얼 영상\\n\\n\\n기본 다중 에이전트 협업\\n에이전트 생성\\nTool(도구) 정의\\n그래프 생성\\n상태 정의\\n에이전트 노드 정의하기\\nTool Node (도구 노드) 정의\\n에지 로직 정의\\n그래프 정의하기\\n\\n\\n호출\\n라이선스\\n\\nLangChain 에서 야심차게 LangGraph 를 새롭게 출시하였습니다. LangGraph 라이브러리가 출시하게 된 가장 큰 이유는 “복잡한 문제들은 단일 AI 에이전트만으로 해결하기 어렵다” 라는 문장에서 시작합니다.\\n이 글에서는 LangGraph의 다중 에이전트 협업을 통해 이러한 문제들을 효과적으로 해결하는 방법을 소개합니다. 특히, LangGraph를 활용한 새로운 접근법을 중점적으로 다룹니다.\\nReference\\n본 튜토리얼은 LangGraph 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다. 라이센스는 하단에 고지하였습니다.\\n원문 바로가기\\n\\n실습파일\\n\\n요약\\n주요내용\\n\\n🤖 다중 에이전트 협업: 각기 다른 도메인의 전문 에이전트들이 협력하여 복잡한 문제를 해결합니다.\\n🔧 도구 정의와 활용: 특정 작업에 적합한 도구들을 정의하고, 이를 에이전트가 활용하는 방법을 설명합니다.\\n📊 그래프 기반 시스템 구축: LangGraph를 사용하여 에이전트들이 서로 통신하고 협력하는 그래프를 생성합니다.\\n\\n튜토리얼 영상\\n기본 다중 에이전트 협업\\n단일 에이전트는 일반적으로 단일 도메인 내에서 소수의 도구를 사용하여 효과적으로 작동할 수 있지만, gpt-4와 같은 강력한 모델을 사용하더라도 많은 도구를 사용하는 데에는 덜 효과적일 수 있습니다.\\n복잡한 작업에 접근하는 한 가지 방법은 ‘나누고 정복하기(divide-and-conquer)’ 접근법입니다. 각 작업이나 도메인에 대해 전문화된 에이전트를 만들고 작업을 올바른 ‘전문가’에게 라우팅합니다.\\n이 노트북은 Wu 등이 작성한 논문 AutoGen: 다중 에이전트 대화를 통한 차세대 LLM 애플리케이션 가능하게 하기에서 영감을 받아 LangGraph를 사용하여 이를 수행하는 한 가지 방법을 보여줍니다.\\n결과적으로 생성된 그래프는 다음 다이어그램과 같은 모습일 것입니다.\\n\\n필요한 패키지를 설치합니다.\\n```\\nlangchain, langchain_openai, langsmith, pandas, langchain_experimental, matplotlib 패키지를 설치합니다.\\n이 코드는 패키지 설치를 위한 pip 명령어를 포함하고 있습니다.\\n```\\npython-dotenv 라이브러리를 사용하여 환경 변수에서 토큰 정보를 로드합니다.\\n이 라이브러리는 .env 파일에 저장된 환경 변수를 읽어와서 Python 프로그램에서 사용할 수 있게 해줍니다. load_dotenv 함수를 호출하여 .env 파일의 내용을 로드합니다.\\n```\\n토큰 정보를 로드하기 위한 라이브러리\\n설치 명령어: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n토큰 정보 로드\\nload_dotenv()\\n```\\nTrue\\n_set_if_undefined는 환경 변수가 설정되어 있지 않을 경우 사용자로부터 해당 환경 변수의 값을 입력받아 설정하는 역할을 합니다. 이 함수는 OPENAI_API_KEY, LANGCHAIN_API_KEY, TAVILY_API_KEY 세 개의 API 키에 대해 환경 변수가 설정되어 있는지 확인하고, 없을 경우 사용자에게 입력을 요청합니다.\\n또한, LangSmith 추적 기능을 활성화하고 프로젝트 이름을 ‘Multi-agent Collaboration’으로 설정합니다.\\n```\\nimport getpass\\nimport os\\ndef _set_if_undefined(var: str):\\n    # 주어진 환경 변수가 설정되어 있지 않다면 사용자에게 입력을 요청하여 설정합니다.\\n    if not os.environ.get(var):\\n        os.environ[var] = getpass.getpass(f\\\"Please provide your {var}\\\")\\nOPENAI_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"OPENAI_API_KEY\\\")\\nLANGCHAIN_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"LANGCHAIN_API_KEY\\\")\\nTAVILY_API_KEY 환경 변수가 설정되어 있지 않으면 사용자에게 입력을 요청합니다.\\n_set_if_undefined(\\\"TAVILY_API_KEY\\\")\\nLangSmith 추적 기능을 활성화합니다. (선택적)\\nos.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\nos.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Multi-agent Collaboration\\\"\\n```\\n에이전트 생성\\ncreate_agent는 AI 에이전트를 생성하는 데 사용됩니다. 이 에이전트는 다른 AI 보조자들과 협력하여 제공된 도구들을 사용해 질문에 대한 답변을 진행합니다. 에이전트는 최종 답변을 할 수 있는 경우 응답 앞에 ‘FINAL ANSWER’라고 표시하여 팀이 작업을 멈출 수 있도록 합니다.\\ncreate_agent 함수는 llm, tools, system_message 세 개의 매개변수를 받으며, 각 도구의 이름을 포함한 프롬프트를 생성하여 에이전트에게 전달합니다.\\nformat_tool_to_openai_function 함수는 도구를 OpenAI 함수 형식으로 변환하는 데 사용되며, ChatPromptTemplate.from_messages는 에이전트에게 전달될 메시지 템플릿을 생성합니다. 마지막으로, 생성된 프롬프트는 llm.bind_functions을 통해 에이전트의 기능과 결합됩니다.\\n```\\nimport json\\nfrom langchain_core.messages import (\\n    BaseMessage,\\n    FunctionMessage,\\n    HumanMessage,\\n)\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\\nfrom langgraph.graph import END, StateGraph\\nfrom langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\\ndef create_agent(llm, tools, system_message: str):\\n    # 에이전트를 생성합니다.\\n    functions = [format_tool_to_openai_function(t) for t in tools]\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\\n            \\\"system\\\",\\n            \\\"You are a helpful AI assistant, collaborating with other assistants.\\\"\\n            \\\" Use the provided tools to progress towards answering the question.\\\"\\n            \\\" If you are unable to fully answer, that's OK, another assistant with different tools \\\"\\n            \\\" will help where you left off. Execute what you can to make progress.\\\"\\n            \\\" If you or any of the other assistants have the final answer or deliverable,\\\"\\n            \\\" prefix your response with FINAL ANSWER so the team knows to stop.\\\"\\n            \\\" You have access to the following tools: {tool_names}.\\\\n{system_message}\\\",\\n        ),\\n        MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n    ]\\n)\\nprompt = prompt.partial(system_message=system_message)\\nprompt = prompt.partial(tool_names=\\\", \\\".join(\\n    [tool.name for tool in tools]))\\nreturn prompt | llm.bind_functions(functions)\\n\\n```\\nTool(도구) 정의\\n우리의 에이전트들이 미래에 사용할 몇 가지 도구들을 정의할 것입니다\\n함수 python_repl은 주어진 파이썬 코드를 실행하고 그 결과를 반환합니다. 이 함수는 tool 데코레이터로 장식되어 있으며, 사용자가 제공한 코드를 PythonREPL 인스턴스를 통해 실행합니다.\\n실행 결과는 표준 출력으로 반환되며, 실행 중 발생한 예외는 오류 메시지와 함께 반환됩니다. 사용자는 print(...) 함수를 사용하여 값을 출력할 수 있습니다.\\n이 함수는 차트 생성과 같은 작업에 사용될 수 있습니다.\\n```\\nfrom langchain_core.tools import tool\\nfrom typing import Annotated\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_community.tools.tavily_search import TavilySearchResults\\ntavily_tool = TavilySearchResults(max_results=5)\\nrepl = PythonREPL()\\n@tool\\ndef python_repl(\\n    code: Annotated[str, \\\"The python code to execute to generate your chart.\\\"]\\n):\\n    \\\"\\\"\\\"Use this to execute python code. If you want to see the output of a value,\\n    you should print it out with print(...). This is visible to the user.\\\"\\\"\\\"\\n    try:\\n        result = repl.run(code)\\n    except BaseException as e:\\n        return f\\\"Failed to execute. Error: {repr(e)}\\\"\\n    return f\\\"Succesfully executed:\\\\npython\\\\n{code}\\\\n\\\\nStdout: {result}\\\"\\n```\\n그래프 생성\\n이제 우리는 도구를 정의하고 몇 가지 헬퍼 함수를 만들었으므로, 아래에서 개별 에이전트를 생성하고 LangGraph를 사용하여 서로 통신하는 방법을 알려줄 것입니다.\\n상태 정의\\n우리는 먼저 그래프의 상태를 정의합니다. 이것은 가장 최근의 발신자를 추적하는 키와 함께 메시지의 리스트일 것입니다.\\n이 코드는 langchain 라이브러리를 사용하여 AI 에이전트와 상호작용하는 그래프 기반의 시스템을 구축하기 위한 준비 작업을 포함하고 있습니다.\\nAgentState 클래스는 에이전트의 상태를 나타내며, messages는 BaseMessage 객체의 시퀀스로 구성되며, sender는 메시지를 보낸 사람의 식별자를 나타냅니다.\\nAnnotated와 operator.add를 사용하여 messages 필드에 메시지를 추가할 수 있는 기능을 제공합니다.\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, Tuple, TypedDict, Union\\nfrom langchain_openai import ChatOpenAI\\nfrom typing_extensions import TypedDict\\n각 에이전트와 도구에 대한 다른 노드를 생성할 것입니다. 이 클래스는 그래프의 각 노드 사이에서 전달되는 객체를 정의합니다.\\nclass AgentState(TypedDict):\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n    sender: str\\n```\\n에이전트 노드 정의하기\\n이제 노드를 정의할 필요가 있습니다. 먼저, 에이전트들을 위한 노드를 정의합시다.\\n함수 agent_node는 주어진 에이전트의 상태를 처리하고, 결과 메시지와 발신자 정보를 포함하는 딕셔너리를 반환합니다. FunctionMessage 인스턴스인 경우에는 특별한 처리를 하지 않고, 그렇지 않은 경우에는 HumanMessage 인스턴스로 변환합니다.\\nChatOpenAI 클래스의 인스턴스 llm은 모델 gpt-4-1106-preview를 사용하여 생성됩니다.\\nresearch_agent와 chart_agent는 각각 연구자와 차트 생성기를 위한 에이전트를 생성하며, 이들은 llm을 사용하고 특정 도구(tavily_tool, python_repl)와 시스템 메시지를 설정합니다. research_node와 chart_node는 functools.partial을 사용하여 agent_node 함수에 필요한 인자를 미리 설정한 콜백 함수를 생성합니다.\\n```\\nimport functools\\ndef agent_node(state, agent, name):\\n    result = agent.invoke(state)\\n    if isinstance(result, FunctionMessage):\\n        pass\\n    else:\\n        result = HumanMessage(**result.dict(exclude={\\\"type\\\", \\\"name\\\"}), name=name)\\n    return {\\n        \\\"messages\\\": [result],\\n        \\\"sender\\\": name,\\n    }\\nllm = ChatOpenAI(model=\\\"gpt-4-1106-preview\\\")\\nResearch agent and node\\nresearch_agent = create_agent(\\n    llm,\\n    [tavily_tool],\\n    system_message=\\\"You should provide accurate data for the chart generator to use.\\\",\\n)\\nresearch_node = functools.partial(agent_node, agent=research_agent, name=\\\"Researcher\\\")\\nChart Generator\\nchart_agent = create_agent(\\n    llm,\\n    [python_repl],\\n    system_message=\\\"Any charts you display will be visible by the user.\\\",\\n)\\nchart_node = functools.partial(agent_node, agent=chart_agent, name=\\\"Chart Generator\\\")\\n```\\nTool Node (도구 노드) 정의\\n우리는 이제 도구를 실행하는 노드를 정의합니다\\ntool_node는 상태 객체를 받아 마지막 메시지에서 도구 호출을 추출하고, 해당 도구를 실행한 후 결과를 FunctionMessage 형태로 반환합니다.\\n이 함수는 ToolExecutor 인스턴스를 사용하여 도구를 실행하며, 실행 결과는 새로운 메시지 리스트에 추가되어 반환됩니다.\\n단일 인자 입력은 값으로 직접 전달되며, 복수 인자의 경우 ToolInvocation 객체를 통해 전달됩니다.\\n```\\ntools = [tavily_tool, python_repl]\\ntool_executor = ToolExecutor(tools)\\ndef tool_node(state):\\n    # 그래프에서 도구를 실행하는 함수입니다.\\n    # 에이전트 액션을 입력받아 해당 도구를 호출하고 결과를 반환합니다.\\n    messages = state[\\\"messages\\\"]\\n    # 계속 조건에 따라 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\n    last_message = messages[-1]\\n    # ToolInvocation을 함수 호출로부터 구성합니다.\\n    tool_input = json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    )\\n    # 단일 인자 입력은 값으로 직접 전달할 수 있습니다.\\n    if len(tool_input) == 1 and \\\"__arg1\\\" in tool_input:\\n        tool_input = next(iter(tool_input.values()))\\n    tool_name = last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"]\\n    action = ToolInvocation(\\n        tool=tool_name,\\n        tool_input=tool_input,\\n    )\\n    # 도구 실행자를 호출하고 응답을 받습니다.\\n    response = tool_executor.invoke(action)\\n    # 응답을 사용하여 FunctionMessage를 생성합니다.\\n    function_message = FunctionMessage(\\n        content=f\\\"{tool_name} response: {str(response)}\\\", name=action.tool\\n    )\\n    # 기존 리스트에 추가될 리스트를 반환합니다.\\n    return {\\\"messages\\\": [function_message]}\\n```\\n에지 로직 정의\\n에이전트의 결과에 따라 무엇을 할지 결정하는 데 필요한 일부 에지 로직을 정의할 수 있습니다.\\nrouter는 상태 정보를 받아서 다음 단계를 결정합니다. 상태 정보에서 마지막 메시지를 확인하고, 이 메시지에 특정 키워드가 포함되어 있는지에 따라 다음 단계를 반환합니다.\\n만약 마지막 메시지의 additional_kwargs에 function_call이 포함되어 있다면, 이전 에이전트가 도구를 호출한 것으로 간주하고 \\\"call_tool\\\"을 반환합니다. 만약 마지막 메시지의 내용에 \\\"FINAL ANSWER\\\"가 포함되어 있다면, 작업이 완료되었다고 판단하고 \\\"end\\\"를 반환합니다. 그렇지 않으면 작업을 계속 진행해야 하므로 \\\"continue\\\"를 반환합니다.\\ndef router(state):\\n    # 상태 정보를 기반으로 다음 단계를 결정하는 라우터 함수\\n    messages = state[\\\"messages\\\"]\\n    last_message = messages[-1]\\n    if \\\"function_call\\\" in last_message.additional_kwargs:\\n        # 이전 에이전트가 도구를 호출함\\n        return \\\"call_tool\\\"\\n    if \\\"FINAL ANSWER\\\" in last_message.content:\\n        # 어느 에이전트든 작업이 끝났다고 결정함\\n        return \\\"end\\\"\\n    return \\\"continue\\\"\\n그래프 정의하기\\n이제 모든 것을 종합하여 그래프를 정의할 수 있습니다!\\nStateGraph 클래스를 사용하여 상태 기반 워크플로우를 구성합니다.\\nAgentState를 기반으로 StateGraph 객체를 생성하고, add_node 메서드를 사용하여 여러 노드(Researcher, Chart Generator, call_tool)를 추가합니다.\\nadd_conditional_edges 메서드를 통해 조건부 엣지를 추가하여, 각 노드가 특정 조건에 따라 다른 노드로 이동할 수 있도록 합니다. 예를 들어, Researcher 노드는 router 함수의 결과에 따라 Chart Generator 또는 call_tool로 이동하거나 워크플로우를 종료할 수 있습니다. call_tool 노드는 sender 필드를 기반으로 원래 호출한 노드로 돌아갑니다.\\n마지막으로 set_entry_point 메서드로 시작점을 Researcher로 설정하고, compile 메서드로 워크플로우 그래프를 컴파일합니다.\\n```\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(\\\"Researcher\\\", research_node)\\nworkflow.add_node(\\\"Chart Generator\\\", chart_node)\\nworkflow.add_node(\\\"call_tool\\\", tool_node)\\nworkflow.add_conditional_edges(\\n    \\\"Researcher\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Chart Generator\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"Chart Generator\\\",\\n    router,\\n    {\\\"continue\\\": \\\"Researcher\\\", \\\"call_tool\\\": \\\"call_tool\\\", \\\"end\\\": END},\\n)\\nworkflow.add_conditional_edges(\\n    \\\"call_tool\\\",\\n    lambda x: x[\\\"sender\\\"],\\n    {\\n        \\\"Researcher\\\": \\\"Researcher\\\",\\n        \\\"Chart Generator\\\": \\\"Chart Generator\\\",\\n    },\\n)\\nworkflow.set_entry_point(\\\"Researcher\\\")\\ngraph = workflow.compile()\\n```\\n호출\\n그래프가 생성되었으니 이제 호출할 수 있습니다! 몇 가지 통계를 차트로 나타내도록 해봅시다.\\n이 코드는 graph 객체의 stream 메소드를 사용하여 데이터를 스트리밍합니다.\\nHumanMessage 객체를 사용하여 대한민국의 2018년부터 2022년까지의 출산율 데이터를 요청하고, 해당 데이터에 대한 그래프를 그리도록 요청합니다. 또한, 코드 실행이 완료되면 종료하도록 메시지에 포함되어 있습니다.\\n스트림은 최대 200번의 재귀 호출로 제한됩니다.\\nfor s in graph.stream(\\n    {\\n        \\\"messages\\\": [\\n            HumanMessage(\\n                content=\\\"대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, \\\"\\n                \\\"그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, \\\"\\n                \\\"마지막으로 수집한 데이터에 대한 그래프를 그려줘. \\\"\\n                \\\"코드 작성을 완료했다면 종료해줘.\\\"\\n            )\\n        ],\\n    },\\n    # 그래프에서 수행할 최대 단계 수\\n    {\\\"recursion_limit\\\": 200},\\n):\\n    print(s)\\n    print(\\\"----\\\")\\n{'Researcher': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher')], 'sender': 'Researcher'}}\\n{'call_tool': {'messages': [FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json')]}}\\n{'Researcher': {'messages': [HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher')], 'sender': 'Researcher'}}\\n\\n{'Chart Generator': {'messages': [HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'call_tool': {'messages': [FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl')]}}\\n{'Chart Generator': {'messages': [HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator')], 'sender': 'Chart Generator'}}\\n{'Researcher': {'messages': [HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n{'__end__': {'messages': [HumanMessage(content='대한민국의 2018년 ~ 2022년의 합계출산율에 대한 데이터를 찾아줘, 그리고 2023, 2024, 2025년에 대한 전망도 찾아줘, 마지막으로 수집한 데이터에 대한 그래프를 그려줘. 코드 작성을 완료했다면 종료해줘.'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea Total Fertility Rate 2018-2022\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9623034/\\\\', \\\\'content\\\\': \\\\'from 2.79 in 1970 to 1.74 in 1995, with a further decrease to 1.63 in 2018. In 2018, Korea (0.98) had the lowest TFR  The comprehensive graph of the changes in the trends of total live births, CBR, and TFR in Korea for the past 100 years  and trends in the population count, number of births, and birth rate in Korea, in the past and future.  rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, KoreaIn 2020, the number of births fell below 300,000 for the first time in South Korea. This year, a decline was observed in the values of both crude birth rate (CBR, 5.3) and total fertility rate (TFR, 0.84), as compared with those in the previous year. Meanwhile, Korea recorded 305,100 deaths per year, which was higher than the number of births ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9733182/\\\\', \\\\'content\\\\': \\\\'The total fertility rate provided by Statistics Korea is a compilation of birth data reported to each local government  Korea, and it is in charge of setting standards for statistics, census, and various statistics. The total fertility  the relationship between changes in the Korean fertility rate and policies to encourage fertility.  The relationship between changes in the korean fertility rate and policies to encourage fertility Kyuhyoung JeongThis study utilized the longitudinal data from 2014 to 2018 on the total fertility rate of 250 local governments (the administration of a town, county, or district) provided by Statistics Korea to estimate changes in the fertility rate. ... the change in the fertility rate in South Korea showed a rapid increase in the rate of decline over time ...\\\\'}, {\\\\'url\\\\': \\\\'https://www.rand.org/pubs/commentary/2022/07/south-koreas-extraordinary-fertility-decline.html\\\\', \\\\'content\\\\': \\\"In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime—fell  About South Korea\\\\'s Extraordinary Fertility Decline commentary (The RAND Blog)  Figure 1: Global Trends in Fertility  Author\\\\'s calculations using OECD data: Demography - Fertility rates - OECD DataJuly 22, 2022. In 2021, South Korea\\\\'s total fertility rate (TFR)—the number of children born to a typical woman over her lifetime— fell to 0.81, the lowest ever recorded in a highly developed democratic nation (see Figure 1). Of all 38 countries in the Organization for Economic Cooperation and Development (OECD), South Korea stands alone as ...\\\"}, {\\\\'url\\\\': \\\\'https://www.bbc.com/news/world-asia-62670717\\\\', \\\\'content\\\\': \\\"South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low.  South Korea records world\\\\'s lowest fertility rate again  In 2020 there was widespread alarm in South Korea when it recorded more deaths than births for the first time.  The rate in the country first dropped lower than one child per woman in 2018.South Korea has again recorded the world\\\\'s lowest fertility rate with the number sinking to a new low. The rate in the country first dropped lower than one child per woman in 2018. But on ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  gender war in South Korea and countering efforts to solve the fertility issue.The fertility rate in South Korea, which has the world\\\\'s lowest rate, hit 0.78 in February. ... Both countries were among the top 10 countries for working women in 2022, while Korea ranked last, ...\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the search results, here are the total fertility rates (TFR) for South Korea from 2018 to 2022:\\\\n\\\\n- 2018: 0.98\\\\n- 2020: 0.84\\\\n- 2021: 0.81\\\\n\\\\nThere is no direct information for the years 2019 and 2022, and no projections for 2023, 2024, and 2025 were provided in the search results. We will need to conduct another search to find the missing TFR data for 2019 and 2022 and to find projections for 2023, 2024, and 2025.\\\\n\\\\nLet's conduct another search to attempt to fill in the gaps.\\\\n\\\", additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"South Korea total fertility rate 2019 2022 projections 2023 2024 2025\\\"}', 'name': 'tavily_search_results_json'}}, name='Researcher'), FunctionMessage(content='tavily_search_results_json response: [{\\\\'url\\\\': \\\\'https://edition.cnn.com/2023/12/15/asia/south-korea-to-see-population-plummet-intl-hnk/index.html\\\\', \\\\'content\\\\': \\\"The United Nations Population Fund estimates North Korea’s fertility rate for 2023 at 1.8 births per woman.  as the median age will increase from 44.9 in 2022 to 63.4 in 2072, Statistics Korea said.  South Korea, the country with the world’s lowest birth rate, expects it to fall even further in the next two years  South Korea’s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop fromSouth Korea\\\\'s total fertility rate, the number of births from a woman in her lifetime, is now expected to drop from 0.78 in 2022 to 0.65 in 2025, according to the government\\\\'s Statistics Korea.\\\"}, {\\\\'url\\\\': \\\\'https://time.com/6488894/south-korea-low-fertility-rate-trend-decline/\\\\', \\\\'content\\\\': \\\\'latest population forecasts. South Korea already has the world’s lowest fertility rate at 0.78 as of 2022.  South Korea Expects Its Already-World’s-Lowest Fertility Rate to Keep Falling  two years ago, when authorities forecast that the fertility rate would bottom out at 0.7 in 2024 before rising again.  Low fertility threatens to undermine South Korea’s economic future by shrinking its workforce and slowing consumption.The latest forecast by Statistics Korea puts the population in 2072 at 36.2 million, a 30% decline from the current 51.7 million, even though the fertility rate may recover a bit to 0.68 in 2026.\\\\'}, {\\\\'url\\\\': \\\\'https://theconversation.com/south-korea-has-the-lowest-fertility-rate-in-the-world-and-that-doesnt-bode-well-for-its-economy-207107\\\\', \\\\'content\\\\': \\\"which South Korea’s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  Edition South Korea has the lowest fertility rate in the world – and that doesn’t bode well for its\\\\\\\\xa0economy Author  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deaths  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,And South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://phys.org/news/2023-06-south-korea-lowest-fertility-worldand.html\\\\', \\\\'content\\\\': \\\"which South Korea\\\\'s fertility rate fell from 6.0 to 0.8, the U.S. saw a more gradual decline from 3.0 to 1.7.  was 0.78. South Korea is the only country in the world to register a fertility rate of less than one child per woman,  proofread South Korea has the lowest fertility rate in the world—and that doesn\\\\'t bode well for its economy  With an extremely low fertility rate of 0.78, South Korea is losing population each year and experiencing more deathsAnd South Korea\\\\'s fertility rate has been consistently below that number since 1984, when it dropped to 1.93, from 2.17 the year before. What makes the South Korean fertility rate decline more ...\\\"}, {\\\\'url\\\\': \\\\'https://www.npr.org/2023/03/19/1163341684/south-korea-fertility-rate\\\\', \\\\'content\\\\': \\\"see fertility rates more than double that of Korea at 1.67.  In South Korea, the fertility rate — the average number of children born to a woman in her reproductive years — is now  World South Korea has the world\\\\'s lowest fertility rate, a struggle with lessons for us all By Ashley Ahn  Asia South Korea prepares the young for a rapidly aging populationIn South Korea, the fertility rate — the average number of children ... given to parents with a child under the age of 1 from 300,000 won per month (about $230) to 1 million won ($765) by 2024.\\\"}]', name='tavily_search_results_json'), HumanMessage(content=\\\"Based on the new search results, we have additional data for the total fertility rates (TFR) for South Korea and projections for the coming years:\\\\n\\\\n- 2019: Missing data, not provided in search results.\\\\n- 2022: 0.78\\\\n- 2023: No specific projection given in the search results.\\\\n- 2024: A forecast from two years ago expected the fertility rate to bottom out at 0.7.\\\\n- 2025: The fertility rate is expected to drop to 0.65, according to the government's Statistics Korea.\\\\n\\\\nUnfortunately, we still lack the TFR for 2019 and the projection for 2023. Given the available data, we can generate a graph for the TFR from 2018, 2020, 2021, and 2022 and include the projections for 2024 and 2025. We'll need to leave 2019 and 2023 as gaps unless we can find more information.\\\\n\\\\nHere is the data that can be used for the chart:\\\\n\\\\n| Year | Total Fertility Rate (TFR) |\\\\n|------|----------------------------|\\\\n| 2018 | 0.98                       |\\\\n| 2019 | Data Not Available         |\\\\n| 2020 | 0.84                       |\\\\n| 2021 | 0.81                       |\\\\n| 2022 | 0.78                       |\\\\n| 2023 | Projection Not Available   |\\\\n| 2024 | 0.7 (Projected)            |\\\\n| 2025 | 0.65 (Projected)           |\\\\n\\\\nPlease let me know if you would like to proceed with generating the graph with the available data, or if there are any other steps you'd like to take.\\\", name='Researcher'), HumanMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"code\\\":\\\"import matplotlib.pyplot as plt\\\\\\\\n\\\\\\\\n# Data\\\\\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\\\\\n\\\\\\\\n# Create the plot\\\\\\\\nplt.figure(figsize=(10, 5))\\\\\\\\nplt.plot(years, fertility_rates, marker=\\\\'o\\\\')\\\\\\\\n\\\\\\\\n# Add titles and labels\\\\\\\\nplt.title(\\\\'Total Fertility Rate in South Korea (2018 - 2025)\\\\')\\\\\\\\nplt.xlabel(\\\\'Year\\\\')\\\\\\\\nplt.ylabel(\\\\'Total Fertility Rate (TFR)\\\\')\\\\\\\\n\\\\\\\\n# Add grid\\\\\\\\nplt.grid(True)\\\\\\\\n\\\\\\\\n# Show the plot\\\\\\\\nplt.show()\\\"}', 'name': 'python_repl'}}, name='Chart Generator'), FunctionMessage(content=\\\"python_repl response: Succesfully executed:\\\\n```python\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Data\\\\nyears = [2018, 2020, 2021, 2022, 2024, 2025]\\\\nfertility_rates = [0.98, 0.84, 0.81, 0.78, 0.7, 0.65]\\\\n\\\\n# Create the plot\\\\nplt.figure(figsize=(10, 5))\\\\nplt.plot(years, fertility_rates, marker='o')\\\\n\\\\n# Add titles and labels\\\\nplt.title('Total Fertility Rate in South Korea (2018 - 2025)')\\\\nplt.xlabel('Year')\\\\nplt.ylabel('Total Fertility Rate (TFR)')\\\\n\\\\n# Add grid\\\\nplt.grid(True)\\\\n\\\\n# Show the plot\\\\nplt.show()\\\\n```\\\\nStdout: \\\", name='python_repl'), HumanMessage(content='Here is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Chart Generator'), HumanMessage(content='FINAL ANSWER\\\\n\\\\nHere is the graph showing the Total Fertility Rate (TFR) in South Korea from 2018 to 2022, along with the projected rates for 2024 and 2025:\\\\n\\\\n![Total Fertility Rate in South Korea (2018 - 2025)](sandbox:/code)\\\\n\\\\nPlease note that data for 2019 and 2023 is not available, and the projections for 2024 and 2025 are based on forecasts, not actual data.', name='Researcher')], 'sender': 'Researcher'}}\\n라이선스\\n```\\nMIT License\\nCopyright (c) LangChain, Inc.\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \\\"Software\\\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \\\"AS IS\\\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n```\\n태그: AutoGen, LangChain, LangGraph, LLM, Python, 그래프 기반 시스템, 노드, 다중 에이전트, 데이터 스트리밍, 딥러닝, 랭체인, 머신러닝, 멀티에이전트, 상태 정의, 에지 로직, 협업, 호출\\n카테고리: langgraph\\n업데이트: 2024년 01월 29일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\", \"url\": \"https://teddylee777.github.io/langgraph/langgraph-agentic-rag/\", \"content\": \"{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\", \"score\": 0.22717811, \"raw_content\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\n목차\\n\\n설치\\nLangGraph Retrieval Agent\\nRetriever\\nAgent state\\n노드와 엣지(Nodes and Edges)\\nGraph\\nReference\\n\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n본 블로그에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 그리고 실제 사용 예시를 통해 이러한 도구들의 효과적인 활용 방법을 탐구합니다.\\nPython 코드를 중심으로 설명을 진행하며, 실제 구현 예시를 통해 문서 검색 및 처리의 전체 흐름을 이해할 수 있도록 구성되어 있습니다.\\n주요 내용\\n\\n📚 LangGraph와 Retrieval Agent 소개: 언어 기반 AI 애플리케이션 개발에 필수적인 도구들의 기능과 중요성을 설명합니다.\\n🛠️ 구현 방법: Python을 활용한 LangGraph Retrieval Agent의 구현 과정을 단계별로 설명합니다.\\n🌐 실제 사용 예시: 동적 문서 검색 및 처리의 실제 사용 예시를 통해 LangGraph와 Retrieval Agent의 통합 사용 방법을 탐구합니다.\\n📝 고급 기능과 활용: 검색 에이전트의 고급 기능과 다양한 활용 방안을 소개합니다.\\n🔄 상태 기반 그래프 작업 흐름: 상태 기반 그래프를 사용하여 복잡한 결정과 작업의 흐름을 관리하는 방법을 설명합니다.\\n\\n설치\\n다양한 언어 처리 및 AI 관련 라이브러리를 설치하는 명령어입니다. langchain_community, tiktoken, langchain-openai, langchainhub, chromadb, langchain, langgraph 등의 패키지를 포함합니다.\\n!pip install -qU langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph\\nAPI KEY를 로드합니다.\\n```\\napi key\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n```\\nTrue\\nLangGraph Retrieval Agent\\n검색 에이전트는 인덱스에서 검색할지 여부에 대한 결정을 내리고 싶을 때 유용합니다.\\n검색 에이전트를 구현하기 위해서는 LLM에 검색 도구에 대한 접근 권한을 제공하기만 하면 됩니다. 이를 LangGraph로 구현해 봅시다!\\nRetriever\\n첫 번째로, 3개의 블로그 게시물을 인덱싱합니다.\\n\\nWebBaseLoader를 사용하여 주어진 URL 목록에서 문서를 로드합니다.\\nRecursiveCharacterTextSplitter는 문서를 특정 크기의 청크로 분할하는 데 사용됩니다.\\n분할된 문서는 Chroma 벡터 저장소에 저장되며, OpenAIEmbeddings를 사용하여 임베딩됩니다.\\n이후, 저장된 문서는 검색을 위해 검색기(retriever)로 변환됩니다.\\n\\n```\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_openai import OpenAIEmbeddings\\nurls = [\\n    \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\\\",\\n]\\ndocs = [WebBaseLoader(url).load() for url in urls]\\ndocs_list = [item for sublist in docs for item in sublist]\\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\\n    chunk_size=100, chunk_overlap=50\\n)\\ndoc_splits = text_splitter.split_documents(docs_list)\\n벡터 데이터베이스에 문서 추가\\nvectorstore = Chroma.from_documents(\\n    documents=doc_splits,\\n    collection_name=\\\"rag-chroma\\\",\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n```\\nLangChain의 create_retriever_tool 함수를 사용하여 특정 주제에 대한 블로그 게시물을 검색하고 정보를 반환하는 도구를 생성합니다. 이 예제에서는 Lilian Weng의 블로그 게시물 중 LLM 에이전트, 프롬프트 엔지니어링, LLM에 대한 적대적 공격에 관한 정보를 검색합니다.\\n생성된 도구는 ToolExecutor 클래스의 인스턴스에 등록되어 실행될 준비가 됩니다. ToolExecutor는 등록된 모든 도구를 관리하고 실행하는 역할을 담당합니다.\\n```\\nfrom langgraph.prebuilt import ToolExecutor\\nfrom langchain.tools.retriever import create_retriever_tool\\n릴리안 웡의 블로그 게시물에 대한 정보를 검색하고 반환하는 도구를 생성합니다.\\ntool = create_retriever_tool(\\n    retriever,\\n    \\\"retrieve_blog_posts\\\",\\n    \\\"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\\\",\\n)\\ntools = [tool]\\n도구들을 실행할 ToolExecutor 객체를 생성합니다.\\ntool_executor = ToolExecutor(tools)\\n```\\nAgent state\\n그래프를 정의해야 합니다.\\n\\nAgentState 는 각 노드에 전달하는 state 객체입니다.\\nAgentState 는 messages의 리스트로 담깁니다.\\n그런 다음 그래프의 각 노드는 AgentState 를 추가합니다.\\n\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain_core.messages import BaseMessage\\nclass AgentState(TypedDict):\\n    # AgentState 클래스는 메시지 시퀀스를 포함하는 타입 딕셔너리입니다.\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n```\\n노드와 엣지(Nodes and Edges)\\n우리는 agentic RAG 그래프를 다음과 같이 구성할 수 있습니다\\n\\n\\n상태는 메시지의 집합입니다\\n\\n\\n각 노드는 상태를 업데이트(추가)합니다\\n\\n\\n조건부 엣지는 다음에 방문할 노드를 결정합니다\\n\\n\\n\\n문서 검색, 관련성 평가, 질문 재구성, 그리고 답변 생성을 포함하는 정보 검색 및 처리 프로세스를 구현합니다.\\n\\n첫 단계에서는 에이전트가 추가 정보를 검색해야 하는지 결정합니다(should_retrieve).\\n다음으로, 검색된 문서가 주어진 질문과 관련이 있는지 평가합니다(grade_documents).\\n이후, 질문을 재구성하여 더 나은 질문을 생성합니다(rewrite).\\n마지막으로, 최종적으로 검색된 문서를 바탕으로 답변을 생성합니다(generate).\\n\\n각 단계는 특정 입력에 따라 동작하며, 이 과정은 대화형 에이전트나 정보 검색 시스템에서 유용하게 사용될 수 있습니다.\\n```\\nimport json\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain import hub\\nfrom langchain.output_parsers import PydanticOutputParser\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain_core.utils.function_calling import convert_to_openai_tool\\nfrom langchain_core.messages import BaseMessage, FunctionMessage\\nfrom langchain.output_parsers.openai_tools import PydanticToolsParser\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.prebuilt import ToolInvocation\\nfrom langchain_core.output_parsers import StrOutputParser\\nEdges\\ndef should_retrieve(state):\\n    \\\"\\\"\\\"\\n    에이전트가 더 많은 정보를 검색해야 하는지 또는 프로세스를 종료해야 하는지 결정합니다.\\n이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\\n\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 검색 프로세스를 \\\"계속\\\"하거나 \\\"종료\\\"하는 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---DECIDE TO RETRIEVE---\\\")\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\n# 함수 호출이 없으면 종료합니다.\\nif \\\"function_call\\\" not in last_message.additional_kwargs:\\n    print(\\\"---DECISION: DO NOT RETRIEVE / DONE---\\\")\\n    return \\\"end\\\"\\n# 그렇지 않으면 함수 호출이 있으므로 계속합니다.\\nelse:\\n    print(\\\"---DECISION: RETRIEVE---\\\")\\n    return \\\"continue\\\"\\n\\ndef grade_documents(state):\\n    \\\"\\\"\\\"\\n    검색된 문서가 질문과 관련이 있는지 여부를 결정합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 문서가 관련이 있는지 여부에 대한 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---CHECK RELEVANCE---\\\")\\n\\n# 데이터 모델\\nclass grade(BaseModel):\\n    \\\"\\\"\\\"관련성 검사를 위한 이진 점수.\\\"\\\"\\\"\\n\\n    binary_score: str = Field(description=\\\"'yes' 또는 'no'의 관련성 점수\\\")\\n\\n# LLM\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\n\\n# 도구\\ngrade_tool_oai = convert_to_openai_tool(grade)\\n\\n# 도구와 강제 호출을 사용한 LLM\\nllm_with_tool = model.bind(\\n    tools=[convert_to_openai_tool(grade_tool_oai)],\\n    tool_choice={\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"grade\\\"}},\\n)\\n\\n# 파서\\nparser_tool = PydanticToolsParser(tools=[grade])\\n\\n# 프롬프트\\nprompt = PromptTemplate(\\n    template=\\\"\\\"\\\"You are a grader assessing relevance of a retrieved document to a user question. \\\\n \\n    Here is the retrieved document: \\\\n\\\\n {context} \\\\n\\\\n\\n    Here is the user question: {question} \\\\n\\n    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\\\n\\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\\"\\\"\\\",\\n    input_variables=[\\\"context\\\", \\\"question\\\"],\\n)\\n\\n# 체인\\nchain = prompt | llm_with_tool | parser_tool\\n\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\nscore = chain.invoke({\\\"question\\\": question, \\\"context\\\": docs})\\n\\ngrade = score[0].binary_score\\n\\nif grade == \\\"yes\\\":\\n    print(\\\"---DECISION: DOCS RELEVANT---\\\")\\n    return \\\"yes\\\"\\n\\nelse:\\n    print(\\\"---DECISION: DOCS NOT RELEVANT---\\\")\\n    print(grade)\\n    return \\\"no\\\"\\n\\nNodes\\ndef agent(state):\\n    \\\"\\\"\\\"\\n    현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---CALL AGENT---\\\")\\nmessages = state[\\\"messages\\\"]\\nmodel = ChatOpenAI(temperature=0, streaming=True,\\n                   model=\\\"gpt-4-0125-preview\\\")\\nfunctions = [format_tool_to_openai_function(t) for t in tools]\\nmodel = model.bind_functions(functions)\\nresponse = model.invoke(messages)\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [response]}\\n\\ndef retrieve(state):\\n    \\\"\\\"\\\"\\n    도구를 사용하여 검색을 실행합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 검색된 문서가 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---EXECUTE RETRIEVAL---\\\")\\nmessages = state[\\\"messages\\\"]\\n# 계속 조건을 기반으로 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\nlast_message = messages[-1]\\n# 함수 호출에서 ToolInvocation을 구성합니다.\\naction = ToolInvocation(\\n    tool=last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"],\\n    tool_input=json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    ),\\n)\\n# 도구 실행자를 호출하고 응답을 받습니다.\\nresponse = tool_executor.invoke(action)\\nfunction_message = FunctionMessage(content=str(response), name=action.tool)\\n\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [function_message]}\\n\\ndef rewrite(state):\\n    \\\"\\\"\\\"\\n    질문을 변형하여 더 나은 질문을 생성합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\n\\nprint(\\\"---TRANSFORM QUERY---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\n\\nmsg = [\\n    HumanMessage(\\n        content=f\\\"\\\"\\\" \\\\n \\nLook at the input and try to reason about the underlying semantic intent / meaning. \\\\n \\nHere is the initial question:\\n\\\\n ------- \\\\n\\n{question} \\n\\\\n ------- \\\\n\\nFormulate an improved question: \\\"\\\"\\\",\\n    )\\n]\\n\\n# 평가자\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\nresponse = model.invoke(msg)\\nreturn {\\\"messages\\\": [response]}\\n\\ndef generate(state):\\n    \\\"\\\"\\\"\\n    답변 생성\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n     dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---GENERATE---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\n# 프롬프트\\nprompt = hub.pull(\\\"rlm/rag-prompt\\\")\\n\\n# LLM\\nllm = ChatOpenAI(model_name=\\\"gpt-4-turbo-preview\\\",\\n                 temperature=0, streaming=True)\\n\\n# 후처리\\ndef format_docs(docs):\\n    return \\\"\\\\n\\\\n\\\".join(doc.page_content for doc in docs)\\n\\n# 체인\\nrag_chain = prompt | llm | StrOutputParser()\\n\\n# 실행\\nresponse = rag_chain.invoke({\\\"context\\\": docs, \\\"question\\\": question})\\nreturn {\\\"messages\\\": [response]}\\n\\n```\\nGraph\\n\\n\\n에이전트로 시작하며, call_model\\n\\n\\n에이전트는 함수를 호출할지 결정합니다\\n\\n\\n만약 호출한다면, 도구(검색기)를 호출하는 action을 수행합니다\\n\\n\\n그 다음 메시지(state)에 도구의 출력을 추가하여 에이전트를 호출합니다\\n\\n\\nStateGraph 클래스는 상태 기반 그래프를 정의하고 관리하는 데 사용됩니다.\\n```\\nfrom langgraph.graph import END, StateGraph\\nlanggraph.graph에서 StateGraph와 END를 가져옵니다.\\nworkflow = StateGraph(AgentState)\\n순환할 노드들을 정의합니다.\\nworkflow.add_node(\\\"agent\\\", agent)  # 에이전트 노드를 추가합니다.\\nworkflow.add_node(\\\"retrieve\\\", retrieve)  # 정보 검색 노드를 추가합니다.\\nworkflow.add_node(\\\"rewrite\\\", rewrite)  # 정보 재작성 노드를 추가합니다.\\nworkflow.add_node(\\\"generate\\\", generate)  # 정보 생성 노드를 추가합니다.\\n```\\n주어진 코드는 워크플로우를 설정하여 에이전트의 결정에 따라 문서를 검색하거나 다른 작업을 수행하는 과정을 정의합니다.\\n처음에는 agent 노드를 시작점으로 설정하고, 에이전트의 결정(should_retrieve)에 따라 retrieve 노드를 호출하거나 작업을 종료합니다.\\nretrieve 노드 이후에는 문서의 평가(grade_documents)를 통해 generate 또는 rewrite 작업을 결정하고, 각각의 경로를 따라 최종적으로 작업을 마무리하거나 에이전트로 돌아가는 과정을 포함합니다.\\n이 과정은 복잡한 결정과 작업의 흐름을 관리하는 데 사용될 수 있으며, 최종적으로 워크플로우를 컴파일하여 실행 가능한 애플리케이션을 생성합니다.\\n```\\n에이전트 노드 호출하여 검색 여부 결정\\nworkflow.set_entry_point(\\\"agent\\\")\\n검색 여부 결정\\nworkflow.add_conditional_edges(\\n    \\\"agent\\\",\\n    # 에이전트 결정 평가\\n    should_retrieve,\\n    {\\n        # 도구 노드 호출\\n        \\\"continue\\\": \\\"retrieve\\\",\\n        \\\"end\\\": END,\\n    },\\n)\\naction 노드 호출 후 진행될 경로\\nworkflow.add_conditional_edges(\\n    \\\"retrieve\\\",\\n    # 에이전트 결정 평가\\n    grade_documents,\\n    {\\n        \\\"yes\\\": \\\"generate\\\",\\n        \\\"no\\\": \\\"rewrite\\\",\\n    },\\n)\\nworkflow.add_edge(\\\"generate\\\", END)\\nworkflow.add_edge(\\\"rewrite\\\", \\\"agent\\\")\\n컴파일\\napp = workflow.compile()\\n```\\n다음은 langchain_core.messages 모듈의 HumanMessage 클래스를 활용하여 사용자의 질문을 정의하고, app.stream 메소드를 통해 이 질문에 대한 응답을 스트리밍하는 과정을 보여줍니다.\\n```\\nimport pprint\\nfrom langchain_core.messages import HumanMessage\\nHumanMessage 객체를 사용하여 질문 메시지를 정의합니다.\\ninputs = {\\n    \\\"messages\\\": [\\n        HumanMessage(\\n            content=\\\"What does Lilian Weng say about the types of agent memory?\\\"\\n        )\\n    ]\\n}\\napp.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\\nfor output in app.stream(inputs):\\n    # 출력된 결과에서 키와 값을 순회합니다.\\n    for key, value in output.items():\\n        # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\\n        pprint.pprint(f\\\"Output from node '{key}':\\\")\\n        pprint.pprint(\\\"---\\\")\\n        # 출력 값을 예쁘게 출력합니다.\\n        pprint.pprint(value, indent=2, width=80, depth=None)\\n    # 각 출력 사이에 구분선을 추가합니다.\\n    pprint.pprint(\\\"\\\\n---\\\\n\\\")\\n```\\n---CALL AGENT---\\n\\\"Output from node 'agent':\\\"\\n'---'\\n{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}})]}\\n'\\\\n---\\\\n'\\n---DECIDE TO RETRIEVE---\\n---DECISION: RETRIEVE---\\n---EXECUTE RETRIEVAL---\\n\\\"Output from node 'retrieve':\\\"\\n'---'\\n{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\\n'\\\\n---\\\\n'\\n---CHECK RELEVANCE---\\n---DECISION: DOCS RELEVANT---\\n---GENERATE---\\n\\\"Output from node 'generate':\\\"\\n'---'\\n{ 'messages': [ 'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\n\\\"Output from node '__end__':\\\"\\n'---'\\n{ 'messages': [ HumanMessage(content='What does Lilian Weng say about the types of agent memory?'),\\n                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}}),\\n                FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts'),\\n                'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\nReference\\n본 튜토리얼은 langchain-ai 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n본 내용의 저작권은 2024년 테디노트(https://teddylee777.github.io)에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com으로 문의할 수 있습니다.\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다.\\n원문 바로가기\\n\\n태그: AI 애플리케이션, langchain, langgraph, openai, python, retrieval agent, 검색 에이전트, 그래프 기반 데이터 처리, 데이터베이스 관리, 문서 검색, 정보 처리\\n카테고리: langgraph\\n업데이트: 2024년 03월 06일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 34 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {\"title\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\", \"url\": \"https://teddylee777.github.io/langgraph/langgraph-agentic-rag/\", \"content\": \"{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\", \"score\": 0.22717811, \"raw_content\": \"LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리 - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langgraph \\n/5.  LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\n목차\\n\\n설치\\nLangGraph Retrieval Agent\\nRetriever\\nAgent state\\n노드와 엣지(Nodes and Edges)\\nGraph\\nReference\\n\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n본 블로그에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 그리고 실제 사용 예시를 통해 이러한 도구들의 효과적인 활용 방법을 탐구합니다.\\nPython 코드를 중심으로 설명을 진행하며, 실제 구현 예시를 통해 문서 검색 및 처리의 전체 흐름을 이해할 수 있도록 구성되어 있습니다.\\n주요 내용\\n\\n📚 LangGraph와 Retrieval Agent 소개: 언어 기반 AI 애플리케이션 개발에 필수적인 도구들의 기능과 중요성을 설명합니다.\\n🛠️ 구현 방법: Python을 활용한 LangGraph Retrieval Agent의 구현 과정을 단계별로 설명합니다.\\n🌐 실제 사용 예시: 동적 문서 검색 및 처리의 실제 사용 예시를 통해 LangGraph와 Retrieval Agent의 통합 사용 방법을 탐구합니다.\\n📝 고급 기능과 활용: 검색 에이전트의 고급 기능과 다양한 활용 방안을 소개합니다.\\n🔄 상태 기반 그래프 작업 흐름: 상태 기반 그래프를 사용하여 복잡한 결정과 작업의 흐름을 관리하는 방법을 설명합니다.\\n\\n설치\\n다양한 언어 처리 및 AI 관련 라이브러리를 설치하는 명령어입니다. langchain_community, tiktoken, langchain-openai, langchainhub, chromadb, langchain, langgraph 등의 패키지를 포함합니다.\\n!pip install -qU langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph\\nAPI KEY를 로드합니다.\\n```\\napi key\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n```\\nTrue\\nLangGraph Retrieval Agent\\n검색 에이전트는 인덱스에서 검색할지 여부에 대한 결정을 내리고 싶을 때 유용합니다.\\n검색 에이전트를 구현하기 위해서는 LLM에 검색 도구에 대한 접근 권한을 제공하기만 하면 됩니다. 이를 LangGraph로 구현해 봅시다!\\nRetriever\\n첫 번째로, 3개의 블로그 게시물을 인덱싱합니다.\\n\\nWebBaseLoader를 사용하여 주어진 URL 목록에서 문서를 로드합니다.\\nRecursiveCharacterTextSplitter는 문서를 특정 크기의 청크로 분할하는 데 사용됩니다.\\n분할된 문서는 Chroma 벡터 저장소에 저장되며, OpenAIEmbeddings를 사용하여 임베딩됩니다.\\n이후, 저장된 문서는 검색을 위해 검색기(retriever)로 변환됩니다.\\n\\n```\\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_openai import OpenAIEmbeddings\\nurls = [\\n    \\\"https://lilianweng.github.io/posts/2023-06-23-agent/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\\\",\\n    \\\"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\\\",\\n]\\ndocs = [WebBaseLoader(url).load() for url in urls]\\ndocs_list = [item for sublist in docs for item in sublist]\\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\\n    chunk_size=100, chunk_overlap=50\\n)\\ndoc_splits = text_splitter.split_documents(docs_list)\\n벡터 데이터베이스에 문서 추가\\nvectorstore = Chroma.from_documents(\\n    documents=doc_splits,\\n    collection_name=\\\"rag-chroma\\\",\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n```\\nLangChain의 create_retriever_tool 함수를 사용하여 특정 주제에 대한 블로그 게시물을 검색하고 정보를 반환하는 도구를 생성합니다. 이 예제에서는 Lilian Weng의 블로그 게시물 중 LLM 에이전트, 프롬프트 엔지니어링, LLM에 대한 적대적 공격에 관한 정보를 검색합니다.\\n생성된 도구는 ToolExecutor 클래스의 인스턴스에 등록되어 실행될 준비가 됩니다. ToolExecutor는 등록된 모든 도구를 관리하고 실행하는 역할을 담당합니다.\\n```\\nfrom langgraph.prebuilt import ToolExecutor\\nfrom langchain.tools.retriever import create_retriever_tool\\n릴리안 웡의 블로그 게시물에 대한 정보를 검색하고 반환하는 도구를 생성합니다.\\ntool = create_retriever_tool(\\n    retriever,\\n    \\\"retrieve_blog_posts\\\",\\n    \\\"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\\\",\\n)\\ntools = [tool]\\n도구들을 실행할 ToolExecutor 객체를 생성합니다.\\ntool_executor = ToolExecutor(tools)\\n```\\nAgent state\\n그래프를 정의해야 합니다.\\n\\nAgentState 는 각 노드에 전달하는 state 객체입니다.\\nAgentState 는 messages의 리스트로 담깁니다.\\n그런 다음 그래프의 각 노드는 AgentState 를 추가합니다.\\n\\n```\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain_core.messages import BaseMessage\\nclass AgentState(TypedDict):\\n    # AgentState 클래스는 메시지 시퀀스를 포함하는 타입 딕셔너리입니다.\\n    messages: Annotated[Sequence[BaseMessage], operator.add]\\n```\\n노드와 엣지(Nodes and Edges)\\n우리는 agentic RAG 그래프를 다음과 같이 구성할 수 있습니다\\n\\n\\n상태는 메시지의 집합입니다\\n\\n\\n각 노드는 상태를 업데이트(추가)합니다\\n\\n\\n조건부 엣지는 다음에 방문할 노드를 결정합니다\\n\\n\\n\\n문서 검색, 관련성 평가, 질문 재구성, 그리고 답변 생성을 포함하는 정보 검색 및 처리 프로세스를 구현합니다.\\n\\n첫 단계에서는 에이전트가 추가 정보를 검색해야 하는지 결정합니다(should_retrieve).\\n다음으로, 검색된 문서가 주어진 질문과 관련이 있는지 평가합니다(grade_documents).\\n이후, 질문을 재구성하여 더 나은 질문을 생성합니다(rewrite).\\n마지막으로, 최종적으로 검색된 문서를 바탕으로 답변을 생성합니다(generate).\\n\\n각 단계는 특정 입력에 따라 동작하며, 이 과정은 대화형 에이전트나 정보 검색 시스템에서 유용하게 사용될 수 있습니다.\\n```\\nimport json\\nimport operator\\nfrom typing import Annotated, Sequence, TypedDict\\nfrom langchain import hub\\nfrom langchain.output_parsers import PydanticOutputParser\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.tools.render import format_tool_to_openai_function\\nfrom langchain_core.utils.function_calling import convert_to_openai_tool\\nfrom langchain_core.messages import BaseMessage, FunctionMessage\\nfrom langchain.output_parsers.openai_tools import PydanticToolsParser\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.prebuilt import ToolInvocation\\nfrom langchain_core.output_parsers import StrOutputParser\\nEdges\\ndef should_retrieve(state):\\n    \\\"\\\"\\\"\\n    에이전트가 더 많은 정보를 검색해야 하는지 또는 프로세스를 종료해야 하는지 결정합니다.\\n이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\\n\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 검색 프로세스를 \\\"계속\\\"하거나 \\\"종료\\\"하는 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---DECIDE TO RETRIEVE---\\\")\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\n# 함수 호출이 없으면 종료합니다.\\nif \\\"function_call\\\" not in last_message.additional_kwargs:\\n    print(\\\"---DECISION: DO NOT RETRIEVE / DONE---\\\")\\n    return \\\"end\\\"\\n# 그렇지 않으면 함수 호출이 있으므로 계속합니다.\\nelse:\\n    print(\\\"---DECISION: RETRIEVE---\\\")\\n    return \\\"continue\\\"\\n\\ndef grade_documents(state):\\n    \\\"\\\"\\\"\\n    검색된 문서가 질문과 관련이 있는지 여부를 결정합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    str: 문서가 관련이 있는지 여부에 대한 결정\\n\\\"\\\"\\\"\\n\\nprint(\\\"---CHECK RELEVANCE---\\\")\\n\\n# 데이터 모델\\nclass grade(BaseModel):\\n    \\\"\\\"\\\"관련성 검사를 위한 이진 점수.\\\"\\\"\\\"\\n\\n    binary_score: str = Field(description=\\\"'yes' 또는 'no'의 관련성 점수\\\")\\n\\n# LLM\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\n\\n# 도구\\ngrade_tool_oai = convert_to_openai_tool(grade)\\n\\n# 도구와 강제 호출을 사용한 LLM\\nllm_with_tool = model.bind(\\n    tools=[convert_to_openai_tool(grade_tool_oai)],\\n    tool_choice={\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"grade\\\"}},\\n)\\n\\n# 파서\\nparser_tool = PydanticToolsParser(tools=[grade])\\n\\n# 프롬프트\\nprompt = PromptTemplate(\\n    template=\\\"\\\"\\\"You are a grader assessing relevance of a retrieved document to a user question. \\\\n \\n    Here is the retrieved document: \\\\n\\\\n {context} \\\\n\\\\n\\n    Here is the user question: {question} \\\\n\\n    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\\\n\\n    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\\\"\\\"\\\",\\n    input_variables=[\\\"context\\\", \\\"question\\\"],\\n)\\n\\n# 체인\\nchain = prompt | llm_with_tool | parser_tool\\n\\nmessages = state[\\\"messages\\\"]\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\nscore = chain.invoke({\\\"question\\\": question, \\\"context\\\": docs})\\n\\ngrade = score[0].binary_score\\n\\nif grade == \\\"yes\\\":\\n    print(\\\"---DECISION: DOCS RELEVANT---\\\")\\n    return \\\"yes\\\"\\n\\nelse:\\n    print(\\\"---DECISION: DOCS NOT RELEVANT---\\\")\\n    print(grade)\\n    return \\\"no\\\"\\n\\nNodes\\ndef agent(state):\\n    \\\"\\\"\\\"\\n    현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---CALL AGENT---\\\")\\nmessages = state[\\\"messages\\\"]\\nmodel = ChatOpenAI(temperature=0, streaming=True,\\n                   model=\\\"gpt-4-0125-preview\\\")\\nfunctions = [format_tool_to_openai_function(t) for t in tools]\\nmodel = model.bind_functions(functions)\\nresponse = model.invoke(messages)\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [response]}\\n\\ndef retrieve(state):\\n    \\\"\\\"\\\"\\n    도구를 사용하여 검색을 실행합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 검색된 문서가 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---EXECUTE RETRIEVAL---\\\")\\nmessages = state[\\\"messages\\\"]\\n# 계속 조건을 기반으로 마지막 메시지가 함수 호출을 포함하고 있음을 알 수 있습니다.\\nlast_message = messages[-1]\\n# 함수 호출에서 ToolInvocation을 구성합니다.\\naction = ToolInvocation(\\n    tool=last_message.additional_kwargs[\\\"function_call\\\"][\\\"name\\\"],\\n    tool_input=json.loads(\\n        last_message.additional_kwargs[\\\"function_call\\\"][\\\"arguments\\\"]\\n    ),\\n)\\n# 도구 실행자를 호출하고 응답을 받습니다.\\nresponse = tool_executor.invoke(action)\\nfunction_message = FunctionMessage(content=str(response), name=action.tool)\\n\\n# 이것은 기존 목록에 추가될 것이므로 리스트를 반환합니다.\\nreturn {\\\"messages\\\": [function_message]}\\n\\ndef rewrite(state):\\n    \\\"\\\"\\\"\\n    질문을 변형하여 더 나은 질문을 생성합니다.\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n    dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\n\\nprint(\\\"---TRANSFORM QUERY---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\n\\nmsg = [\\n    HumanMessage(\\n        content=f\\\"\\\"\\\" \\\\n \\nLook at the input and try to reason about the underlying semantic intent / meaning. \\\\n \\nHere is the initial question:\\n\\\\n ------- \\\\n\\n{question} \\n\\\\n ------- \\\\n\\nFormulate an improved question: \\\"\\\"\\\",\\n    )\\n]\\n\\n# 평가자\\nmodel = ChatOpenAI(\\n    temperature=0, model=\\\"gpt-4-0125-preview\\\", streaming=True)\\nresponse = model.invoke(msg)\\nreturn {\\\"messages\\\": [response]}\\n\\ndef generate(state):\\n    \\\"\\\"\\\"\\n    답변 생성\\nArgs:\\n    state (messages): 현재 상태\\n\\nReturns:\\n     dict: 재구성된 질문이 추가된 업데이트된 상태\\n\\\"\\\"\\\"\\nprint(\\\"---GENERATE---\\\")\\nmessages = state[\\\"messages\\\"]\\nquestion = messages[0].content\\nlast_message = messages[-1]\\n\\nquestion = messages[0].content\\ndocs = last_message.content\\n\\n# 프롬프트\\nprompt = hub.pull(\\\"rlm/rag-prompt\\\")\\n\\n# LLM\\nllm = ChatOpenAI(model_name=\\\"gpt-4-turbo-preview\\\",\\n                 temperature=0, streaming=True)\\n\\n# 후처리\\ndef format_docs(docs):\\n    return \\\"\\\\n\\\\n\\\".join(doc.page_content for doc in docs)\\n\\n# 체인\\nrag_chain = prompt | llm | StrOutputParser()\\n\\n# 실행\\nresponse = rag_chain.invoke({\\\"context\\\": docs, \\\"question\\\": question})\\nreturn {\\\"messages\\\": [response]}\\n\\n```\\nGraph\\n\\n\\n에이전트로 시작하며, call_model\\n\\n\\n에이전트는 함수를 호출할지 결정합니다\\n\\n\\n만약 호출한다면, 도구(검색기)를 호출하는 action을 수행합니다\\n\\n\\n그 다음 메시지(state)에 도구의 출력을 추가하여 에이전트를 호출합니다\\n\\n\\nStateGraph 클래스는 상태 기반 그래프를 정의하고 관리하는 데 사용됩니다.\\n```\\nfrom langgraph.graph import END, StateGraph\\nlanggraph.graph에서 StateGraph와 END를 가져옵니다.\\nworkflow = StateGraph(AgentState)\\n순환할 노드들을 정의합니다.\\nworkflow.add_node(\\\"agent\\\", agent)  # 에이전트 노드를 추가합니다.\\nworkflow.add_node(\\\"retrieve\\\", retrieve)  # 정보 검색 노드를 추가합니다.\\nworkflow.add_node(\\\"rewrite\\\", rewrite)  # 정보 재작성 노드를 추가합니다.\\nworkflow.add_node(\\\"generate\\\", generate)  # 정보 생성 노드를 추가합니다.\\n```\\n주어진 코드는 워크플로우를 설정하여 에이전트의 결정에 따라 문서를 검색하거나 다른 작업을 수행하는 과정을 정의합니다.\\n처음에는 agent 노드를 시작점으로 설정하고, 에이전트의 결정(should_retrieve)에 따라 retrieve 노드를 호출하거나 작업을 종료합니다.\\nretrieve 노드 이후에는 문서의 평가(grade_documents)를 통해 generate 또는 rewrite 작업을 결정하고, 각각의 경로를 따라 최종적으로 작업을 마무리하거나 에이전트로 돌아가는 과정을 포함합니다.\\n이 과정은 복잡한 결정과 작업의 흐름을 관리하는 데 사용될 수 있으며, 최종적으로 워크플로우를 컴파일하여 실행 가능한 애플리케이션을 생성합니다.\\n```\\n에이전트 노드 호출하여 검색 여부 결정\\nworkflow.set_entry_point(\\\"agent\\\")\\n검색 여부 결정\\nworkflow.add_conditional_edges(\\n    \\\"agent\\\",\\n    # 에이전트 결정 평가\\n    should_retrieve,\\n    {\\n        # 도구 노드 호출\\n        \\\"continue\\\": \\\"retrieve\\\",\\n        \\\"end\\\": END,\\n    },\\n)\\naction 노드 호출 후 진행될 경로\\nworkflow.add_conditional_edges(\\n    \\\"retrieve\\\",\\n    # 에이전트 결정 평가\\n    grade_documents,\\n    {\\n        \\\"yes\\\": \\\"generate\\\",\\n        \\\"no\\\": \\\"rewrite\\\",\\n    },\\n)\\nworkflow.add_edge(\\\"generate\\\", END)\\nworkflow.add_edge(\\\"rewrite\\\", \\\"agent\\\")\\n컴파일\\napp = workflow.compile()\\n```\\n다음은 langchain_core.messages 모듈의 HumanMessage 클래스를 활용하여 사용자의 질문을 정의하고, app.stream 메소드를 통해 이 질문에 대한 응답을 스트리밍하는 과정을 보여줍니다.\\n```\\nimport pprint\\nfrom langchain_core.messages import HumanMessage\\nHumanMessage 객체를 사용하여 질문 메시지를 정의합니다.\\ninputs = {\\n    \\\"messages\\\": [\\n        HumanMessage(\\n            content=\\\"What does Lilian Weng say about the types of agent memory?\\\"\\n        )\\n    ]\\n}\\napp.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\\nfor output in app.stream(inputs):\\n    # 출력된 결과에서 키와 값을 순회합니다.\\n    for key, value in output.items():\\n        # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\\n        pprint.pprint(f\\\"Output from node '{key}':\\\")\\n        pprint.pprint(\\\"---\\\")\\n        # 출력 값을 예쁘게 출력합니다.\\n        pprint.pprint(value, indent=2, width=80, depth=None)\\n    # 각 출력 사이에 구분선을 추가합니다.\\n    pprint.pprint(\\\"\\\\n---\\\\n\\\")\\n```\\n---CALL AGENT---\\n\\\"Output from node 'agent':\\\"\\n'---'\\n{ 'messages': [ AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}})]}\\n'\\\\n---\\\\n'\\n---DECIDE TO RETRIEVE---\\n---DECISION: RETRIEVE---\\n---EXECUTE RETRIEVAL---\\n\\\"Output from node 'retrieve':\\\"\\n'---'\\n{ 'messages': [ FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts')]}\\n'\\\\n---\\\\n'\\n---CHECK RELEVANCE---\\n---DECISION: DOCS RELEVANT---\\n---GENERATE---\\n\\\"Output from node 'generate':\\\"\\n'---'\\n{ 'messages': [ 'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\n\\\"Output from node '__end__':\\\"\\n'---'\\n{ 'messages': [ HumanMessage(content='What does Lilian Weng say about the types of agent memory?'),\\n                AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\\"query\\\":\\\"types of agent memory\\\"}', 'name': 'retrieve_blog_posts'}}),\\n                FunctionMessage(content='Table of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', name='retrieve_blog_posts'),\\n                'Lilian Weng discusses two types of agent memory: short-term '\\n                'memory, which involves in-context learning and utilizes the '\\n                \\\"model's immediate memory to learn, and long-term memory, \\\"\\n                'which allows an agent to retain and recall information over '\\n                'extended periods, often through the use of an external vector '\\n                'store for fast retrieval.']}\\n'\\\\n---\\\\n'\\nReference\\n본 튜토리얼은 langchain-ai 튜토리얼 노트북 파일을 참조하여 작성하였습니다.\\n본 내용의 저작권은 2024년 테디노트(https://teddylee777.github.io)에 있습니다. 모든 권리는 저작권자에게 있으며, teddylee777@gmail.com으로 문의할 수 있습니다.\\n본 내용의 무단 전재 및 재배포를 금지합니다. 본 내용의 전체 혹은 일부를 인용할 경우, 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\n\\n본 문서의 원 저작권자는 langchain-ai 이며, 코드는 MIT License 에 따라 사용이 허가된 파일입니다.\\n원문 바로가기\\n\\n태그: AI 애플리케이션, langchain, langgraph, openai, python, retrieval agent, 검색 에이전트, 그래프 기반 데이터 처리, 데이터베이스 관리, 문서 검색, 정보 처리\\n카테고리: langgraph\\n업데이트: 2024년 03월 06일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 34 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\nLangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편\\n2024년 02월 06일 22 분 소요\\nLangChain의 RAG 시스템을 통해 문서(PDF, txt, 웹페이지 등)에 대한 질문-답변을 찾는 과정을 정리하였습니다.\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 찾았습니다. 다음 링크들을 통해 LangGraph에 대한 자세한 정보를 얻을 수 있습니다:\n",
      "\n",
      "1. [LangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리](https://teddylee777.github.io/langgraph/langgraph-agentic-rag/) - 이 글에서는 LangGraph와 Retrieval Agent의 통합 과정, 구현 방법, 다양한 사용 예시를 소개합니다. Python 코드를 중심으로 설명되어 있어 실제 구현 방법을 쉽게 이해할 수 있습니다.\n",
      "\n",
      "2. [LangGraph - Multi-Agent Collaboration](https://teddylee777.github.io/langgraph/langgraph-multi-agent-collaboration/) - 이 튜토리얼에서는 LangGraph를 사용하여 복잡한 테스크를 수행하는 다중 에이전트 협업 시스템을 구축하는 방법을 다룹니다. 각기 다른 도메인에 특화된 에이전트들이 협력하여 문제를 해결하는 방법을 설명합니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능 및 활용 방법을 깊이 있게 배울 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림에서 이벤트 수신\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    # 메시지가 있는 경우 마지막 메시지 출력\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이벤트 스트림 생성\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 한국어로 답변해줘! 출처를 반드시 포함해줘!\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "# 메시지 이벤트 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40da8a3c",
   "metadata": {},
   "source": [
    "최종 상태에서 `messages` 의 마지막 메시지를 확인합니다. (이는 곧 최종 응답 메시지입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config).values[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21173667",
   "metadata": {},
   "source": [
    "## 지난 스냅샷의 결과 수정 및 Replay\n",
    "\n",
    "이번에는 지난 스냅샷의 결과를 수정하여 Replay 하는 방법을 살펴보겠습니다.\n",
    "\n",
    "지난 스냅샷을 확인 후 특정 노드로 되돌아가, **상태(State) 를 수정한 뒤 해당 노드부터 다시 진행**합니다.\n",
    "\n",
    "이를 Replay 라고 합니다.\n",
    "\n",
    "먼저 지난 스냅샷의 상태를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eba0794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-db592bae-cf0e-479d-a2eb-5980e5a50649-0\n",
      "메시지 수:  4 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "74af5bfd-7b4c-431b-ad94-cb6541793ad7\n",
      "메시지 수:  3 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-2cf14257-1e97-4e3f-b79f-35371975327b-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-2cf14257-1e97-4e3f-b79f-35371975327b-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "523e51b8-0d97-4b4a-9b70-cd40f479be5a\n",
      "메시지 수:  1 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay_state = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "\n",
    "    messages = state.values[\"messages\"]\n",
    "\n",
    "    if len(messages) > 0:\n",
    "        print(state.values[\"messages\"][-1].id)\n",
    "        # 메시지 수 및 다음 상태 출력\n",
    "        print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "        print(\"-\" * 80)\n",
    "        # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "        if len(state.values[\"messages\"]) == 2:\n",
    "            # 특정 메시지 ID 선택\n",
    "            to_replay_state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cadcca",
   "metadata": {},
   "source": [
    "선택한 메시지의 내용을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0463ea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[93mcontent\u001b[0m: \"\"\n",
      "    \u001b[93madditional_kwargs\u001b[0m:\n",
      "        \u001b[94mtool_calls\u001b[0m:\n",
      "            \u001b[94mindex [0]\u001b[0m\n",
      "                \u001b[92mid\u001b[0m: \"call_yjNEMMqxr2qjHGtGe4podO6U\"\n",
      "                \u001b[92mfunction\u001b[0m: {\"arguments\": \"{\"query\":\"LangGraph 소개 및 자료\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001b[92mtype\u001b[0m: \"function\"\n",
      "        \u001b[94mrefusal\u001b[0m: None\n",
      "    \u001b[93mresponse_metadata\u001b[0m:\n",
      "        \u001b[94mtoken_usage\u001b[0m:\n",
      "            \u001b[95mcompletion_tokens\u001b[0m: 22\n",
      "            \u001b[95mprompt_tokens\u001b[0m: 110\n",
      "            \u001b[95mtotal_tokens\u001b[0m: 132\n",
      "            \u001b[95mcompletion_tokens_details\u001b[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001b[95mprompt_tokens_details\u001b[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001b[94mmodel_name\u001b[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001b[94msystem_fingerprint\u001b[0m: \"fp_b8bc95a0ac\"\n",
      "        \u001b[94mfinish_reason\u001b[0m: \"tool_calls\"\n",
      "        \u001b[94mlogprobs\u001b[0m: None\n",
      "    \u001b[93mtype\u001b[0m: \"ai\"\n",
      "    \u001b[93mname\u001b[0m: None\n",
      "    \u001b[93mid\u001b[0m: \"run-2cf14257-1e97-4e3f-b79f-35371975327b-0\"\n",
      "    \u001b[93mexample\u001b[0m: False\n",
      "    \u001b[93mtool_calls\u001b[0m:\n",
      "        \u001b[93mindex [0]\u001b[0m\n",
      "            \u001b[95mname\u001b[0m: \"tavily_web_search\"\n",
      "            \u001b[95margs\u001b[0m: {\"query\": \"LangGraph 소개 및 자료\"}\n",
      "            \u001b[95mid\u001b[0m: \"call_yjNEMMqxr2qjHGtGe4podO6U\"\n",
      "            \u001b[95mtype\u001b[0m: \"tool_call\"\n",
      "    \u001b[93minvalid_tool_calls\u001b[0m:\n",
      "    \u001b[93musage_metadata\u001b[0m:\n",
      "        \u001b[94minput_tokens\u001b[0m: 110\n",
      "        \u001b[94moutput_tokens\u001b[0m: 22\n",
      "        \u001b[94mtotal_tokens\u001b[0m: 132\n",
      "        \u001b[94minput_token_details\u001b[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001b[94moutput_token_details\u001b[0m: {\"audio\": 0, \"reasoning\": 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 선택한 메시지 가져오기\n",
    "existing_message = to_replay_state.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 출력\n",
    "display_message_tree(existing_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770063e4",
   "metadata": {},
   "source": [
    "검색 쿼리를 업데이트 후 반영이 됐는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dbc1f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph human-in-the-loop workflow site:reddit.com'},\n",
       " 'id': 'call_yjNEMMqxr2qjHGtGe4podO6U',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = existing_message.tool_calls[0].copy()\n",
    "tool_call[\"args\"] = {\"query\": \"LangGraph human-in-the-loop workflow site:reddit.com\"}\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a66f6d",
   "metadata": {},
   "source": [
    "업데이트된 AIMessage 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2656f8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph human-in-the-loop workflow site:reddit.com'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[tool_call],\n",
    "    # 중요! ID는 메시지를 상태에 추가하는 대신 교체하는 방법\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13751a91",
   "metadata": {},
   "source": [
    "아래는 업데이트가 되기 전의 메시지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27eb7447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph 소개 및 자료'},\n",
       "  'id': 'call_yjNEMMqxr2qjHGtGe4podO6U',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트 전 메시지 확인\n",
    "graph.get_state(to_replay_state.config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf5572",
   "metadata": {},
   "source": [
    "`graph` 에 `update_state` 메서드를 사용하여 상태를 업데이트 합니다.\n",
    "\n",
    "업데이트된 상태를 `updated_state` 에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41a6e114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'adfb12',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f008539-5fa7-63cc-8002-e54093c17eb1'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 업데이트\n",
    "updated_state = graph.update_state(\n",
    "    to_replay_state.config,\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "updated_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036c5e4",
   "metadata": {},
   "source": [
    "이제 업데이트된 상태를 스트리밍 합니다. 여기서 입력은 `None` 으로 주어 Replay 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe04786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_yjNEMMqxr2qjHGtGe4podO6U)\n",
      " Call ID: call_yjNEMMqxr2qjHGtGe4podO6U\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Go to LangChain r/LangChain r/LangChain When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? Top Posts Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion Communities Best of Reddit Topics Reddit Rules Privacy Policy User Agreement Reddit, Inc.\", \"score\": 0.65359193, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntisi3000\\nHuman intervention in agent workflows\\nWhen building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g. incoming emails?\\nI guess I'd have to design my UI so that it's not only a simple single-threaded chat interface, but some sort of inbox, right? Or is there any standard way that comes to mind?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 20, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"Reddit - Dive into anything Go to LangChain I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval. Document Submission (Manual User Action): Entry point for examiners to submit documents. Policy Compliance Checker Node (PCCN): Checks documents against policy rules. Quality Assurance Node (QAN): Final review to ensure document quality. Approval and Compliance Marking Node (ACMN): Marks documents as approved. Has anyone automated a Quality Assurance process with langchain/graph? Reddit Reddit Reddit Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.6347929, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\nSwimminInIt\\nLangGraph Workflow for Quality Assurance\\nQuestion | Help\\nI've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\\nI see a ton of people talking about document chat and integration with knowledge repos. Rather than just providing information I am looking to perform QA on the documents itself.\\nHere's a brief overview of the workflow:\\n\\n\\nDocument Submission (Manual User Action): Entry point for examiners to submit documents.\\n\\n\\nPre-Processing Node (Script for Data Manipulation): Handles initial formatting and basic validation.\\n\\n\\nPolicy Compliance Checker Node (PCCN): Checks documents against policy rules.\\n\\n\\nError Suggestion Node (ESN): Identifies compliance issues and suggests corrections.\\n\\n\\nQuality Assurance Node (QAN): Final review to ensure document quality.\\n\\n\\nFeedback and Interaction Node (FIN): Where examiners review AI suggestions and apply corrections.\\n\\n\\nApproval and Compliance Marking Node (ACMN): Marks documents as approved.\\n\\n\\nSome questions I have are:\\n\\n\\nHas anyone automated a Quality Assurance process with langchain/graph?\\n\\n\\nIf yes, what was successful or what did not work?\\n\\n\\nAny suggestions on how to improve my approach?\\n\\n\\nAre there any examples you are aware of I could use as a reference?\\n\\n\\nI appreciate any help and thoughts on the topic!\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of March 31, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of March 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Reddit - Dive into anything Open menu Open navigation  Go to Reddit Home Get App Get the Reddit app Log In Log in to Reddit Go to LangChain r/LangChain r/LangChain I'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. I can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. Reddit Reddit Reddit Action Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion About Reddit Advertise Help Blog Careers*   Press Communities Best of Reddit Topics Reddit, Inc.\", \"score\": 0.20606238, \"raw_content\": \"Reddit - Dive into anything\\nSkip to main content\\nOpen menu Open navigation  Go to Reddit Home\\nr/LangChain A chip A close button\\nGet App Get the Reddit app Log In Log in to Reddit\\nExpand user menu Open settings menu\\n Go to LangChain\\nr/LangChain\\nr/LangChain\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\nMembers Online\\n•\\ntranswarpconduit1\\nTool-calling agents: Human approval before tool invocation?\\nQuestion | Help\\nI'd like to be able to ask for human confirmation before the agent executor invokes a certain tool. For example, let's say I have asend_emailtool, and I'd like to confirm before it is run.\\nDoes the Langchain agent framework provide a way to hook into the lifecycle in order to do this? Ideally, a hook that would run before the invocation, has tool name and arguments passed in, and then you can return True or False (or an *Exception for an error). I could have the email displayed to standard out there, and collect input.\\nIt doesn't seem like callback handlers work, and they weren't intended for that anyway. They are for introspection (like logging, instrumentation, etc.).\\nI can actually put the confirmation logic in the tool function itself and get it to work, but that doesn't seem right. I could create a special wrapper function \\\"add_human_approval(tool_func)\\\" that returns a new function that asks for human approval, and if it passes invokes the passed in func, otherwise returns. Again, that's still at the tool level, instead as part of the lifecycle.\\nThoughts?\\nRead more\\nTop 3% Rank by size\\nPublic\\nAnyone can view, post, and comment to this community\\nTop Posts\\n\\n\\n\\nReddit\\nreReddit: Top posts of May 2, 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of May 2024 * * *\\n\\n\\nReddit\\nreReddit: Top posts of 2024 * * *\\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\nTOPICS\\n\\n\\nInternet Culture (Viral)\\n\\n\\nAmazing Animals & Pets Cringe & Facepalm Funny Interesting Memes Oddly Satisfying Reddit Meta Wholesome & Heartwarming\\n\\n\\nGames\\n\\n\\nAction Games Adventure Games Esports Gaming Consoles & Gear Gaming News & Discussion Mobile Games Other Games Role-Playing Games Simulation Games Sports & Racing Games Strategy Games*   Tabletop Games\\n\\n\\nQ&As\\n\\n\\nQ&As*   Stories & Confessions\\n\\n\\nTechnology\\n\\n\\n3D Printing Artificial Intelligence & Machine Learning Computers & Hardware Consumer Electronics DIY Electronics Programming Software & Apps Streaming Services Tech News & Discussion*   Virtual & Augmented Reality\\n\\n\\nPop Culture\\n\\n\\nCelebrities Creators & Influencers Generations & Nostalgia Podcasts Streamers*   Tarot & Astrology\\n\\n\\nMovies & TV\\n\\n\\nAction Movies & Series Animated Movies & Series Comedy Movies & Series Crime, Mystery, & Thriller Movies & Series Documentary Movies & Series Drama Movies & Series Fantasy Movies & Series Horror Movies & Series Movie News & Discussion Reality TV Romance Movies & Series Sci-Fi Movies & Series Superhero Movies & Series*   TV News & Discussion\\n\\n\\n\\n\\n\\nRESOURCES\\n\\n\\nAbout Reddit Advertise Help Blog Careers*   Press\\n\\n\\n\\n\\nCommunities Best of Reddit Topics\\n\\n\\n\\nReddit Rules Privacy Policy User Agreement\\n\\nReddit, Inc. © 2025. All rights reserved.\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 추천해 드립니다. LangGraph는 LangChain의 일부로, LLM(대형 언어 모델) 워크플로우를 구축하는 데 사용되는 도구입니다.\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)** - 이 Reddit 스레드에서는 LangGraph를 사용하여 LLM 워크플로우에서 인간이 개입할 수 있는 노드를 만드는 방법에 대해 논의합니다. 사용자의 입력을 요구하는 Human-in-the-loop 컴포넌트에 대한 질문과 답변이 포함되어 있습니다.\n",
      "\n",
      "2. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)** - 이 스레드에서는 LangGraph를 사용하여 복잡한 법적 문서의 품질 보증 프로세스를 자동화하는 개념에 대해 설명합니다. 문서 제출에서 최종 승인까지의 워크플로우를 간략히 설명하며, QA 프로세스를 자동화하는 방법에 대한 질문과 피드백을 요청합니다.\n",
      "\n",
      "3. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)** - 이 스레드에서는 특정 도구를 호출하기 전에 인간의 승인을 요구하는 방법에 대한 논의가 이루어집니다. LangChain 에이전트 프레임워크에서 라이프사이클에 후킹하여 이를 구현할 수 있는 방법에 대한 질문이 포함되어 있습니다.\n",
      "\n",
      "이 자료들은 LangGraph의 기능과 사용 방법에 대한 이해를 높이는 데 도움이 될 것입니다. 추가적으로 LangChain 공식 웹사이트인 [LangChain.com](https://www.langchain.com/)도 방문해 보시기 바랍니다.\n"
     ]
    }
   ],
   "source": [
    "# config 에는 updated_state 를 전달합니다. 이는 임의로 갱신한 상태를 전달하는 것입니다.\n",
    "for event in graph.stream(None, updated_state, stream_mode=\"values\"):\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dedf06",
   "metadata": {},
   "source": [
    "최종 결과를 출력합니다.\n",
    "\n",
    "이때 사용하는 `config` 는 최종 상태를 가져오는 것이 아니라, 최종 상태를 가져오기 위한 초기 `config` 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 출력\n",
    "for msg in graph.get_state(config).values[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-h6vp0ZFq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
