{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서는 Chroma 벡터스토어를 시작하는 방법을 다룹니다.\n",
    "\n",
    "Chroma는 개발자의 생산성과 행복에 초점을 맞춘 AI 네이티브 오픈 소스 벡터 데이터베이스입니다. Chroma는 Apache 2.0에 따라 라이선스가 부여됩니다. \n",
    "\n",
    "\n",
    "**참고링크**\n",
    "\n",
    "- [Chroma LangChain 문서](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "- [Chroma 공식문서](https://docs.trychroma.com/getting-started)\n",
    "- [LangChain 지원 VectorStore 리스트](https://python.langchain.com/v0.2/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH06-VectorStores\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH06-VectorStores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 데이터셋을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "\n",
    "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "loader1 = TextLoader(\"data/nlp-keywords.txt\")\n",
    "loader2 = TextLoader(\"data/finance-keywords.txt\")\n",
    "\n",
    "# 문서 분할\n",
    "split_doc1 = loader1.load_and_split(text_splitter)\n",
    "split_doc2 = loader2.load_and_split(text_splitter)\n",
    "\n",
    "# 문서 개수 확인\n",
    "len(split_doc1), len(split_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_doc1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorStore 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 저장소 생성 (from_documents)\n",
    "\n",
    "`from_documents` 클래스 메서드는 문서 리스트로부터 벡터 저장소를 생성합니다. \n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `documents` (List[Document]): 벡터 저장소에 추가할 문서 리스트\n",
    "- `embedding` (Optional[Embeddings]): 임베딩 함수. 기본값은 None\n",
    "- `ids` (Optional[List[str]]): 문서 ID 리스트. 기본값은 None\n",
    "- `collection_name` (str): 생성할 컬렉션 이름.\n",
    "- `persist_directory` (Optional[str]): 컬렉션을 저장할 디렉토리. 기본값은 None\n",
    "- `client_settings` (Optional[chromadb.config.Settings]): Chroma 클라이언트 설정\n",
    "- `client` (Optional[chromadb.Client]): Chroma 클라이언트 인스턴스\n",
    "- `collection_metadata` (Optional[Dict]): 컬렉션 구성 정보. 기본값은 None\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `persist_directory`가 지정되면 컬렉션이 해당 디렉토리에 저장됩니다. 지정되지 않으면 데이터는 메모리에 임시로 저장됩니다.\n",
    "- 이 메서드는 내부적으로 `from_texts` 메서드를 호출하여 벡터 저장소를 생성합니다.\n",
    "- 문서의 `page_content`는 텍스트로, `metadata`는 메타데이터로 사용됩니다.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- `Chroma`: 생성된 Chroma 벡터 저장소 인스턴스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성시 `documents` 매개변수로 `Document` 리스트를 전달합니다. embedding 에 활용할 임베딩 모델을 지정하며, `namespace` 의 역할을 하는 `collection_name` 을 지정할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 생성\n",
    "db = Chroma.from_documents(\n",
    "    documents=split_doc1, embedding=OpenAIEmbeddings(), collection_name=\"my_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`persist_directory` 지정시 disk 에 파일 형태로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장할 경로 지정\n",
    "DB_PATH = \"./chroma_db\"\n",
    "\n",
    "# 문서를 디스크에 저장합니다. 저장시 persist_directory에 저장할 경로를 지정합니다.\n",
    "persist_db = Chroma.from_documents(\n",
    "    split_doc1, OpenAIEmbeddings(), persist_directory=DB_PATH, collection_name=\"my_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드를 실행하여 `DB_PATH` 에 저장된 데이터를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디스크에서 문서를 로드합니다.\n",
    "persist_db = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    collection_name=\"my_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 VectorStore 에서 저장된 데이터를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['0ffaa06e-6053-4b55-83ae-e20a85d2e6ac',\n",
       "  '1fbb35d8-5483-4327-8e1d-f3befb13f295',\n",
       "  '2d43dc9e-5e6c-45dc-a2a7-ab3b801aa91a',\n",
       "  '2d6807ea-b372-4422-beff-ef2dcfc7d24b',\n",
       "  '34f1bda0-f453-4306-ba9f-da3b93017958',\n",
       "  '375b821d-547d-4977-991a-862a3b4f2897',\n",
       "  '3c955d81-5d31-47e3-8695-e036da25d1f3',\n",
       "  '467657e5-ad16-4e31-b0b1-fd957913cef8',\n",
       "  '5285be1a-a40b-41ae-9299-cd9920a0dce6',\n",
       "  '69f843ac-10ec-4d03-95db-b07852209310',\n",
       "  '73b8e67f-92eb-419e-8d12-7452c4acbfd7',\n",
       "  '7b1e36fe-ba61-4eba-966c-fab72bc27974',\n",
       "  '912b0af5-0d27-414f-a113-3b79192661e0',\n",
       "  '91389e2d-55ca-4da9-8417-401b82c2d2df',\n",
       "  '940f5a7b-61b2-46f6-bf16-d07468d2cb37',\n",
       "  '94d4ea17-cedd-4b44-b5e2-f13529730f75',\n",
       "  'c0d36882-c915-4d42-b598-f388d874ff7c',\n",
       "  'd0a21290-1335-44b8-b8fa-b6ab14f12f6d',\n",
       "  'd9359348-5830-471f-9bee-8b442f409cee',\n",
       "  'e9329f03-601f-42ad-952f-dc0960abd272',\n",
       "  'ede9c083-b135-467a-a301-9a9d6f07780a',\n",
       "  'ff85ce15-cd6e-4b1d-b949-8270e5607260'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'},\n",
       "  {'source': 'data/nlp-keywords.txt'}],\n",
       " 'documents': ['정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV',\n",
       "  '정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec',\n",
       "  '정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source',\n",
       "  '정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace',\n",
       "  '정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)',\n",
       "  '정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace',\n",
       "  '정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)',\n",
       "  '정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec',\n",
       "  \"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\",\n",
       "  'Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer',\n",
       "  'Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer',\n",
       "  \"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\",\n",
       "  '정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝',\n",
       "  '정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame',\n",
       "  '정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)',\n",
       "  '정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)',\n",
       "  'GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search',\n",
       "  '정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source',\n",
       "  'GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search',\n",
       "  '정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝',\n",
       "  '정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV',\n",
       "  '정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 데이터 확인\n",
    "persist_db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 `collection_name` 을 다르게 지정하면 저장된 데이터가 없기 때문에 아무런 결과도 얻지 못합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디스크에서 문서를 로드합니다.\n",
    "persist_db2 = Chroma(\n",
    "    persist_directory=DB_PATH,\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    collection_name=\"my_db2\",\n",
    ")\n",
    "\n",
    "# 저장된 데이터 확인\n",
    "persist_db2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 저장소 생성 (from_texts)\n",
    "\n",
    "`from_texts` 클래스 메서드는 텍스트 리스트로부터 벡터 저장소를 생성합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `texts` (List[str]): 컬렉션에 추가할 텍스트 리스트\n",
    "- `embedding` (Optional[Embeddings]): 임베딩 함수. 기본값은 None\n",
    "- `metadatas` (Optional[List[dict]]): 메타데이터 리스트. 기본값은 None\n",
    "- `ids` (Optional[List[str]]): 문서 ID 리스트. 기본값은 None\n",
    "- `collection_name` (str): 생성할 컬렉션 이름. 기본값은 '_LANGCHAIN_DEFAULT_COLLECTION_NAME'\n",
    "- `persist_directory` (Optional[str]): 컬렉션을 저장할 디렉토리. 기본값은 None\n",
    "- `client_settings` (Optional[chromadb.config.Settings]): Chroma 클라이언트 설정\n",
    "- `client` (Optional[chromadb.Client]): Chroma 클라이언트 인스턴스\n",
    "- `collection_metadata` (Optional[Dict]): 컬렉션 구성 정보. 기본값은 None\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `persist_directory`가 지정되면 컬렉션이 해당 디렉토리에 저장됩니다. 지정되지 않으면 데이터는 메모리에 임시로 저장됩니다.\n",
    "- `ids`가 제공되지 않으면 UUID를 사용하여 자동으로 생성됩니다.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- 생성된 벡터 저장소 인스턴스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열 리스트로 생성\n",
    "db2 = Chroma.from_texts(\n",
    "    [\"안녕하세요. 정말 반갑습니다.\", \"제 이름은 테디입니다.\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['5dee2e22-6303-4403-83df-44e721956b2b',\n",
       "  '9750d208-c048-4a3a-be3b-fc83d1072e4d'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [None, None],\n",
       " 'documents': ['제 이름은 테디입니다.', '안녕하세요. 정말 반갑습니다.'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 조회합니다.\n",
    "db2.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 된 벡터, 문서 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 정말 반갑습니다.\n"
     ]
    }
   ],
   "source": [
    "collection = db2._collection\n",
    "results = collection.get(include=['embeddings', 'documents'])  # include 파라미터 사용\n",
    "# embeddings = results[\"embeddings\"]\n",
    "\n",
    "print(results[\"documents\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.008529899641871452, -0.021671237424016, -0.022931192070245743, -0.017714975401759148, -0.0017292890697717667, 0.025955086573958397, -0.01232236623764038, 0.007824324071407318, -0.012964943423867226, 0.025652697309851646, -0.01049542985856533, -0.0053737107664346695, -0.024367541074752808, -0.027971014380455017, -0.016077034175395966, -0.01593843847513199, 0.02398955449461937, -0.006545469630509615, 0.007729827892035246, -0.011686088517308235, 0.006671465002000332, -0.015069069340825081, 0.009745757095515728, -0.014829677529633045, 0.0037389183416962624, 0.01009854394942522, 0.010010347701609135, -0.01794176734983921, 0.01824415661394596, -0.017840972170233727, 0.009115778841078281, 0.017916569486260414, -0.006923456210643053, -0.004668135661631823, -0.00039983904571272433, -0.010665524750947952, -0.0013780765002593398, -0.014061104506254196, 0.0012410562485456467, -0.004438193514943123, 0.009361470118165016, -0.025425903499126434, 0.018937133252620697, 0.0011945954756811261, 0.006576968356966972, 0.021759433671832085, -0.002086801454424858, -0.024695130065083504, -0.00010975394980050623, 0.034825172275304794, 0.022729599848389626, -0.009355170652270317, -0.013443726114928722, -0.026257475838065147, 0.006397424731403589, 0.007024252787232399, -0.0141871003434062, 0.02417854778468609, 0.005146918818354607, -0.028097011148929596, 0.010199340991675854, -0.009821354411542416, -0.014023305848240852, 0.008838588371872902, -0.013645319268107414, -0.014754080213606358, 0.012479860335588455, -0.022074421867728233, -0.03270844742655754, -0.0011473470367491245, -0.002557709813117981, 0.030616922304034233, -0.002639607060700655, -0.016253426671028137, 0.03747107833623886, 0.00872519239783287, 0.004466542508453131, 0.013531923294067383, -0.0378238670527935, -0.016820408403873444, 0.010778920724987984, -0.009115778841078281, 0.009115778841078281, 0.010041845962405205, 0.021923227235674858, 0.006803760305047035, -0.016618814319372177, -0.0032538354862481356, -0.02343517541885376, -0.023057186976075172, 0.017840972170233727, 0.016555815935134888, -0.00018771369650494307, 0.02532510831952095, -0.01854654587805271, 0.010627726092934608, 0.01976870372891426, 0.025955086573958397, 0.0068289595656096935, -0.006835259031504393, -0.006702963728457689, -0.028474997729063034, -0.008259008638560772, 3.6272940633352846e-05, -0.0396886020898819, -0.009159876964986324, 0.012952343560755253, -0.03154928982257843, 0.02527470886707306, -0.008580298162996769, -0.003464877838268876, 0.02301938831806183, -0.016820408403873444, -0.03880663216114044, -0.0029183721635490656, 0.020713670179247856, 0.019113527610898018, -0.011893981136381626, -0.003805065993219614, -0.015006070956587791, -0.001048125559464097, 0.01837015338242054, 0.016770008951425552, -0.025098316371440887, 0.010130043141543865, -0.019617509096860886, -0.022200418636202812, -0.020827066153287888, -0.004101155325770378, 0.002086801454424858, 0.051355790346860886, -5.027518272981979e-05, 0.029155373573303223, -0.005981639493256807, -0.007912521250545979, 0.0022411460522562265, -0.023157984018325806, 0.013947708532214165, -0.02385096065700054, -0.014804478734731674, 0.0015103718033060431, 0.011635689996182919, -0.01556045189499855, -0.027693824842572212, 0.013783914037048817, 0.0027608778327703476, 0.04361966252326965, -0.0018348103621974587, 0.020713670179247856, -0.000166944126249291, -0.00283805001527071, 0.00019421034085098654, 0.011333300732076168, -0.0011394723551347852, 0.020978260785341263, 0.02063807286322117, 0.014313096180558205, 0.010634025558829308, -0.024304544553160667, -0.0052729141898453236, -0.0005102819995954633, -0.005461907479912043, 0.01671961136162281, -0.015409257262945175, 0.00012668459385167807, 0.03318722918629646, -0.021469643339514732, 0.019239522516727448, 0.0019560810178518295, -0.011938079260289669, -2.7340052838553675e-05, 0.006057236809283495, -0.009550463408231735, 0.0018789088353514671, -0.02281779609620571, -0.0004827204975299537, 0.004813030362129211, 0.004431894049048424, -0.008794490247964859, -0.02368716523051262, -0.0433172732591629, 0.0071439482271671295, 0.017236193642020226, 0.015636049211025238, 0.008926785551011562, 0.0271646436303854, 0.02678665705025196, -0.0006732887704856694, 0.0011213604593649507, -0.006728162989020348, 0.022754797711968422, 0.021217653527855873, 0.008000718429684639, -0.026156678795814514, -0.6277602910995483, -0.024606933817267418, 0.02375016361474991, 0.03248165547847748, 0.011805783957242966, -0.0030569673981517553, 0.004945325665175915, 0.034144796431064606, -0.015207664109766483, 0.032506853342056274, 0.0022694950457662344, -0.0030758667271584272, -0.023107586428523064, 0.0008796065230853856, 0.0018773338524624705, -0.014199700206518173, -0.003553074784576893, 0.011087609454989433, -0.003329432802274823, 0.009052781388163567, 0.0036192224361002445, 0.01282004825770855, -0.021318448707461357, 0.0031215399503707886, 0.015270662494003773, 0.00483822962269187, 0.010142643004655838, 0.009040181525051594, -0.032809242606163025, 0.05301893129944801, -0.031272098422050476, 0.012460961006581783, 0.010904915630817413, -0.004041307605803013, 0.05241415277123451, -0.006507670972496271, -0.007099850103259087, 0.02708904631435871, 0.015673847869038582, 0.055690038949251175, -0.013909909874200821, -0.02178463339805603, 0.001648966921493411, -0.03532915562391281, 0.005288663785904646, -0.00718804681673646, -0.016757410019636154, 0.0075156353414058685, -0.01232236623764038, 0.0005236690631136298, -0.01653061807155609, 0.0013883135979995131, 0.0323304608464241, 0.015182465314865112, -0.004126354586333036, -0.0008803940145298839, 0.011585291475057602, -0.016026634722948074, 0.008151913061738014, 0.031171301379799843, 0.015144666656851768, 0.026207076385617256, -0.013771315105259418, -0.01016154233366251, -0.03429599106311798, 0.0271646436303854, -0.03021373599767685, -0.008662194944918156, -0.021709036082029343, -0.022502807900309563, 0.008013317361474037, -0.016996800899505615, -0.0016788908978924155, 0.015333659946918488, -0.01782837137579918, 0.017349589616060257, 0.027794620022177696, 0.005168967880308628, -0.009336271323263645, 0.00558475311845541, 0.0068730576895177364, 0.012120773084461689, -0.0030931909568607807, 0.006822659634053707, 0.016644014045596123, -0.014149301685392857, -0.021205052733421326, -0.01574944518506527, -0.012656253762543201, -0.01016154233366251, 0.02191062830388546, 0.008044816553592682, 0.005310712847858667, -0.019252121448516846, -0.005335912108421326, 0.021620837971568108, 0.0013465775409713387, 0.008794490247964859, 0.011679788120090961, 0.007043152116239071, -0.0017844121903181076, 0.011641989462077618, 0.03989019617438316, -0.012259367853403091, 0.0029908197466284037, 0.0015056469710543752, -0.037874266505241394, -0.010791519656777382, 0.034270793199539185, -0.010451331734657288, 0.025526700541377068, 0.004998873919248581, -0.0008488951134495437, 0.0201340913772583, 0.004731133114546537, -0.02319578267633915, -0.017966967076063156, 0.037798669189214706, -0.006331277079880238, -0.001165458932518959, 0.018785938620567322, -0.005609952379018068, 0.014124102890491486, 0.008674794808030128, 0.0034270791802555323, 0.013708316721022129, -0.006107634864747524, -0.025073116645216942, -0.020701071247458458, -0.012259367853403091, -0.01416190154850483, -0.028349000960588455, 0.006006838288158178, -0.02136884815990925, -0.00019932891882490367, -0.0024112400133162737, 0.011975877918303013, -0.021532641723752022, 0.0201340913772583, 0.0008622821187600493, -0.015094268135726452, -0.002123025245964527, 0.011339600197970867, 0.016883404925465584, 0.005071321502327919, 0.0016158930957317352, -0.01641722209751606, 0.009644960053265095, 0.01369571778923273, 0.0244179405272007, 0.00034806274925358593, 0.029709752649068832, 0.010489130392670631, -0.0011024611303582788, 0.02094046212732792, 0.012467260472476482, -0.0034365288447588682, -0.01489267498254776, -0.005635151639580727, -0.005320162512362003, 0.027240240946412086, 0.024317143484950066, -0.021381447091698647, -0.0050020236521959305, 0.017664577811956406, -0.06753361970186234, -0.0030931909568607807, 0.006810060236603022, -0.018697740510106087, -0.02245240844786167, -0.008958284743130207, -0.013015341944992542, -0.012215269729495049, -0.006784860976040363, 0.013342930004000664, -0.002560859778895974, 0.004101155325770378, -0.003997209016233683, -0.011572692543268204, -0.004945325665175915, 0.010999412275850773, -0.006759661715477705, -0.017500784248113632, 0.026988249272108078, 0.04956665262579918, 0.0167826097458601, 0.005357961170375347, 0.015132066793739796, -0.020335683599114418, 0.02600548416376114, 0.020096292719244957, 0.028575792908668518, -0.0244179405272007, -0.019302520900964737, -0.006312377750873566, -0.011320700868964195, 0.007981819100677967, 0.010363134555518627, 0.01770237646996975, 0.033842407166957855, 0.01811816170811653, -0.0026002333033829927, 0.040016189217567444, 0.01126400288194418, -0.0019230073085054755, -0.0019293070072308183, 0.0017844121903181076, -0.03638751804828644, 0.02191062830388546, -0.00042326634866185486, -0.004535840358585119, 0.0010142643004655838, 0.004526390694081783, 0.00234981719404459, 0.0006803760188631713, 0.021948426961898804, -0.02453133650124073, 0.010331636294722557, -0.024065151810646057, 0.015900639817118645, 0.0047122337855398655, 0.012794849462807178, -0.022439809516072273, -0.016694411635398865, -0.01183728314936161, -0.005342212039977312, 0.014804478734731674, 0.0317256823182106, 0.0071439482271671295, 0.0020427030976861715, -0.027819819748401642, 0.0036507213953882456, -0.003927911631762981, 0.02136884815990925, -0.005134318955242634, -0.015333659946918488, 0.036891501396894455, -0.020008094608783722, 0.017916569486260414, 0.005345361772924662, -0.0007803849875926971, 0.014917874708771706, 0.0012048325734212995, -0.012064075097441673, 0.013481524772942066, 0.019819101318717003, 0.002675830852240324, 0.0014961973065510392, -0.002916797297075391, 0.028424598276615143, -0.03137289360165596, 0.012158571742475033, 0.0256274975836277, -0.017425186932086945, 0.0032239113934338093, -0.03752147778868675, 0.0173873882740736, 0.01321693416684866, 0.028474997729063034, 0.030717717483639717, 0.0020127790048718452, 0.002852224512025714, 0.010665524750947952, -0.002337217563763261, 0.02068847045302391, 0.0040098088793456554, 0.018634743988513947, -0.03434639051556587, -0.00891418568789959, 0.011623090133070946, -0.019806502386927605, -0.026811854913830757, -0.0021734235342592, -0.03900822624564171, -0.012404263019561768, -0.019982896745204926, 0.023447774350643158, -0.036463115364313126, 0.014287896454334259, -0.015094268135726452, -0.0028852983377873898, -0.03248165547847748, -0.011793185025453568, 0.009607161395251751, 0.009298472665250301, -0.03553074970841408, -0.01516986545175314, -0.013116138055920601, -0.016014035791158676, 0.0060509368777275085, -0.0036475714296102524, 0.01300274208188057, -0.0012426312314346433, 0.013859511353075504, -0.02222561649978161, -0.026660660281777382, 0.03338882327079773, -0.006709263660013676, 0.0024206896778196096, 0.023825760930776596, 0.019453715533018112, 0.012914544902741909, 0.0017891370225697756, -0.021822432056069374, -0.017475584521889687, 0.02538810484111309, -0.008340906351804733, -0.019138725474476814, 0.003949960693717003, -0.01568644680082798, -0.024921922013163567, -0.0015308461152017117, -0.0396886020898819, -0.018760738894343376, -0.012914544902741909, 0.01241686288267374, -0.01630382612347603, -0.014842277392745018, 0.016442419961094856, 0.0027656026650220156, -0.009531564079225063, 4.129307490075007e-05, -0.013720916584134102, -0.00616118311882019, 0.05150698497891426, -0.02338477596640587, -0.00537056103348732, -0.018407952040433884, -0.0029010477010160685, 0.010904915630817413, -0.01824415661394596, -0.025526700541377068, -0.012089273892343044, -0.02648426778614521, 0.002392340684309602, -0.0033703811932355165, -0.0024474638048559427, 0.016455020755529404, 0.034623581916093826, -0.011900280602276325, 0.028097011148929596, -0.005890292581170797, 0.00979615468531847, 0.02221301756799221, -0.008000718429684639, -0.010690723545849323, 0.006923456210643053, 0.0120514752343297, 0.00037365558091551065, 0.026937851682305336, 0.0013961882796138525, -0.010514329187572002, 0.023523371666669846, -0.02484632469713688, -0.016492819413542747, -0.010602526366710663, -0.004979974590241909, -0.010961613617837429, -0.00372316874563694, 0.06083065643906593, -0.019919898360967636, 0.011018311604857445, 0.0015710071893408895, 0.017551181837916374, 0.04248570278286934, 0.027492230758070946, 0.008870087563991547, -0.0036885200534015894, -0.015132066793739796, -0.005269764456897974, -0.00811411440372467, 0.006501371040940285, -0.018521348014473915, -0.024808526039123535, 0.030012141913175583, -0.007553433999419212, -0.028953779488801956, -0.0011111233616247773, 0.014237498864531517, -0.009821354411542416, -0.007389639504253864, -0.0018584345234557986, -0.00665256567299366, 0.02294379100203514, 0.015321060083806515, -0.0396634042263031, -0.013569721952080727, -0.018155960366129875, -0.021822432056069374, -0.01579984277486801, -0.013531923294067383, -0.016921203583478928, -0.012977543286979198, -0.003587723709642887, -0.012089273892343044, -0.011131707578897476, -0.009260674007236958, 0.00425864988937974, 0.007944020442664623, 0.030465727671980858, 0.018823737278580666, -0.010577327571809292, 0.004567339085042477, 0.01965530775487423, -0.012643654830753803, -0.012750750407576561, 0.025904687121510506, -0.022175218909978867, -0.009046480990946293, 0.01879853755235672, -0.010791519656777382, 0.005244565196335316, -0.024266745895147324, 0.02759302780032158, 0.028349000960588455, 0.021192453801631927, 0.015081669203937054, -0.018659941852092743, 0.006627366412431002, -0.021217653527855873, -0.0025356607511639595, 0.010684424079954624, -0.007679429370909929, 0.00602573761716485, 0.02216261997818947, -0.0222760159522295, 0.009103178977966309, -0.011459296569228172, -0.004671285394579172, 0.023107586428523064, -0.007710928563028574, 0.018584344536066055, -0.00851100031286478, 0.01697160303592682, 0.012807448394596577, -0.015283261425793171, 0.010413533076643944, -0.022842995822429657, 0.02123025245964527, 0.01665661297738552, 0.005071321502327919, 0.016152631491422653, -1.0470920642546844e-05, -0.009941049851477146, -0.021885428577661514, -0.028172608464956284, 0.0241029504686594, 0.01848354935646057, 0.007043152116239071, 0.010533228516578674, -0.02635827101767063, -0.008460601791739464, 0.0024868373293429613, -0.011503394693136215, -0.0010851367842406034, -0.0010536379413679242, -0.011604190804064274, -0.011402598582208157, 0.012190070934593678, 0.006428923457860947, -0.019012730568647385, 0.0082401093095541, -0.00630292808637023, -0.040620967745780945, -0.018571745604276657, -0.034321192651987076, -0.01272555161267519, -0.012278267182409763, -0.03449758514761925, -0.0256400965154171, -0.024241546168923378, 0.016329023987054825, -0.013985507190227509, 0.0283742006868124, 0.015421857126057148, 0.016077034175395966, -0.024090351536870003, -4.168681334704161e-05, 0.008416503667831421, -0.02489672228693962, -0.012120773084461689, 0.006312377750873566, 0.046593159437179565, 0.022666601464152336, 0.01556045189499855, 0.002398640615865588, 0.009878052398562431, -0.0010473381262272596, 0.0017592130461707711, 0.005792645737528801, -0.023120185360312462, -0.00034491284168325365, -0.034825172275304794, 0.006986454129219055, 0.0015332085313275456, 0.0016017185989767313, 0.02295639179646969, 0.002357691992074251, 0.0018111862009391189, 0.01811816170811653, 0.0009937899885699153, -0.012095574289560318, -0.0037893166299909353, -0.008744091726839542, 0.007887322455644608, -0.02362416870892048, 0.0006791948108002543, -0.004053907003253698, -0.006444673053920269, -0.015207664109766483, 0.008863788098096848, -0.0032821844797581434, 0.019516712054610252, 0.0039058623369783163, 0.021671237424016, -0.028651390224695206, 0.01459028571844101, 0.020726269111037254, -0.0038617639802396297, -0.02283039502799511, -0.0141871003434062, 0.0011371099390089512, -0.017551181837916374, -0.00621158117428422, 0.010715922340750694, 0.014854876324534416, -0.0022316963877528906, -0.01232236623764038, -0.010016647167503834, 0.025904687121510506, -0.015951037406921387, -0.021507441997528076, 0.004044457338750362, -0.011830983683466911, -0.03303603455424309, -0.007918820716440678, -0.006980154197663069, -0.026333073154091835, -0.0029876697808504105, -0.002308868570253253, -0.01641722209751606, 0.021935828030109406, -0.017954368144273758, -0.004872878547757864, -0.018899334594607353, 0.007282543461769819, 0.01959230937063694, -0.0075975325889885426, 0.017009401693940163, 0.00607298593968153, -0.006009988486766815, -0.012794849462807178, -0.014149301685392857, 0.01125770341604948, 0.00465553579851985, 0.018357552587985992, 0.004957925528287888, -0.0317256823182106, -0.01581244356930256, -0.006671465002000332, 0.003883813275024295, -0.00713764876127243, -0.01843314990401268, 0.021028658375144005, 0.007150248158723116, -0.0025451104156672955, 0.0038680636789649725, 0.0186221431940794, -0.04120054841041565, 0.024065151810646057, -0.009506365284323692, -0.0051847174763679504, -0.025955086573958397, -0.01983170211315155, 0.007761326618492603, 0.011522294022142887, -0.009550463408231735, 0.02367456629872322, 0.01818116009235382, -0.019617509096860886, -0.010886016301810741, -0.0038712136447429657, -0.015056469477713108, 0.01232866570353508, -0.014413892291486263, 0.02294379100203514, -0.02557709813117981, 0.020285286009311676, -0.0013418527087196708, 0.007818024605512619, -0.027416633442044258, -0.0012843672884628177, -0.003694819752126932, 0.02850019559264183, -0.002658506389707327, 0.003578274045139551, 0.004649236332625151, 0.017135396599769592, 0.004734283313155174, 0.022364212200045586, -0.002552984980866313, -0.006885657552629709, -0.011704987846314907, -0.02434234321117401, 0.003823965322226286, 0.005228815600275993, 0.008920486085116863, -0.007899921387434006, -0.017538582906126976, -0.014943073503673077, -0.047273535281419754, -0.007219545543193817, 0.0059690396301448345, 0.024606933817267418, -0.022490207105875015, -0.014779279008507729, -0.011383699253201485, 0.013405927456915379, 0.010665524750947952, -0.013418527320027351, 0.01616523042321205, 0.002534085651859641, -0.02056247554719448, 0.014577686786651611, -0.022868193686008453, 0.029508160427212715, -0.0007583358092233539, 0.017173195257782936, 0.009802455082535744, -0.02325878106057644, 0.015031270682811737, -0.01787877082824707, -0.04142734035849571, -0.009468566626310349, -0.0017481883987784386, -0.001103248680010438, -0.008498400449752808, -0.012624755501747131, 0.02887818217277527, 0.020474279299378395, 0.0141871003434062, -0.016770008951425552, -0.032305262982845306, 0.023208381608128548, -0.03107050620019436, 0.03361561521887779, 0.007024252787232399, -0.002174998400732875, -0.03026413358747959, 0.0011441971873864532, -0.003486927133053541, -0.0022411460522562265, -0.01659361459314823, -0.010445032268762589, 0.017664577811956406, 0.012549158185720444, 0.0012024701572954655, -0.023649366572499275, 0.00310579058714211, -0.04230931028723717, -0.0256400965154171, 0.025854289531707764, 0.014476889744400978, -0.026282673701643944, 0.022540606558322906, 0.03331322595477104, -9.493962716078386e-05, 0.030969709157943726, 0.014111503027379513, -0.01224046852439642, -0.018899334594607353, -0.0378238670527935, -0.005638301372528076, -0.0036601710598915815, 0.002652206690981984, 0.040923357009887695, 0.017122797667980194, -0.018836336210370064, -0.03626152127981186, 0.00612023426219821, -0.01825675740838051, 0.016215628013014793, -0.0017450385494157672, 0.015220263972878456, -0.0012985417852178216, 0.0029246718622744083, 0.011163206771016121, 0.027618227526545525, -0.0005677674780599773, 0.03192727640271187, -0.012139672413468361, -0.023220982402563095, 0.021129455417394638, -0.0010851367842406034, -6.102909901528619e-05, -0.005033522844314575, -0.02049947716295719, -0.033111631870269775, -0.0011252978583797812, 0.008397604338824749, -0.01916392520070076, 0.032254863530397415, -0.003754667704924941, -0.013922509737312794, 0.008378705009818077, -0.002318318234756589, -0.009966248646378517, 0.008926785551011562, 0.030742917209863663, 0.0029813700821250677, -0.008070015348494053, 0.01787877082824707, -0.010602526366710663, -0.011711287312209606, 0.0029923946131020784, 0.02983574941754341, -0.009304772131145, 0.010665524750947952, 0.001653691753745079, -0.017777973785996437, 0.04399764910340309, -0.010892316699028015, 0.011641989462077618, 0.0037074193824082613, -0.005694999359548092, 0.017286591231822968, -0.0097646564245224, -0.011188405565917492, -0.009361470118165016, -0.005087070632725954, -0.0032727348152548075, 0.009437067434191704, 0.02222561649978161, -0.01855914667248726, -0.003527875756844878, -0.00967645924538374, 0.009374069981276989, -0.03348962217569351, 0.005855643656104803, -0.005052422173321247, 0.004233451094478369, -0.028978979215025902, 0.02673625759780407, 0.006243079900741577, -0.008996083401143551, -0.005685549695044756, -0.00851729977875948, -0.007099850103259087, 0.006419473793357611, -0.03258245065808296, 0.003852314315736294, -0.015182465314865112, 0.0040003592148423195, 0.052212562412023544, -0.010728522203862667, -0.01241686288267374, 0.014943073503673077, -0.023334378376603127, 0.011112808249890804, 0.011345900595188141, 0.2544102370738983, -0.018886733800172806, -0.010552127845585346, 0.021696435287594795, 0.006353326141834259, 0.014237498864531517, -0.003108940552920103, -0.0034333791118115187, 0.0031309896148741245, 0.03726948797702789, -0.008536199107766151, -3.836466567008756e-05, -0.010829318314790726, -0.006019438151270151, 0.005033522844314575, -0.009663859382271767, -0.03069251962006092, -0.003915312234312296, -0.014451690949499607, -0.010697023011744022, -0.008983483538031578, -0.004142104182392359, -0.01281374879181385, -0.00011615215771598741, 0.010967914015054703, 0.0048949276097118855, -0.031952474266290665, 0.0066651650704443455, 0.006032037548720837, -0.013998107053339481, -0.025614896789193153, -0.001787562039680779, 0.009619761258363724, -0.002562434645369649, 0.00478783156722784, -0.023397374898195267, 0.022112220525741577, 0.012681453488767147, 0.03187687695026398, 0.029256168752908707, 0.005134318955242634, 0.011900280602276325, -0.006419473793357611, -0.016429821029305458, -0.002787651726976037, -0.009323671460151672, -0.00832830648869276, -0.011490794830024242, -0.0125113595277071, 0.01806776411831379, -0.01819375902414322, -0.016618814319372177, 0.015321060083806515, 0.06571928411722183, 0.0019230073085054755, 0.00532646244391799, 0.0006039912113919854, -0.021154655143618584, -0.019327718764543533, 0.00514061888679862, -0.0001629083271836862, 0.03039013035595417, -0.012347565032541752, 0.03820185363292694, -0.021381447091698647, 0.011081309989094734, -0.02490932308137417, 0.023951755836606026, -0.00023683228937443346, -0.024821124970912933, -0.013153936713933945, -0.0075345346704125404, -0.002118300413712859, -0.018874134868383408, -0.03099490888416767, -0.026711059734225273, 0.028978979215025902, -0.00016674725338816643, 0.0323304608464241, 0.049213867634534836, -0.005893442314118147, 0.0011898706434294581, 0.011994777247309685, -0.004447643179446459, -0.02613147906959057, -0.03578273952007294, 0.007962919771671295, 0.014527288265526295, -0.04314088076353073, -0.024254145100712776, 0.002036403166130185, -0.014212299138307571, -0.014476889744400978, -0.01630382612347603, 0.01223416905850172, 0.020108891651034355, 0.006507670972496271, 0.003543625120073557, -0.020461678504943848, 0.012977543286979198, -0.005380010697990656, -0.007080950774252415, -0.02068847045302391, 0.01897493191063404, -0.004110604990273714, 0.006265129428356886, 0.004138953983783722, 0.005830444395542145, 0.03258245065808296, -0.0019277321407571435, -0.021520042791962624, -0.007521934807300568, 0.025047916918992996, 0.006778561044484377, 0.027971014380455017, -0.004422444384545088, 0.008435402996838093, -0.003754667704924941, 0.012649954296648502, -0.01733698882162571, -0.009821354411542416, -0.01891193352639675, 0.01397290825843811, 0.009922150522470474, 0.021494843065738678, -0.021772032603621483, -0.015333659946918488, -0.009229174815118313, 0.017966967076063156, -0.038428645581007004, 0.021570440381765366, -0.033968403935432434, 0.03734508529305458, -0.02592988684773445, -0.012196370400488377, 0.005420959088951349, 0.006463572382926941, 0.018634743988513947, -0.014577686786651611, -0.007660530041903257, 0.005332762375473976, 0.019264722242951393, 0.011742786504328251, -0.014426492154598236, -0.018105562776327133, -0.019756104797124863, 0.02648426778614521, -0.020713670179247856, -0.012555457651615143, 0.01019304059445858, -0.025740893557667732, -0.0006606891984120011, -0.015144666656851768, -0.010571027174592018, 0.030868912115693092, -0.01351932343095541, -0.03742068260908127, -0.035253558307886124, -0.017059799283742905, 0.02832380309700966, -0.04462762922048569, 0.003924761898815632, 0.04722313582897186, -0.023649366572499275, -0.01964270882308483, -0.007868423126637936, -0.15734325349330902, 0.028223006054759026, 0.0086936941370368, -0.02759302780032158, 0.036110326647758484, 0.014880076050758362, 0.023397374898195267, 0.002332492731511593, -0.016492819413542747, 0.02130584977567196, 0.03197767212986946, -0.019604910165071487, -0.013153936713933945, -0.0013922509970143437, 0.013040540739893913, -0.010589927434921265, -0.017979566007852554, -0.02057507447898388, 0.03021373599767685, 0.00354677508585155, 0.021444445475935936, -0.027618227526545525, 0.017916569486260414, 0.022628802806138992, -0.0011764835799112916, 0.0015135216526687145, 0.0004126354760956019, 0.0025073117576539516, -0.02807181142270565, -0.010413533076643944, -0.00839130487293005, 0.002845924813300371, 0.013191735371947289, 0.001181995845399797, 0.041099753230810165, 0.010274938307702541, -0.016933804377913475, 0.0032790345139801502, -0.0222760159522295, 0.011213605292141438, 0.009878052398562431, 0.010583627037703991, 0.00830310769379139, -0.012681453488767147, -0.025010118260979652, -0.0034680278040468693, 0.0037168690469115973, 0.03258245065808296, 0.011119108647108078, -0.0036822203546762466, -7.313648529816419e-05, -0.017538582906126976, 0.00839130487293005, 0.009191376157104969, 0.016492819413542747, 0.02953336015343666, -0.008706293068826199, 0.006564368959516287, 0.0016930653946474195, 0.0026978799141943455, -0.006734462920576334, 0.002184448065236211, 0.005361111368983984, 0.018634743988513947, 0.015774644911289215, 0.01592583954334259, -0.012656253762543201, 0.007899921387434006, -0.029331766068935394, 0.006765961647033691, 0.0027073295786976814, -0.0031687882728874683, 0.006098185200244188, -0.029634155333042145, 0.0018552846740931273, -0.0005795795586891472, -0.02867658995091915, 0.038781434297561646, -0.015321060083806515, -0.023094985634088516, -0.012775950133800507, 0.007578633259981871, -0.02221301756799221, 0.013657919131219387, -0.005342212039977312, 0.013317731209099293, 0.020159289240837097, -0.007339241448789835, 0.0005059509421698749, -0.016744811087846756, 0.023057186976075172, -0.023661967366933823, 0.012694052420556545, -0.011251403950154781, 0.026963049545884132, 0.02106645703315735, -0.005313863046467304, 0.0048035806976258755, -0.004138953983783722, -0.006602167617529631, 0.0027419785037636757, -0.0063848248682916164, -0.019063128158450127, 0.019504113122820854, 0.028424598276615143, 0.00562885170802474, 0.0013079914497211576, 0.014716281555593014, 0.024934520944952965, -0.022981589660048485, 0.009159876964986324, 0.021381447091698647, 0.0027120544109493494, 0.011793185025453568, 0.02189802937209606, 0.031347695738077164, -0.01025603897869587, -0.02106645703315735, 0.007465236820280552, -0.018281955271959305, 0.039209820330142975, -0.011679788120090961, -0.024997519329190254, 0.013783914037048817, 0.02008369192481041, 0.008504700846970081, -0.07584933191537857, -0.04419924318790436, 0.008214910514652729, 0.0009197675972245634, 0.0041169049218297005, 0.024014754220843315, 0.01636682264506817, 0.013783914037048817, -0.04183052480220795, -0.008895286358892918, -0.017954368144273758, -0.007521934807300568, 0.008032216690480709, 0.007200646214187145, 0.014061104506254196, -0.018962332978844643, 0.0006638391059823334, -0.01787877082824707, 0.0003795616212300956, 0.01126400288194418, 0.01768977753818035, -0.003505826462060213, 0.0020049044396728277, -0.004617737140506506, -0.016757410019636154, -0.00723214540630579, -0.009317371994256973, 0.038529444485902786, 0.007125048898160458, 0.011522294022142887, -0.011698687449097633, -0.011509694159030914, -0.011956978589296341, -0.005509155802428722, -0.0033609315287321806, -0.018105562776327133, -0.03394320607185364, 0.0022679201792925596, 0.011012012138962746, -0.014968272298574448, 0.019201723858714104, 0.010413533076643944, 0.006860458292067051, -0.03215406835079193, 0.0018285105470567942, 0.008958284743130207, -0.005361111368983984, 0.03434639051556587, -0.004321647807955742, -0.006532869767397642, -0.013292531482875347, -0.011704987846314907, -0.04752552509307861, 0.006973854266107082, 0.05042342469096184, -0.002304143738001585, 0.021709036082029343, 0.008227510377764702, -0.02257840521633625, -0.009695358574390411, -0.006066686473786831, 0.009430767968297005, -0.023661967366933823, -0.011711287312209606, 0.008888986892998219, 0.010841918177902699, 0.013909909874200821, 0.006476171780377626, -0.012927144765853882, 0.000497682485729456, 0.01153489388525486, 0.009166177362203598, -0.022842995822429657, 0.035606347024440765, -0.01964270882308483, -0.005313863046467304, -0.022376811131834984, -0.014350894838571548, 0.013922509737312794, -0.009588262066245079, -0.014300496317446232, -0.020297884941101074, -0.001294604386202991, 0.0164802186191082, 0.00208207662217319, 0.01388471107929945, -0.0030286184046417475, -0.007956619374454021, -0.0024537635035812855, -0.022905992344021797, 0.013708316721022129, -0.00286167417652905, 0.019793903455138206, 0.01598883606493473, -0.001069387304596603, 0.006658865604549646, -0.01467848289757967, -0.0016599915688857436, 0.023044588044285774, 0.0022049222607165575, 0.029130173847079277, -0.03142329305410385, -0.05901632085442543, 0.023598968982696533, -0.007332941517233849, -0.034270793199539185, 0.013456325978040695, 0.018848935142159462, 0.004224001429975033, -0.026585062965750694, -0.010237139649689198, -0.010004047304391861, -0.004532690159976482, 0.015699047595262527, -0.008473201654851437, 0.0027325288392603397, -0.04954145476222038, -0.03192727640271187, 0.032305262982845306, 0.0086936941370368, 0.024065151810646057, 0.00704945158213377, -0.011509694159030914, -0.02630787342786789, 0.01156639214605093, 0.013405927456915379, -0.021469643339514732, 0.015270662494003773, -0.019113527610898018, -0.0018080363515764475, -0.012687752954661846, -0.0034333791118115187, 0.022074421867728233, -0.029256168752908707, 0.011131707578897476, 0.0026789805851876736, -0.01574944518506527, -0.008611796423792839, 0.023359576240181923, 0.021570440381765366, -0.007950319908559322, 0.030868912115693092, -0.03863023966550827, -0.029306568205356598, 0.006784860976040363, 0.011389998719096184, -0.012712951749563217, 0.030112938955426216, -0.027492230758070946, 0.005216216202825308, 0.027567828074097633, -0.018055163323879242, 0.024279344826936722, 0.01714799553155899, -0.01416190154850483, -0.004031857941299677, 0.0013623270206153393, -0.029558558017015457, 0.015888040885329247, 0.010167841799557209, 0.011301801539957523, -0.03331322595477104, 0.01697160303592682, -0.012851547449827194, 0.009084279648959637, -0.001529271132312715, 0.007080950774252415, -0.006041487213224173, -0.027492230758070946, -0.007540834601968527, 0.0031766630709171295, -0.035984333604574203, -0.026660660281777382, -0.006391124799847603, 0.0002076958044199273, 0.005928091239184141, 0.01910092681646347, 0.015699047595262527, -0.01752598211169243, -0.0045862384140491486, -0.0020080541726201773, 0.016883404925465584, 0.0032002872321754694, -0.0012190070701763034, -0.020045893266797066, -0.022011425346136093, 0.01573684625327587, 0.024619532749056816, -0.018811136484146118, 0.02385096065700054, 0.03739548102021217, 0.015447055920958519, -0.0707591101527214, 0.007263644132763147, 0.005792645737528801, 0.011289202608168125, 0.011490794830024242, 0.012366464361548424, 0.013872111216187477, 0.0001639910915400833, 0.03303603455424309, 0.005855643656104803, -5.49754076928366e-05, 0.005521755665540695, 0.005997388623654842, 0.01123250462114811, -0.022729599848389626, 0.016102232038974762, -0.018055163323879242, -0.007301442790776491, 0.012826348654925823, 0.022779997438192368, -0.028978979215025902, 0.01123250462114811, 0.000616197066847235, 0.011875081807374954, -0.024707728996872902, -0.0014198124408721924, 0.014350894838571548, -0.010048146359622478, -0.016467619687318802, 0.024014754220843315, 0.008958284743130207, 0.01860954426229, 0.026333073154091835, -0.012120773084461689, 0.04344327002763748, -0.0018915083492174745, -0.03442198783159256, -0.02148224413394928, 0.00985915306955576, 0.021583039313554764, -0.006277728825807571, 0.0024348641745746136, -0.028827784582972527, -0.016316425055265427, -0.011308101937174797, 0.03996579349040985, -0.017677176743745804, 0.02337217703461647, -0.03928541764616966, 0.058260347694158554, 0.018105562776327133, 0.0022427209187299013, 0.0173873882740736, 0.001677315915003419, 0.007635331247001886, 0.016190430149435997, -0.0063848248682916164, -0.011434096843004227, -0.01107500959187746, 0.014136701822280884, -0.00704945158213377, -0.02111685648560524, -0.04052017256617546, -0.012082974426448345, 0.00212932494468987, -0.017614180222153664, -0.01416190154850483, -0.023586370050907135, 0.03706789389252663, 0.026937851682305336, 0.003316833171993494, 0.014565086923539639, 0.018874134868383408, -0.015724245458841324, -0.005439858417958021, 0.010545828379690647, 0.011238804087042809, -0.0024931372608989477, -0.024254145100712776, 0.0032790345139801502, -0.00704945158213377, -0.028525395318865776, -0.0032727348152548075, 0.006860458292067051, 0.0015513203106820583, -0.0158754400908947, -0.0022096470929682255, -0.0024443138390779495, -0.0011457721702754498, 0.012694052420556545, 0.017677176743745804, -0.0378238670527935, 0.00590604217723012, 0.01746298559010029, -0.002134049776941538, -0.010854518041014671, 0.009777255356311798, 0.013594920746982098]\n"
     ]
    }
   ],
   "source": [
    "print(results[\"embeddings\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 검색\n",
    "\n",
    "`similarity_search` 메서드는 Chroma 데이터베이스에서 유사도 검색을 수행합니다. 이 메서드는 주어진 쿼리와 가장 유사한 문서들을 반환합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `query` (str): 검색할 쿼리 텍스트\n",
    "- `k` (int, 선택적): 반환할 결과의 수. 기본값은 4입니다.\n",
    "- `filter` (Dict[str, str], 선택적): 메타데이터로 필터링. 기본값은 None입니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `k` 값을 조절하여 원하는 수의 결과를 얻을 수 있습니다.\n",
    "- `filter` 매개변수를 사용하여 특정 메타데이터 조건에 맞는 문서만 검색할 수 있습니다.\n",
    "- 이 메서드는 점수 정보 없이 문서만 반환합니다. 점수 정보도 필요한 경우 `similarity_search_with_score` 메서드를 직접 사용하세요.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- `List[Document]`: 쿼리 텍스트와 가장 유사한 문서들의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fd277936-75fb-4818-8ac9-778d68425ebc', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
       " Document(id='83e08339-99e9-4b77-ab98-2b7ca20a694d', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
       " Document(id='4cea98f2-d18a-450a-ab86-e4ad7add7f46', metadata={'source': 'data/nlp-keywords.txt'}, page_content=\"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\"),\n",
       " Document(id='1dab252d-1490-438a-a584-1b2ca65a0617', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"TF IDF 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`k` 값에 검색 결과의 개수를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fd277936-75fb-4818-8ac9-778d68425ebc', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
       " Document(id='83e08339-99e9-4b77-ab98-2b7ca20a694d', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.similarity_search(\"TF IDF 에 대하여 알려줘\", k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter` 에 `metadata` 정보를 활용하여 검색 결과를 필터링 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fd277936-75fb-4818-8ac9-778d68425ebc', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
       " Document(id='83e08339-99e9-4b77-ab98-2b7ca20a694d', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter 사용\n",
    "db.similarity_search(\n",
    "    \"TF IDF 에 대하여 알려줘\", filter={\"source\": \"data/nlp-keywords.txt\"}, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 `filter` 에서 다른 `source` 를 사용하여 검색한 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter 사용\n",
    "db.similarity_search(\n",
    "    \"TF IDF 에 대하여 알려줘\", filter={\"source\": \"data/finance-keywords.txt\"}, k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 저장소에 문서 추가\n",
    "\n",
    "`add_documents` 메서드는 벡터 저장소에 문서를 추가하거나 업데이트합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `documents` (List[Document]): 벡터 저장소에 추가할 문서 리스트\n",
    "- `**kwargs`: 추가 키워드 인자\n",
    "  - `ids`: 문서 ID 리스트 (제공 시 문서의 ID보다 우선함)\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `add_texts` 메서드가 구현되어 있어야 합니다.\n",
    "- 문서의 `page_content`는 텍스트로, `metadata`는 메타데이터로 사용됩니다.\n",
    "- 문서에 ID가 있고 `kwargs`에 ID가 제공되지 않으면 문서의 ID가 사용됩니다.\n",
    "- `kwargs`의 ID와 문서 수가 일치하지 않으면 ValueError가 발생합니다.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- `List[str]`: 추가된 텍스트의 ID 리스트\n",
    "\n",
    "**예외**\n",
    "\n",
    "- `NotImplementedError`: `add_texts` 메서드가 구현되지 않은 경우 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# page_content, metadata, id 지정\n",
    "db.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요\",\n",
    "            metadata={\"source\": \"mydata.txt\"},\n",
    "            id=\"1\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['1'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'mydata.txt'}],\n",
       " 'documents': ['안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id=1 로 문서 조회\n",
    "db.get(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add_texts` 메서드는 텍스트를 임베딩하고 벡터 저장소에 추가합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `texts` (Iterable[str]): 벡터 저장소에 추가할 텍스트 리스트\n",
    "- `metadatas` (Optional[List[dict]]): 메타데이터 리스트. 기본값은 None\n",
    "- `ids` (Optional[List[str]]): 문서 ID 리스트. 기본값은 None\n",
    "\n",
    "**참고**\n",
    "\n",
    "- `ids`가 제공되지 않으면 UUID를 사용하여 자동으로 생성됩니다.\n",
    "- 임베딩 함수가 설정되어 있으면 텍스트를 임베딩합니다.\n",
    "- 메타데이터가 제공된 경우:\n",
    "  - 메타데이터가 있는 텍스트와 없는 텍스트를 분리하여 처리합니다.\n",
    "  - 메타데이터가 없는 텍스트의 경우 빈 딕셔너리로 채웁니다.\n",
    "- 컬렉션에 upsert 작업을 수행하여 텍스트, 임베딩, 메타데이터를 추가합니다.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- `List[str]`: 추가된 텍스트의 ID 리스트\n",
    "\n",
    "**예외**\n",
    "\n",
    "- `ValueError`: 복잡한 메타데이터로 인한 오류 발생 시, 필터링 방법 안내 메시지와 함께 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 아이디에 추가하는 경우 `upsert` 가 수행되며, 기존의 문서는 대체됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신규 데이터를 추가합니다. 이때 기존의 id=1 의 데이터는 덮어쓰게 됩니다.\n",
    "db.add_texts(\n",
    "    [\"이전에 추가한 Document 를 덮어쓰겠습니다.\", \"덮어쓴 결과가 어떤가요?\"],\n",
    "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
    "    ids=[\"1\", \"2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['1'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'mydata.txt'}],\n",
       " 'documents': ['이전에 추가한 Document 를 덮어쓰겠습니다.'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id=1 조회\n",
    "db.get([\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 저장소에서 문서 삭제\n",
    "\n",
    "`delete` 메서드는 벡터 저장소에서 지정된 ID의 문서를 삭제합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `ids` (Optional[List[str]]): 삭제할 문서의 ID 리스트. 기본값은 None\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이 메서드는 내부적으로 컬렉션의 `delete` 메서드를 호출합니다.\n",
    "- `ids`가 None이면 아무 작업도 수행하지 않습니다.\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id 1 삭제\n",
    "db.delete(ids=[\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['2'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'mydata.txt'}],\n",
       " 'documents': ['덮어쓴 결과가 어떤가요?'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 조회\n",
    "db.get([\"1\", \"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['2'],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [{'source': 'mydata.txt'}],\n",
       " 'documents': ['덮어쓴 결과가 어떤가요?'],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where 조건으로 metadata 조회\n",
    "db.get(where={\"source\": \"mydata.txt\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초기화(reset_collection)\n",
    "\n",
    "`reset_collection` 메서드는 벡터 저장소의 컬렉션을 초기화합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬렉션 초기화\n",
    "db.reset_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 후 문서 조회\n",
    "db.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터 저장소를 검색기(Retriever)로 변환\n",
    "\n",
    "`as_retriever` 메서드는 벡터 저장소를 기반으로 VectorStoreRetriever를 생성합니다.\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `**kwargs`: 검색 함수에 전달할 키워드 인자\n",
    "  - `search_type` (Optional[str]): 검색 유형 (`\"similarity\"`, `\"mmr\"`, `\"similarity_score_threshold\"`)\n",
    "  - `search_kwargs` (Optional[Dict]): 검색 함수에 전달할 추가 인자\n",
    "    - `k`: 반환할 문서 수 (기본값: 4)\n",
    "    - `score_threshold`: 최소 유사도 임계값\n",
    "    - `fetch_k`: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "    - `lambda_mult`: MMR 결과의 다양성 조절 (0~1, 기본값: 0.5)\n",
    "    - `filter`: 문서 메타데이터 필터링\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- `VectorStoreRetriever`: 벡터 저장소 기반 검색기 인스턴스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DB` 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 생성\n",
    "db = Chroma.from_documents(\n",
    "    documents=split_doc1 + split_doc2,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=\"nlp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본 값으로 설정된 4개 문서를 유사도 검색을 수행하여 조회합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be3e6a02-03cd-4e06-934d-eca5868d5c48', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
       " Document(id='d7a03223-1ea1-4628-9a0f-9226368fab51', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
       " Document(id='36b759d9-fd0e-4184-9a6e-13e9328f281f', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
       " Document(id='eb1c4f56-a66d-432f-8f25-b9975406c4d3', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양성이 높은 더 많은 문서 검색\n",
    "\n",
    "- `k`: 반환할 문서 수 (기본값: 4)\n",
    "- `fetch_k`: MMR 알고리즘에 전달할 문서 수 (기본값: 20)\n",
    "- `lambda_mult`: MMR 결과의 다양성 조절 (0~1, 기본값: 0.5, 0: 유사도 점수만 고려, 1: 다양성만 고려)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be3e6a02-03cd-4e06-934d-eca5868d5c48', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
       " Document(id='eb1c4f56-a66d-432f-8f25-b9975406c4d3', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
       " Document(id='2c9f92e5-421d-47e8-92d7-6ad5bdf5bca3', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)'),\n",
       " Document(id='7192c26f-e140-44e5-9883-d031e953de94', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace'),\n",
       " Document(id='7290a484-37e7-4cbd-9304-eb67369cac40', metadata={'source': 'data/nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
       " Document(id='44cb696a-dec7-48b1-865e-2349ca49671a', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25, \"fetch_k\": 10}\n",
    ")\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMR 알고리즘을 위해 더 많은 문서를 가져오되 상위 2개만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be3e6a02-03cd-4e06-934d-eca5868d5c48', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
       " Document(id='7290a484-37e7-4cbd-9304-eb67369cac40', metadata={'source': 'data/nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10})\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 임계값 이상의 유사도를 가진 문서만 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be3e6a02-03cd-4e06-934d-eca5868d5c48', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")\n",
    "\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 유사한 단일 문서만 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='be3e6a02-03cd-4e06-934d-eca5868d5c48', metadata={'source': 'data/nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 메타데이터 필터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='50355d42-9542-477b-a68b-e91c01c94097', metadata={'source': 'data/finance-keywords.txt'}, page_content='정의: ESG는 기업의 환경, 사회, 지배구조 측면을 고려하는 투자 접근 방식입니다.\\n예시: S&P 500 ESG 지수는 우수한 ESG 성과를 보이는 기업들로 구성된 지수입니다.\\n연관키워드: 지속가능 투자, 기업의 사회적 책임, 윤리 경영\\n\\nStock Buyback\\n\\n정의: 자사주 매입은 기업이 자사의 주식을 시장에서 다시 사들이는 것을 말합니다.\\n예시: 애플은 S&P 500 기업 중 가장 큰 규모의 자사주 매입 프로그램을 운영하고 있습니다.\\n연관키워드: 주주 가치, 자본 관리, 주가 부양\\n\\nCyclical Stocks\\n\\n정의: 경기순환주는 경제 상황에 따라 실적이 크게 변동하는 기업의 주식을 말합니다.\\n예시: 포드, 제너럴 모터스와 같은 자동차 기업들은 S&P 500에 포함된 대표적인 경기순환주입니다.\\n연관키워드: 경제 사이클, 섹터 분석, 투자 타이밍\\n\\nDefensive Stocks\\n\\n정의: 방어주는 경기 변동에 상관없이 안정적인 실적을 보이는 기업의 주식을 의미합니다.\\n예시: 프록터앤갬블, 존슨앤존슨과 같은 생활필수품 기업들은 S&P 500 내 대표적인 방어주로 꼽힙니다.\\n연관키워드: 안정적 수익, 저변동성, 리스크 관리'),\n",
       " Document(id='f21e6e72-f4a5-4707-9b28-750e94e708e9', metadata={'source': 'data/finance-keywords.txt'}, page_content='정의: 주식 리서치는 기업의 재무 상태, 사업 모델, 경쟁력 등을 분석하여 투자 의사 결정을 돕는 활동입니다.\\n예시: 골드만삭스의 애널리스트들이 S&P 500 기업들에 대한 분기별 실적 전망을 발표했습니다.\\n연관키워드: 투자 분석, 기업 가치평가, 시장 전망\\n\\nCorporate Governance\\n\\n정의: 기업 지배구조는 기업의 경영과 통제에 관한 시스템과 프로세스를 의미합니다.\\n예시: S&P 500 기업들 중 이사회의 다양성을 높이는 기업들이 증가하고 있습니다.\\n연관키워드: 주주 권리, ESG, 기업 윤리\\n\\nMergers and Acquisitions (M&A)\\n\\n정의: 인수합병은 기업들이 다른 기업을 사거나 합치는 과정을 말합니다.\\n예시: 마이크로소프트가 액티비전 블리자드를 인수하면서 S&P 500 내 게임 산업의 판도가 변화했습니다.\\n연관키워드: 기업 전략, 시너지 효과, 기업 가치\\n\\nESG (Environmental, Social, and Governance)')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"source\": \"data/finance-keywords.txt\"}, \"k\": 2}\n",
    ")\n",
    "retriever.invoke(\"ESG 에 대하여 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 멀티모달 검색\n",
    "\n",
    "Chroma는 멀티모달 컬렉션, 즉 여러 양식의 데이터를 포함하고 쿼리할 수 있는 컬렉션을 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 세트\n",
    "\n",
    "허깅페이스에서 호스팅되는 [coco object detection dataset](https://huggingface.co/datasets/detection-datasets/coco)의 작은 하위 집합을 사용합니다.\n",
    "\n",
    "데이터 세트의 모든 이미지 중 일부만 로컬로 다운로드하고 이를 사용하여 멀티모달 컬렉션을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f746b14fb343d2b1f05d792e7513c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# COCO 데이터셋 로드\n",
    "dataset = load_dataset(\n",
    "    path=\"detection-datasets/coco\", name=\"default\", split=\"train\", streaming=True\n",
    ")\n",
    "\n",
    "# 이미지 저장 폴더와 이미지 개수 설정\n",
    "IMAGE_FOLDER = \"tmp\"\n",
    "N_IMAGES = 20\n",
    "\n",
    "# 그래프 플로팅을 위한 설정\n",
    "plot_cols = 5\n",
    "plot_rows = N_IMAGES // plot_cols\n",
    "fig, axes = plt.subplots(plot_rows, plot_cols, figsize=(plot_rows * 2, plot_cols * 2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 이미지를 폴더에 저장하고 그래프에 표시\n",
    "dataset_iter = iter(dataset)\n",
    "os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "for i in range(N_IMAGES):\n",
    "    # 데이터셋에서 이미지와 레이블 추출\n",
    "    data = next(dataset_iter)\n",
    "    image = data[\"image\"]\n",
    "    label = data[\"objects\"][\"category\"][0]  # 첫 번째 객체의 카테고리를 레이블로 사용\n",
    "\n",
    "    # 그래프에 이미지 표시 및 레이블 추가\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(label, fontsize=8)\n",
    "    axes[i].axis(\"off\")\n",
    "\n",
    "    # 이미지 파일로 저장\n",
    "    image.save(f\"{IMAGE_FOLDER}/{i}.jpg\")\n",
    "\n",
    "# 그래프 레이아웃 조정 및 표시\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimodal Embeddings\n",
    "\n",
    "Multimodal Embeddings 을 활용하여 이미지, 텍스트에 대한 Embedding 을 생성합니다.\n",
    "\n",
    "이번 튜토리얼에서는 OpenClipEmbeddingFunction 을 사용하여 이미지를 임베딩합니다.\n",
    "\n",
    "- [OpenCLIP](https://github.com/mlfoundations/open_clip/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 벤치마크\n",
    "\n",
    "| Model                              | Training data  | Resolution | # of samples seen | ImageNet zero-shot acc. |\n",
    "|------------------------------------|----------------|------------|-------------------|-------------------------|\n",
    "| ConvNext-Base                       | LAION-2B       | 256px      | 13B               | 71.5%                   |\n",
    "| ConvNext-Large                      | LAION-2B       | 320px      | 29B               | 76.9%                   |\n",
    "| ConvNext-XXLarge                    | LAION-2B       | 256px      | 34B               | 79.5%                   |\n",
    "| ViT-B/32                            | DataComp-1B    | 256px      | 34B               | 72.8%                   |\n",
    "| ViT-B/16                            | DataComp-1B    | 224px      | 13B               | 73.5%                   |\n",
    "| ViT-L/14                            | LAION-2B       | 224px      | 32B               | 75.3%                   |\n",
    "| ViT-H/14                            | LAION-2B       | 224px      | 32B               | 78.0%                   |\n",
    "| ViT-L/14                            | DataComp-1B    | 224px      | 13B               | 79.2%                   |\n",
    "| ViT-G/14                            | LAION-2B       | 224px      | 34B               | 80.1%                   |\n",
    "| ViT-L/14 ([Original CLIP](https://openai.com/research/clip)) | WIT            | 224px      | 13B               | 75.5%                   |\n",
    "| ViT-SO400M/14 ([SigLIP](https://github.com/mlfoundations/open_clip)) | WebLI | 224px | 45B | 82.0% |\n",
    "| ViT-SO400M-14-SigLIP-384 ([SigLIP](https://github.com/mlfoundations/open_clip)) | WebLI | 384px | 45B | 83.1% |\n",
    "| ViT-H/14-quickgelu ([DFN](https://www.deeplearning.ai/glossary/neural-networks/)) | DFN-5B | 224px | 39B | 83.4% |\n",
    "| ViT-H-14-378-quickgelu ([DFN](https://www.deeplearning.ai/glossary/neural-networks/)) | DFN-5B | 378px | 44B | 84.4% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 예시에서 `model_name` 과 `checkpoint` 를 설정하여 사용합니다.\n",
    "\n",
    "- `model_name`: OpenCLIP 모델명\n",
    "- `checkpoint`: OpenCLIP 모델의 `Training data` 에 해당하는 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Uq open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import pandas as pd\n",
    "\n",
    "# 사용 가능한 모델/Checkpoint 를 출력\n",
    "pd.DataFrame(open_clip.list_pretrained(), columns=[\"model_name\", \"checkpoint\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "\n",
    "# OpenCLIP 임베딩 함수 객체 생성\n",
    "image_embedding_function = OpenCLIPEmbeddings(\n",
    "    model_name=\"ViT-H-14-378-quickgelu\", checkpoint=\"dfn5b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지의 경로를 list 로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 경로를 리스트로 저장\n",
    "image_uris = sorted(\n",
    "    [\n",
    "        os.path.join(\"tmp\", image_name)\n",
    "        for image_name in os.listdir(\"tmp\")\n",
    "        if image_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# MultiModal 모델 설정\n",
    "model = MultiModal(\n",
    "    model=llm,\n",
    "    system_prompt=\"Your mission is to describe the image in detail\",  # 시스템 프롬프트: 이미지를 상세히 설명하도록 지시\n",
    "    user_prompt=\"Description should be written in one sentence(less than 60 characters)\",  # 사용자 프롬프트: 60자 이내의 한 문장으로 설명 요청\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image 에 대한 description 을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 설명 생성\n",
    "model.invoke(image_uris[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 설명\n",
    "descriptions = dict()\n",
    "\n",
    "for image_uri in image_uris:\n",
    "    descriptions[image_uri] = model.invoke(image_uri, display_image=False)\n",
    "\n",
    "# 생성된 결과물 출력\n",
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 원본 이미지, 처리된 이미지, 텍스트 설명을 저장할 리스트 초기화\n",
    "original_images = []\n",
    "images = []\n",
    "texts = []\n",
    "\n",
    "# 그래프 크기 설정 (20x10 인치)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# 'tmp' 디렉토리에 저장된 이미지 파일들을 처리\n",
    "for i, image_uri in enumerate(image_uris):\n",
    "    # 이미지 파일 열기 및 RGB 모드로 변환\n",
    "    image = Image.open(image_uri).convert(\"RGB\")\n",
    "\n",
    "    # 4x5 그리드의 서브플롯 생성\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # 이미지 파일명과 설명을 제목으로 설정\n",
    "    plt.title(f\"{os.path.basename(image_uri)}\\n{descriptions[image_uri]}\", fontsize=8)\n",
    "\n",
    "    # x축과 y축의 눈금 제거\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # 원본 이미지, 처리된 이미지, 텍스트 설명을 각 리스트에 추가\n",
    "    original_images.append(image)\n",
    "    images.append(image)\n",
    "    texts.append(descriptions[image_uri])\n",
    "\n",
    "# 서브플롯 간 간격 조정\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 생성한 이미지 description 과 텍스트 간의 유사도를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 이미지와 텍스트 임베딩\n",
    "# 이미지 URI를 사용하여 이미지 특징 추출\n",
    "img_features = image_embedding_function.embed_image(image_uris)\n",
    "# 텍스트 설명에 \"This is\" 접두사를 추가하고 텍스트 특징 추출\n",
    "text_features = image_embedding_function.embed_documents(\n",
    "    [\"This is \" + desc for desc in texts]\n",
    ")\n",
    "\n",
    "# 행렬 연산을 위해 리스트를 numpy 배열로 변환\n",
    "img_features_np = np.array(img_features)\n",
    "text_features_np = np.array(text_features)\n",
    "\n",
    "# 유사도 계산\n",
    "# 텍스트와 이미지 특징 간의 코사인 유사도를 계산\n",
    "similarity = np.matmul(text_features_np, img_features_np.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 대 이미지 description 간 유사도를 구하고 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 행렬을 시각화하기 위한 플롯 생성\n",
    "count = len(descriptions)\n",
    "plt.figure(figsize=(20, 14))\n",
    "\n",
    "# 유사도 행렬을 히트맵으로 표시\n",
    "plt.imshow(similarity, vmin=0.1, vmax=0.3, cmap=\"coolwarm\")\n",
    "plt.colorbar()  # 컬러바 추가\n",
    "\n",
    "# y축에 텍스트 설명 표시\n",
    "plt.yticks(range(count), texts, fontsize=18)\n",
    "plt.xticks([])  # x축 눈금 제거\n",
    "\n",
    "# 원본 이미지를 x축 아래에 표시\n",
    "for i, image in enumerate(original_images):\n",
    "    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin=\"lower\")\n",
    "\n",
    "# 유사도 값을 히트맵 위에 텍스트로 표시\n",
    "for x in range(similarity.shape[1]):\n",
    "    for y in range(similarity.shape[0]):\n",
    "        plt.text(x, y, f\"{similarity[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
    "\n",
    "# 플롯 테두리 제거\n",
    "for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "    plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "# 플롯 범위 설정\n",
    "plt.xlim([-0.5, count - 0.5])\n",
    "plt.ylim([count + 0.5, -2])\n",
    "\n",
    "# 제목 추가\n",
    "plt.title(\"Cosine Similarity\", size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore 생성 및 이미지 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorstore 를 생성하고 이미지를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 생성\n",
    "image_db = Chroma(\n",
    "    collection_name=\"multimodal\",\n",
    "    embedding_function=image_embedding_function,\n",
    ")\n",
    "\n",
    "# 이미지 추가, 이미지 파일이 있는 경로 \n",
    "image_db.add_images(uris=image_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 이미지 검색된 결과를 이미지로 출력하기 위한 helper class 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import HTML, display\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "class ImageRetriever:\n",
    "    def __init__(self, retriever):\n",
    "        \"\"\"\n",
    "        이미지 검색기를 초기화합니다.\n",
    "\n",
    "        인자:\n",
    "        retriever: LangChain의 retriever 객체\n",
    "        \"\"\"\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def invoke(self, query):\n",
    "        \"\"\"\n",
    "        쿼리를 사용하여 이미지를 검색하고 표시합니다.\n",
    "\n",
    "        인자:\n",
    "        query (str): 검색 쿼리\n",
    "        \"\"\"\n",
    "        docs = self.retriever.invoke(query)\n",
    "        if docs and isinstance(docs[0], Document):\n",
    "            self.plt_img_base64(docs[0].page_content)\n",
    "        else:\n",
    "            print(\"검색된 이미지가 없습니다.\")\n",
    "        return docs\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_base64_image(base64_string, size=(224, 224)):\n",
    "        \"\"\"\n",
    "        Base64 문자열로 인코딩된 이미지의 크기를 조정합니다.\n",
    "\n",
    "        인자:\n",
    "        base64_string (str): 원본 이미지의 Base64 문자열.\n",
    "        size (tuple): (너비, 높이)로 표현된 원하는 이미지 크기.\n",
    "\n",
    "        반환:\n",
    "        str: 크기가 조정된 이미지의 Base64 문자열.\n",
    "        \"\"\"\n",
    "        img_data = base64.b64decode(base64_string)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        resized_img = img.resize(size, Image.LANCZOS)\n",
    "        buffered = io.BytesIO()\n",
    "        resized_img.save(buffered, format=img.format)\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plt_img_base64(img_base64):\n",
    "        \"\"\"\n",
    "        Base64로 인코딩된 이미지를 표시합니다.\n",
    "\n",
    "        인자:\n",
    "        img_base64 (str): Base64로 인코딩된 이미지 문자열\n",
    "        \"\"\"\n",
    "        image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "        display(HTML(image_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Retriever 생성\n",
    "retriever = image_db.as_retriever(search_kwargs={\"k\": 3})\n",
    "image_retriever = ImageRetriever(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 조회\n",
    "result = image_retriever.invoke(\"A Dog on the street\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-05.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 조회\n",
    "result = image_retriever.invoke(\"Motorcycle with a man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/chroma-06.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu-rag-h6vp0ZFq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
